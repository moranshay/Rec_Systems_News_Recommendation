{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lstur_notebook_v2_1_five_epochs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIzxOKqbkaaQ"
      },
      "source": [
        "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
        "\n",
        "<i>Licensed under the MIT License.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljlZtzh9kaaU"
      },
      "source": [
        "# LSTUR: Neural News Recommendation with Long- and Short-term User Representations\n",
        "LSTUR \\[1\\] is a news recommendation approach capturing users' both long-term preferences and short-term interests. The core of LSTUR is a news encoder and a user encoder.  In the news encoder, we learn representations of news from their titles. In user encoder, we propose to learn long-term\n",
        "user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine\n",
        "long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both\n",
        "long- and short-term user representations as a unified user vector.\n",
        "\n",
        "## Properties of LSTUR:\n",
        "- LSTUR captures users' both long-term and short term preference.\n",
        "- It uses embeddings of users' IDs to learn long-term user representations.\n",
        "- It uses users' recently browsed news via GRU network to learn short-term user representations.\n",
        "\n",
        "## Data format:\n",
        "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
        " \n",
        "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
        "\n",
        "### news data\n",
        "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
        "One simple example: <br>\n",
        "\n",
        "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
        "<br>\n",
        "\n",
        "In general, each line in data file represents information of one piece of news: <br>\n",
        "\n",
        "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
        "\n",
        "<br>\n",
        "\n",
        "We generate a word_dict file to tranform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
        "\n",
        "### behaviors data\n",
        "One simple example: <br>\n",
        "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
        "<br>\n",
        "\n",
        "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
        "\n",
        "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
        "\n",
        "<br>\n",
        "\n",
        "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
        "\n",
        "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
        "\n",
        "<br>\n",
        "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOGRws6CkaaX"
      },
      "source": [
        "# Global settings and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMmmhURw64ab"
      },
      "source": [
        "The following command is only required in Google Collab. The goal is to set Tensorflow version to 1.x instead of the default 2.x. If this code is executed on a different notebook platform, please assign the notebook a kernel that contains Tensorflow 1.x and not 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlqGgQcRm8tR"
      },
      "source": [
        "# !pip install matplotlib==3.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8A532RzobB4"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP-mjChbkaar"
      },
      "source": [
        "# Required only in Google Collab, to change the default TensorFlow version to 1.x instead of the default 2.x.\n",
        "# %tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7QylbedKkaat",
        "outputId": "5609336a-7a70-418c-ce37-5d98b0df9e27"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1.15.5'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FulhGrFZkaaa",
        "outputId": "791a6f44-7800-4316-ea04-4b886239c9cb"
      },
      "source": [
        "!pip install scrapbook\n",
        "!pip install backoff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scrapbook\n",
            "  Downloading scrapbook-0.5.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scrapbook) (3.2.0)\n",
            "Collecting papermill\n",
            "  Downloading papermill-2.3.3-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scrapbook) (4.0.1)\n",
            "Requirement already satisfied: ipython in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scrapbook) (7.16.1)\n",
            "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scrapbook) (1.1.5)\n",
            "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (49.6.0.post20210108)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (3.0.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (0.17.2)\n",
            "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (2.8.0)\n",
            "Requirement already satisfied: pexpect in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (4.8.0)\n",
            "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->scrapbook) (4.4.2)\n",
            "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython->scrapbook) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->scrapbook) (0.2.5)\n",
            "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->scrapbook) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->scrapbook) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jsonschema->scrapbook) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jsonschema->scrapbook) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jsonschema->scrapbook) (20.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->jsonschema->scrapbook) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->jsonschema->scrapbook) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->scrapbook) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->scrapbook) (2021.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->scrapbook) (1.18.5)\n",
            "Collecting ansiwrap\n",
            "  Downloading ansiwrap-0.8.4-py2.py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (4.61.2)\n",
            "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (0.3)\n",
            "Requirement already satisfied: black in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (20.8b1)\n",
            "Requirement already satisfied: nbformat>=5.1.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (5.1.2)\n",
            "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (7.1.2)\n",
            "Requirement already satisfied: tenacity in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (8.0.0)\n",
            "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (2.25.1)\n",
            "Requirement already satisfied: nbclient>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from papermill->scrapbook) (0.5.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill->scrapbook) (6.1.11)\n",
            "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill->scrapbook) (1.4.3)\n",
            "Requirement already satisfied: async-generator in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill->scrapbook) (1.10)\n",
            "Requirement already satisfied: pyzmq>=13 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (22.0.3)\n",
            "Requirement already satisfied: tornado>=4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (4.7.1)\n",
            "Collecting textwrap3>=0.9.2\n",
            "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: toml>=0.10.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (0.10.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (0.4.3)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (0.8)\n",
            "Requirement already satisfied: appdirs in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (1.4.4)\n",
            "Requirement already satisfied: pathspec<1,>=0.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (0.8.1)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (2020.11.13)\n",
            "Requirement already satisfied: typed-ast>=1.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from black->papermill->scrapbook) (1.4.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pexpect->ipython->scrapbook) (0.7.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->papermill->scrapbook) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->papermill->scrapbook) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->papermill->scrapbook) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->papermill->scrapbook) (1.26.6)\n",
            "Installing collected packages: textwrap3, ansiwrap, papermill, scrapbook\n",
            "Successfully installed ansiwrap-0.8.4 papermill-2.3.3 scrapbook-0.5.0 textwrap3-0.9.2\n",
            "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
            "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Collecting backoff\n",
            "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-1.11.1\n",
            "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
            "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t1_Eir8kaah"
      },
      "source": [
        "# !pip install git+https://github.com/microsoft/recommenders/#egg=reco_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWlb7_rplYhp"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import requests\n",
        "import math\n",
        "import zipfile\n",
        "from contextlib import contextmanager\n",
        "from tempfile import TemporaryDirectory\n",
        "from tqdm import tqdm\n",
        "import backoff\n",
        "\n",
        "\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.HTTPError, requests.exceptions.ChunkedEncodingError),\n",
        "    max_tries=5,\n",
        ")\n",
        "def maybe_download(url, filename=None, work_directory=\".\", expected_bytes=None):\n",
        "    \"\"\"Download a file if it is not already downloaded.\n",
        "    Args:\n",
        "        filename (str): File name.\n",
        "        work_directory (str): Working directory.\n",
        "        url (str): URL of the file to download.\n",
        "        expected_bytes (int): Expected file size in bytes.\n",
        "    Returns:\n",
        "        str: File path of the file downloaded.\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        filename = url.split(\"/\")[-1]\n",
        "    os.makedirs(work_directory, exist_ok=True)\n",
        "    filepath = os.path.join(work_directory, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "\n",
        "        r = requests.get(url, stream=True)\n",
        "        total_size = int(r.headers.get(\"content-length\", 0))\n",
        "        block_size = 1024\n",
        "        num_iterables = math.ceil(total_size / block_size)\n",
        "\n",
        "        with open(filepath, \"wb\") as file:\n",
        "            for data in tqdm(\n",
        "                r.iter_content(block_size),\n",
        "                total=num_iterables,\n",
        "                unit=\"KB\",\n",
        "                unit_scale=True,\n",
        "            ):\n",
        "                file.write(data)\n",
        "    else:\n",
        "        log.info(\"File {} already downloaded\".format(filepath))\n",
        "    if expected_bytes is not None:\n",
        "        statinfo = os.stat(filepath)\n",
        "        if statinfo.st_size != expected_bytes:\n",
        "            os.remove(filepath)\n",
        "            raise IOError(\"Failed to verify {}\".format(filepath))\n",
        "\n",
        "    return filepath\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def download_path(path=None):\n",
        "    \"\"\"Return a path to download data. If `path=None`, then it yields a temporal path that is eventually deleted,\n",
        "    otherwise the real path of the input.\n",
        "    Args:\n",
        "        path (str): Path to download data.\n",
        "    Returns:\n",
        "        str: Real path where the data is stored.\n",
        "    Examples:\n",
        "        >>> with download_path() as path:\n",
        "        >>> ... maybe_download(url=\"http://example.com/file.zip\", work_directory=path)\n",
        "    \"\"\"\n",
        "    if path is None:\n",
        "        tmp_dir = TemporaryDirectory()\n",
        "        try:\n",
        "            yield tmp_dir.name\n",
        "        finally:\n",
        "            tmp_dir.cleanup()\n",
        "    else:\n",
        "        path = os.path.realpath(path)\n",
        "        yield path\n",
        "\n",
        "\n",
        "def unzip_file(zip_src, dst_dir, clean_zip_file=True):\n",
        "    \"\"\"Unzip a file\n",
        "    Args:\n",
        "        zip_src (str): Zip file.\n",
        "        dst_dir (str): Destination folder.\n",
        "        clean_zip_file (bool): Whether or not to clean the zip file.\n",
        "    \"\"\"\n",
        "    fz = zipfile.ZipFile(zip_src, \"r\")\n",
        "    for file in fz.namelist():\n",
        "        fz.extract(file, dst_dir)\n",
        "    if clean_zip_file:\n",
        "        os.remove(zip_src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1MJOvmflPjR"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "\n",
        "import os\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    log_loss,\n",
        "    mean_squared_error,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "import numpy as np\n",
        "import yaml\n",
        "import zipfile\n",
        "import json\n",
        "import pickle as pkl\n",
        "import tensorflow as tf\n",
        "\n",
        "def flat_config(config):\n",
        "    \"\"\"Flat config loaded from a yaml file to a flat dict.\n",
        "    \n",
        "    Args:\n",
        "        config (dict): Configuration loaded from a yaml file.\n",
        "    Returns:\n",
        "        dict: Configuration dictionary.\n",
        "    \"\"\"\n",
        "    f_config = {}\n",
        "    category = config.keys()\n",
        "    for cate in category:\n",
        "        for key, val in config[cate].items():\n",
        "            f_config[key] = val\n",
        "    return f_config\n",
        "\n",
        "\n",
        "def check_type(config):\n",
        "    \"\"\"Check that the config parameters are the correct type\n",
        "    \n",
        "    Args:\n",
        "        config (dict): Configuration dictionary.\n",
        "    Raises:\n",
        "        TypeError: If the parameters are not the correct type.\n",
        "    \"\"\"\n",
        "\n",
        "    int_parameters = [\n",
        "        \"word_size\",\n",
        "        \"entity_size\",\n",
        "        \"doc_size\",\n",
        "        \"history_size\",\n",
        "        \"FEATURE_COUNT\",\n",
        "        \"FIELD_COUNT\",\n",
        "        \"dim\",\n",
        "        \"epochs\",\n",
        "        \"batch_size\",\n",
        "        \"show_step\",\n",
        "        \"save_epoch\",\n",
        "        \"PAIR_NUM\",\n",
        "        \"DNN_FIELD_NUM\",\n",
        "        \"attention_layer_sizes\",\n",
        "        \"n_user\",\n",
        "        \"n_item\",\n",
        "        \"n_user_attr\",\n",
        "        \"n_item_attr\",\n",
        "        \"item_embedding_dim\",\n",
        "        \"cate_embedding_dim\",\n",
        "        \"user_embedding_dim\",\n",
        "        \"max_seq_length\",\n",
        "        \"hidden_size\",\n",
        "        \"T\",\n",
        "        \"L\",\n",
        "        \"n_v\",\n",
        "        \"n_h\",\n",
        "        \"kernel_size\",\n",
        "        \"min_seq_length\",\n",
        "        \"attention_size\",\n",
        "        \"epochs\",\n",
        "        \"batch_size\",\n",
        "        \"show_step\",\n",
        "        \"save_epoch\",\n",
        "        \"train_num_ngs\",\n",
        "    ]\n",
        "    for param in int_parameters:\n",
        "        if param in config and not isinstance(config[param], int):\n",
        "            raise TypeError(\"Parameters {0} must be int\".format(param))\n",
        "\n",
        "    float_parameters = [\n",
        "        \"init_value\",\n",
        "        \"learning_rate\",\n",
        "        \"embed_l2\",\n",
        "        \"embed_l1\",\n",
        "        \"layer_l2\",\n",
        "        \"layer_l1\",\n",
        "        \"mu\",\n",
        "    ]\n",
        "    for param in float_parameters:\n",
        "        if param in config and not isinstance(config[param], float):\n",
        "            raise TypeError(\"Parameters {0} must be float\".format(param))\n",
        "\n",
        "    str_parameters = [\n",
        "        \"train_file\",\n",
        "        \"eval_file\",\n",
        "        \"test_file\",\n",
        "        \"infer_file\",\n",
        "        \"method\",\n",
        "        \"load_model_name\",\n",
        "        \"infer_model_name\",\n",
        "        \"loss\",\n",
        "        \"optimizer\",\n",
        "        \"init_method\",\n",
        "        \"attention_activation\",\n",
        "        \"user_vocab\",\n",
        "        \"item_vocab\",\n",
        "        \"cate_vocab\",\n",
        "    ]\n",
        "    for param in str_parameters:\n",
        "        if param in config and not isinstance(config[param], str):\n",
        "            raise TypeError(\"Parameters {0} must be str\".format(param))\n",
        "\n",
        "    list_parameters = [\n",
        "        \"layer_sizes\",\n",
        "        \"activation\",\n",
        "        \"dropout\",\n",
        "        \"att_fcn_layer_sizes\",\n",
        "        \"dilations\",\n",
        "    ]\n",
        "    for param in list_parameters:\n",
        "        if param in config and not isinstance(config[param], list):\n",
        "            raise TypeError(\"Parameters {0} must be list\".format(param))\n",
        "\n",
        "\n",
        "def check_nn_config(f_config):\n",
        "    \"\"\"Check neural networks configuration.\n",
        "    \n",
        "    Args:\n",
        "        f_config (dict): Neural network configuration.\n",
        "    \n",
        "    Raises:\n",
        "        ValueError: If the parameters are not correct.\n",
        "    \"\"\"\n",
        "    if f_config[\"model_type\"] in [\"fm\", \"FM\"]:\n",
        "        required_parameters = [\"FEATURE_COUNT\", \"dim\", \"loss\", \"data_format\", \"method\"]\n",
        "    elif f_config[\"model_type\"] in [\"lr\", \"LR\"]:\n",
        "        required_parameters = [\"FEATURE_COUNT\", \"loss\", \"data_format\", \"method\"]\n",
        "    elif f_config[\"model_type\"] in [\"dkn\", \"DKN\"]:\n",
        "        required_parameters = [\n",
        "            \"doc_size\",\n",
        "            \"history_size\",\n",
        "            \"wordEmb_file\",\n",
        "            \"entityEmb_file\",\n",
        "            \"contextEmb_file\",\n",
        "            \"news_feature_file\",\n",
        "            \"user_history_file\",\n",
        "            \"word_size\",\n",
        "            \"entity_size\",\n",
        "            \"use_entity\",\n",
        "            \"use_context\",\n",
        "            \"data_format\",\n",
        "            \"dim\",\n",
        "            \"layer_sizes\",\n",
        "            \"activation\",\n",
        "            \"attention_activation\",\n",
        "            \"attention_activation\",\n",
        "            \"attention_dropout\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "            \"method\",\n",
        "            \"num_filters\",\n",
        "            \"filter_sizes\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"exDeepFM\", \"xDeepFM\"]:\n",
        "        required_parameters = [\n",
        "            \"FIELD_COUNT\",\n",
        "            \"FEATURE_COUNT\",\n",
        "            \"method\",\n",
        "            \"dim\",\n",
        "            \"layer_sizes\",\n",
        "            \"cross_layer_sizes\",\n",
        "            \"activation\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "    if f_config[\"model_type\"] in [\"gru4rec\", \"GRU4REC\", \"GRU4Rec\"]:\n",
        "        required_parameters = [\n",
        "            \"item_embedding_dim\",\n",
        "            \"cate_embedding_dim\",\n",
        "            \"max_seq_length\",\n",
        "            \"loss\",\n",
        "            \"method\",\n",
        "            \"user_vocab\",\n",
        "            \"item_vocab\",\n",
        "            \"cate_vocab\",\n",
        "            \"hidden_size\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"caser\", \"CASER\", \"Caser\"]:\n",
        "        required_parameters = [\n",
        "            \"item_embedding_dim\",\n",
        "            \"cate_embedding_dim\",\n",
        "            \"user_embedding_dim\",\n",
        "            \"max_seq_length\",\n",
        "            \"loss\",\n",
        "            \"method\",\n",
        "            \"user_vocab\",\n",
        "            \"item_vocab\",\n",
        "            \"cate_vocab\",\n",
        "            \"T\",\n",
        "            \"L\",\n",
        "            \"n_v\",\n",
        "            \"n_h\",\n",
        "            \"min_seq_length\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"asvd\", \"ASVD\", \"a2svd\", \"A2SVD\"]:\n",
        "        required_parameters = [\n",
        "            \"item_embedding_dim\",\n",
        "            \"cate_embedding_dim\",\n",
        "            \"max_seq_length\",\n",
        "            \"loss\",\n",
        "            \"method\",\n",
        "            \"user_vocab\",\n",
        "            \"item_vocab\",\n",
        "            \"cate_vocab\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"slirec\", \"sli_rec\", \"SLI_REC\", \"Sli_rec\"]:\n",
        "        required_parameters = [\n",
        "            \"item_embedding_dim\",\n",
        "            \"cate_embedding_dim\",\n",
        "            \"max_seq_length\",\n",
        "            \"loss\",\n",
        "            \"method\",\n",
        "            \"user_vocab\",\n",
        "            \"item_vocab\",\n",
        "            \"cate_vocab\",\n",
        "            \"attention_size\",\n",
        "            \"hidden_size\",\n",
        "            \"att_fcn_layer_sizes\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\n",
        "        \"nextitnet\",\n",
        "        \"next_it_net\",\n",
        "        \"NextItNet\",\n",
        "        \"NEXT_IT_NET\",\n",
        "    ]:\n",
        "        required_parameters = [\n",
        "            \"item_embedding_dim\",\n",
        "            \"cate_embedding_dim\",\n",
        "            \"user_embedding_dim\",\n",
        "            \"max_seq_length\",\n",
        "            \"loss\",\n",
        "            \"method\",\n",
        "            \"user_vocab\",\n",
        "            \"item_vocab\",\n",
        "            \"cate_vocab\",\n",
        "            \"dilations\",\n",
        "            \"kernel_size\",\n",
        "            \"min_seq_length\",\n",
        "        ]\n",
        "    else:\n",
        "        required_parameters = []\n",
        "\n",
        "    # check required parameters\n",
        "    for param in required_parameters:\n",
        "        if param not in f_config:\n",
        "            raise ValueError(\"Parameters {0} must be set\".format(param))\n",
        "\n",
        "    if f_config[\"model_type\"] in [\"exDeepFM\", \"xDeepFM\"]:\n",
        "        if f_config[\"data_format\"] != \"ffm\":\n",
        "            raise ValueError(\n",
        "                \"For xDeepFM model, data format must be 'ffm', but your set is {0}\".format(\n",
        "                    f_config[\"data_format\"]\n",
        "                )\n",
        "            )\n",
        "    elif f_config[\"model_type\"] in [\"dkn\", \"DKN\"]:\n",
        "        if f_config[\"data_format\"] != \"dkn\":\n",
        "            raise ValueError(\n",
        "                \"For dkn model, data format must be 'dkn', but your set is {0}\".format(\n",
        "                    f_config[\"data_format\"]\n",
        "                )\n",
        "            )\n",
        "    check_type(f_config)\n",
        "\n",
        "\n",
        "def load_yaml(filename):\n",
        "    \"\"\"Load a yaml file.\n",
        "    Args:\n",
        "        filename (str): Filename.\n",
        "    Returns:\n",
        "        dict: Dictionary.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, \"r\") as f:\n",
        "            config = yaml.load(f, yaml.SafeLoader)\n",
        "        return config\n",
        "    except FileNotFoundError:  # for file not found\n",
        "        raise\n",
        "    except Exception as e:  # for other exceptions\n",
        "        raise IOError(\"load {0} error!\".format(filename))\n",
        "\n",
        "\n",
        "def create_hparams(flags):\n",
        "    \"\"\"Create the model hyperparameters.\n",
        "    Args:\n",
        "        flags (dict): Dictionary with the model requirements.\n",
        "    Returns:\n",
        "        obj: Hyperparameter object in TF (tf.contrib.training.HParams).\n",
        "    \"\"\"\n",
        "    return tf.contrib.training.HParams(\n",
        "        # data\n",
        "        kg_file=flags[\"kg_file\"] if \"kg_file\" in flags else None,\n",
        "        user_clicks=flags[\"user_clicks\"] if \"user_clicks\" in flags else None,\n",
        "        FEATURE_COUNT=flags[\"FEATURE_COUNT\"] if \"FEATURE_COUNT\" in flags else None,\n",
        "        FIELD_COUNT=flags[\"FIELD_COUNT\"] if \"FIELD_COUNT\" in flags else None,\n",
        "        data_format=flags[\"data_format\"] if \"data_format\" in flags else None,\n",
        "        PAIR_NUM=flags[\"PAIR_NUM\"] if \"PAIR_NUM\" in flags else None,\n",
        "        DNN_FIELD_NUM=flags[\"DNN_FIELD_NUM\"] if \"DNN_FIELD_NUM\" in flags else None,\n",
        "        n_user=flags[\"n_user\"] if \"n_user\" in flags else None,\n",
        "        n_item=flags[\"n_item\"] if \"n_item\" in flags else None,\n",
        "        n_user_attr=flags[\"n_user_attr\"] if \"n_user_attr\" in flags else None,\n",
        "        n_item_attr=flags[\"n_item_attr\"] if \"n_item_attr\" in flags else None,\n",
        "        iterator_type=flags[\"iterator_type\"] if \"iterator_type\" in flags else None,\n",
        "        SUMMARIES_DIR=flags[\"SUMMARIES_DIR\"] if \"SUMMARIES_DIR\" in flags else None,\n",
        "        MODEL_DIR=flags[\"MODEL_DIR\"] if \"MODEL_DIR\" in flags else None,\n",
        "        # dkn\n",
        "        wordEmb_file=flags[\"wordEmb_file\"] if \"wordEmb_file\" in flags else None,\n",
        "        entityEmb_file=flags[\"entityEmb_file\"] if \"entityEmb_file\" in flags else None,\n",
        "        contextEmb_file=flags[\"contextEmb_file\"]\n",
        "        if \"contextEmb_file\" in flags\n",
        "        else None,\n",
        "        news_feature_file=flags[\"news_feature_file\"]\n",
        "        if \"news_feature_file\" in flags\n",
        "        else None,\n",
        "        user_history_file=flags[\"user_history_file\"]\n",
        "        if \"user_history_file\" in flags\n",
        "        else None,\n",
        "        use_entity=flags[\"use_entity\"] if \"use_entity\" in flags else True,\n",
        "        use_context=flags[\"use_context\"] if \"use_context\" in flags else True,\n",
        "        doc_size=flags[\"doc_size\"] if \"doc_size\" in flags else None,\n",
        "        history_size=flags[\"history_size\"] if \"history_size\" in flags else None,\n",
        "        word_size=flags[\"word_size\"] if \"word_size\" in flags else None,\n",
        "        entity_size=flags[\"entity_size\"] if \"entity_size\" in flags else None,\n",
        "        entity_dim=flags[\"entity_dim\"] if \"entity_dim\" in flags else None,\n",
        "        entity_embedding_method=flags[\"entity_embedding_method\"]\n",
        "        if \"entity_embedding_method\" in flags\n",
        "        else None,\n",
        "        transform=flags[\"transform\"] if \"transform\" in flags else None,\n",
        "        train_ratio=flags[\"train_ratio\"] if \"train_ratio\" in flags else None,\n",
        "        # model\n",
        "        dim=flags[\"dim\"] if \"dim\" in flags else None,\n",
        "        layer_sizes=flags[\"layer_sizes\"] if \"layer_sizes\" in flags else None,\n",
        "        cross_layer_sizes=flags[\"cross_layer_sizes\"]\n",
        "        if \"cross_layer_sizes\" in flags\n",
        "        else None,\n",
        "        cross_layers=flags[\"cross_layers\"] if \"cross_layers\" in flags else None,\n",
        "        activation=flags[\"activation\"] if \"activation\" in flags else None,\n",
        "        cross_activation=flags[\"cross_activation\"]\n",
        "        if \"cross_activation\" in flags\n",
        "        else \"identity\",\n",
        "        user_dropout=flags[\"user_dropout\"] if \"user_dropout\" in flags else False,\n",
        "        dropout=flags[\"dropout\"] if \"dropout\" in flags else [0.0],\n",
        "        attention_layer_sizes=flags[\"attention_layer_sizes\"]\n",
        "        if \"attention_layer_sizes\" in flags\n",
        "        else None,\n",
        "        attention_activation=flags[\"attention_activation\"]\n",
        "        if \"attention_activation\" in flags\n",
        "        else None,\n",
        "        attention_dropout=flags[\"attention_dropout\"]\n",
        "        if \"attention_dropout\" in flags\n",
        "        else 0.0,\n",
        "        model_type=flags[\"model_type\"] if \"model_type\" in flags else None,\n",
        "        method=flags[\"method\"] if \"method\" in flags else None,\n",
        "        load_saved_model=flags[\"load_saved_model\"]\n",
        "        if \"load_saved_model\" in flags\n",
        "        else False,\n",
        "        load_model_name=flags[\"load_model_name\"]\n",
        "        if \"load_model_name\" in flags\n",
        "        else None,\n",
        "        filter_sizes=flags[\"filter_sizes\"] if \"filter_sizes\" in flags else None,\n",
        "        num_filters=flags[\"num_filters\"] if \"num_filters\" in flags else None,\n",
        "        mu=flags[\"mu\"] if \"mu\" in flags else None,\n",
        "        fast_CIN_d=flags[\"fast_CIN_d\"] if \"fast_CIN_d\" in flags else 0,\n",
        "        use_Linear_part=flags[\"use_Linear_part\"]\n",
        "        if \"use_Linear_part\" in flags\n",
        "        else False,\n",
        "        use_FM_part=flags[\"use_FM_part\"] if \"use_FM_part\" in flags else False,\n",
        "        use_CIN_part=flags[\"use_CIN_part\"] if \"use_CIN_part\" in flags else False,\n",
        "        use_DNN_part=flags[\"use_DNN_part\"] if \"use_DNN_part\" in flags else False,\n",
        "        # train\n",
        "        init_method=flags[\"init_method\"] if \"init_method\" in flags else \"tnormal\",\n",
        "        init_value=flags[\"init_value\"] if \"init_value\" in flags else 0.01,\n",
        "        embed_l2=flags[\"embed_l2\"] if \"embed_l2\" in flags else 0.0000,\n",
        "        embed_l1=flags[\"embed_l1\"] if \"embed_l1\" in flags else 0.0000,\n",
        "        layer_l2=flags[\"layer_l2\"] if \"layer_l2\" in flags else 0.0000,\n",
        "        layer_l1=flags[\"layer_l1\"] if \"layer_l1\" in flags else 0.0000,\n",
        "        cross_l2=flags[\"cross_l2\"] if \"cross_l2\" in flags else 0.0000,\n",
        "        cross_l1=flags[\"cross_l1\"] if \"cross_l1\" in flags else 0.0000,\n",
        "        reg_kg=flags[\"reg_kg\"] if \"reg_kg\" in flags else 0.0000,\n",
        "        learning_rate=flags[\"learning_rate\"] if \"learning_rate\" in flags else 0.001,\n",
        "        lr_rs=flags[\"lr_rs\"] if \"lr_rs\" in flags else 1,\n",
        "        lr_kg=flags[\"lr_kg\"] if \"lr_kg\" in flags else 0.5,\n",
        "        kg_training_interval=flags[\"kg_training_interval\"]\n",
        "        if \"kg_training_interval\" in flags\n",
        "        else 5,\n",
        "        max_grad_norm=flags[\"max_grad_norm\"] if \"max_grad_norm\" in flags else 2,\n",
        "        is_clip_norm=flags[\"is_clip_norm\"] if \"is_clip_norm\" in flags else 0,\n",
        "        dtype=flags[\"dtype\"] if \"dtype\" in flags else 32,\n",
        "        loss=flags[\"loss\"] if \"loss\" in flags else None,\n",
        "        optimizer=flags[\"optimizer\"] if \"optimizer\" in flags else \"adam\",\n",
        "        epochs=flags[\"epochs\"] if \"epochs\" in flags else 10,\n",
        "        batch_size=flags[\"batch_size\"] if \"batch_size\" in flags else 1,\n",
        "        enable_BN=flags[\"enable_BN\"] if \"enable_BN\" in flags else False,\n",
        "        # show info\n",
        "        show_step=flags[\"show_step\"] if \"show_step\" in flags else 1,\n",
        "        save_model=flags[\"save_model\"] if \"save_model\" in flags else True,\n",
        "        save_epoch=flags[\"save_epoch\"] if \"save_epoch\" in flags else 5,\n",
        "        metrics=flags[\"metrics\"] if \"metrics\" in flags else None,\n",
        "        write_tfevents=flags[\"write_tfevents\"] if \"write_tfevents\" in flags else False,\n",
        "        # sequential\n",
        "        item_embedding_dim=flags[\"item_embedding_dim\"]\n",
        "        if \"item_embedding_dim\" in flags\n",
        "        else None,\n",
        "        cate_embedding_dim=flags[\"cate_embedding_dim\"]\n",
        "        if \"cate_embedding_dim\" in flags\n",
        "        else None,\n",
        "        user_embedding_dim=flags[\"user_embedding_dim\"]\n",
        "        if \"user_embedding_dim\" in flags\n",
        "        else None,\n",
        "        train_num_ngs=flags[\"train_num_ngs\"] if \"train_num_ngs\" in flags else 4,\n",
        "        need_sample=flags[\"need_sample\"] if \"need_sample\" in flags else True,\n",
        "        embedding_dropout=flags[\"embedding_dropout\"]\n",
        "        if \"embedding_dropout\" in flags\n",
        "        else 0.0,\n",
        "        user_vocab=flags[\"user_vocab\"] if \"user_vocab\" in flags else None,\n",
        "        item_vocab=flags[\"item_vocab\"] if \"item_vocab\" in flags else None,\n",
        "        cate_vocab=flags[\"cate_vocab\"] if \"cate_vocab\" in flags else None,\n",
        "        pairwise_metrics=flags[\"pairwise_metrics\"]\n",
        "        if \"pairwise_metrics\" in flags\n",
        "        else None,\n",
        "        EARLY_STOP=flags[\"EARLY_STOP\"] if \"EARLY_STOP\" in flags else 100,\n",
        "        # gru4rec\n",
        "        max_seq_length=flags[\"max_seq_length\"] if \"max_seq_length\" in flags else None,\n",
        "        hidden_size=flags[\"hidden_size\"] if \"hidden_size\" in flags else None,\n",
        "        # caser,\n",
        "        L=flags[\"L\"] if \"L\" in flags else None,\n",
        "        T=flags[\"T\"] if \"T\" in flags else None,\n",
        "        n_v=flags[\"n_v\"] if \"n_v\" in flags else None,\n",
        "        n_h=flags[\"n_h\"] if \"n_h\" in flags else None,\n",
        "        min_seq_length=flags[\"min_seq_length\"] if \"min_seq_length\" in flags else 1,\n",
        "        # sli_rec\n",
        "        attention_size=flags[\"attention_size\"] if \"attention_size\" in flags else None,\n",
        "        att_fcn_layer_sizes=flags[\"att_fcn_layer_sizes\"]\n",
        "        if \"att_fcn_layer_sizes\" in flags\n",
        "        else None,\n",
        "        # nextitnet\n",
        "        dilations=flags[\"dilations\"] if \"dilations\" in flags else None,\n",
        "        kernel_size=flags[\"kernel_size\"] if \"kernel_size\" in flags else None,\n",
        "        # lightgcn\n",
        "        embed_size=flags[\"embed_size\"] if \"embed_size\" in flags else None,\n",
        "        n_layers=flags[\"n_layers\"] if \"n_layers\" in flags else None,\n",
        "        decay=flags[\"decay\"] if \"decay\" in flags else None,\n",
        "        eval_epoch=flags[\"eval_epoch\"] if \"eval_epoch\" in flags else None,\n",
        "        top_k=flags[\"top_k\"] if \"top_k\" in flags else None,\n",
        "        # sum\n",
        "        slots=flags[\"slots\"] if \"slots\" in flags else 5,\n",
        "        cell=flags[\"cell\"] if \"cell\" in flags else \"SUM\",\n",
        "    )\n",
        "\n",
        "\n",
        "def prepare_hparams(yaml_file=None, **kwargs):\n",
        "    \"\"\"Prepare the model hyperparameters and check that all have the correct value.\n",
        "    Args:\n",
        "        yaml_file (str): YAML file as configuration.\n",
        "    Returns:\n",
        "        obj: Hyperparameter object in TF (tf.contrib.training.HParams).\n",
        "    \"\"\"\n",
        "    if yaml_file is not None:\n",
        "        config = load_yaml(yaml_file)\n",
        "        config = flat_config(config)\n",
        "    else:\n",
        "        config = {}\n",
        "\n",
        "    if kwargs:\n",
        "        for name, value in kwargs.items():\n",
        "            config[name] = value\n",
        "\n",
        "    check_nn_config(config)\n",
        "    return create_hparams(config)\n",
        "\n",
        "\n",
        "def download_deeprec_resources(azure_container_url, data_path, remote_resource_name):\n",
        "    \"\"\"Download resources.\n",
        "    Args:\n",
        "        azure_container_url (str): URL of Azure container.\n",
        "        data_path (str): Path to download the resources.\n",
        "        remote_resource_name (str): Name of the resource.\n",
        "    \"\"\"\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "    remote_path = azure_container_url + remote_resource_name\n",
        "    maybe_download(remote_path, remote_resource_name, data_path)\n",
        "    zip_ref = zipfile.ZipFile(os.path.join(data_path, remote_resource_name), \"r\")\n",
        "    zip_ref.extractall(data_path)\n",
        "    zip_ref.close()\n",
        "    os.remove(os.path.join(data_path, remote_resource_name))\n",
        "\n",
        "\n",
        "def mrr_score(y_true, y_score):\n",
        "    \"\"\"Computing mrr score metric.\n",
        "    Args:\n",
        "        y_true (np.ndarray): ground-truth labels.\n",
        "        y_score (np.ndarray): predicted labels.\n",
        "    \n",
        "    Returns:\n",
        "        np.ndarray: mrr scores.\n",
        "    \"\"\"\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order)\n",
        "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
        "    return np.sum(rr_score) / np.sum(y_true)\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_score, k=10):\n",
        "    \"\"\"Computing ndcg score metric at k.\n",
        "    Args:\n",
        "        y_true (np.ndarray): ground-truth labels.\n",
        "        y_score (np.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        np.ndarray: ndcg scores.\n",
        "    \"\"\"\n",
        "    best = dcg_score(y_true, y_true, k)\n",
        "    actual = dcg_score(y_true, y_score, k)\n",
        "    return actual / best\n",
        "\n",
        "\n",
        "def hit_score(y_true, y_score, k=10):\n",
        "    \"\"\"Computing hit score metric at k.\n",
        "    Args:\n",
        "        y_true (np.ndarray): ground-truth labels.\n",
        "        y_score (np.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        np.ndarray: hit score.\n",
        "    \"\"\"\n",
        "    ground_truth = np.where(y_true == 1)[0]\n",
        "    argsort = np.argsort(y_score)[::-1][:k]\n",
        "    for idx in argsort:\n",
        "        if idx in ground_truth:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def dcg_score(y_true, y_score, k=10):\n",
        "    \"\"\"Computing dcg score metric at k.\n",
        "    Args:\n",
        "        y_true (np.ndarray): ground-truth labels.\n",
        "        y_score (np.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        np.ndarray: dcg scores.\n",
        "    \"\"\"\n",
        "    k = min(np.shape(y_true)[-1], k)\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gains = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gains / discounts)\n",
        "\n",
        "\n",
        "def cal_metric(labels, preds, metrics):\n",
        "    \"\"\"Calculate metrics,such as auc, logloss.\n",
        "    \n",
        "    FIXME: \n",
        "        refactor this with the reco metrics and make it explicit.\n",
        "    \"\"\"\n",
        "    res = {}\n",
        "    for metric in metrics:\n",
        "        if metric == \"auc\":\n",
        "            auc = roc_auc_score(np.asarray(labels), np.asarray(preds))\n",
        "            res[\"auc\"] = round(auc, 4)\n",
        "        elif metric == \"rmse\":\n",
        "            rmse = mean_squared_error(np.asarray(labels), np.asarray(preds))\n",
        "            res[\"rmse\"] = np.sqrt(round(rmse, 4))\n",
        "        elif metric == \"logloss\":\n",
        "            # avoid logloss nan\n",
        "            preds = [max(min(p, 1.0 - 10e-12), 10e-12) for p in preds]\n",
        "            logloss = log_loss(np.asarray(labels), np.asarray(preds))\n",
        "            res[\"logloss\"] = round(logloss, 4)\n",
        "        elif metric == \"acc\":\n",
        "            pred = np.asarray(preds)\n",
        "            pred[pred >= 0.5] = 1\n",
        "            pred[pred < 0.5] = 0\n",
        "            acc = accuracy_score(np.asarray(labels), pred)\n",
        "            res[\"acc\"] = round(acc, 4)\n",
        "        elif metric == \"f1\":\n",
        "            pred = np.asarray(preds)\n",
        "            pred[pred >= 0.5] = 1\n",
        "            pred[pred < 0.5] = 0\n",
        "            f1 = f1_score(np.asarray(labels), pred)\n",
        "            res[\"f1\"] = round(f1, 4)\n",
        "        elif metric == \"mean_mrr\":\n",
        "            mean_mrr = np.mean(\n",
        "                [\n",
        "                    mrr_score(each_labels, each_preds)\n",
        "                    for each_labels, each_preds in zip(labels, preds)\n",
        "                ]\n",
        "            )\n",
        "            res[\"mean_mrr\"] = round(mean_mrr, 4)\n",
        "        elif metric.startswith(\"ndcg\"):  # format like:  ndcg@2;4;6;8\n",
        "            ndcg_list = [1, 2]\n",
        "            ks = metric.split(\"@\")\n",
        "            if len(ks) > 1:\n",
        "                ndcg_list = [int(token) for token in ks[1].split(\";\")]\n",
        "            for k in ndcg_list:\n",
        "                ndcg_temp = np.mean(\n",
        "                    [\n",
        "                        ndcg_score(each_labels, each_preds, k)\n",
        "                        for each_labels, each_preds in zip(labels, preds)\n",
        "                    ]\n",
        "                )\n",
        "                res[\"ndcg@{0}\".format(k)] = round(ndcg_temp, 4)\n",
        "        elif metric.startswith(\"hit\"):  # format like:  hit@2;4;6;8\n",
        "            hit_list = [1, 2]\n",
        "            ks = metric.split(\"@\")\n",
        "            if len(ks) > 1:\n",
        "                hit_list = [int(token) for token in ks[1].split(\";\")]\n",
        "            for k in hit_list:\n",
        "                hit_temp = np.mean(\n",
        "                    [\n",
        "                        hit_score(each_labels, each_preds, k)\n",
        "                        for each_labels, each_preds in zip(labels, preds)\n",
        "                    ]\n",
        "                )\n",
        "                res[\"hit@{0}\".format(k)] = round(hit_temp, 4)\n",
        "        elif metric == \"group_auc\":\n",
        "            group_auc = np.mean(\n",
        "                [\n",
        "                    roc_auc_score(each_labels, each_preds)\n",
        "                    for each_labels, each_preds in zip(labels, preds)\n",
        "                ]\n",
        "            )\n",
        "            res[\"group_auc\"] = round(group_auc, 4)\n",
        "        else:\n",
        "            raise ValueError(\"not define this metric {0}\".format(metric))\n",
        "    return res\n",
        "\n",
        "\n",
        "def load_dict(filename):\n",
        "    \"\"\"Load the vocabularies.\n",
        "    Args:\n",
        "        filename (str): Filename of user, item or category vocabulary.\n",
        "    Returns:\n",
        "        dict: A saved vocabulary.\n",
        "    \"\"\"\n",
        "    with open(filename, \"rb\") as f:\n",
        "        f_pkl = pkl.load(f)\n",
        "        return f_pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6YZmSPR7X9C"
      },
      "source": [
        "# BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19UL7dF9kSea"
      },
      "source": [
        "from os.path import join\n",
        "import abc\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "__all__ = [\"BaseModel\"]\n",
        "\n",
        "\n",
        "class BaseModel:\n",
        "    \"\"\"Basic class of models\n",
        "    Attributes:\n",
        "        hparams (obj): A tf.contrib.training.HParams object, hold the entire set of hyperparameters.\n",
        "        iterator_creator_train (obj): An iterator to load the data in training steps.\n",
        "        iterator_creator_train (obj): An iterator to load the data in testing steps.\n",
        "        graph (obj): An optional graph.\n",
        "        seed (int): Random seed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hparams,\n",
        "        iterator_creator,\n",
        "        seed=None,\n",
        "    ):\n",
        "        \"\"\"Initializing the model. Create common logics which are needed by all deeprec models, such as loss function,\n",
        "        parameter set.\n",
        "        Args:\n",
        "            hparams (obj): A tf.contrib.training.HParams object, hold the entire set of hyperparameters.\n",
        "            iterator_creator_train (obj): An iterator to load the data in training steps.\n",
        "            iterator_creator_train (obj): An iterator to load the data in testing steps.\n",
        "            graph (obj): An optional graph.\n",
        "            seed (int): Random seed.\n",
        "        \"\"\"\n",
        "        self.seed = seed\n",
        "        tf.compat.v1.set_random_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.train_iterator = iterator_creator(\n",
        "            hparams,\n",
        "            hparams.npratio,\n",
        "            col_spliter=\"\\t\",\n",
        "        )\n",
        "        self.test_iterator = iterator_creator(\n",
        "            hparams,\n",
        "            col_spliter=\"\\t\",\n",
        "        )\n",
        "\n",
        "        self.hparams = hparams\n",
        "        self.support_quick_scoring = hparams.support_quick_scoring\n",
        "\n",
        "        # set GPU use with on demand growth\n",
        "        gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
        "        sess = tf.compat.v1.Session(\n",
        "            config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
        "        )\n",
        "\n",
        "        # set this TensorFlow session as the default session for Keras\n",
        "        tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "        # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras!\n",
        "        # Otherwise, their weights will be unavailable in the threads after the session there has been set\n",
        "        self.model, self.scorer = self._build_graph()\n",
        "\n",
        "        self.loss = self._get_loss()\n",
        "        self.train_optimizer = self._get_opt()\n",
        "\n",
        "        self.model.compile(loss=self.loss, optimizer=self.train_optimizer)\n",
        "\n",
        "    def _init_embedding(self, file_path):\n",
        "        \"\"\"Load pre-trained embeddings as a constant tensor.\n",
        "        Args:\n",
        "            file_path (str): the pre-trained glove embeddings file path.\n",
        "        Returns:\n",
        "            np.array: A constant numpy array.\n",
        "        \"\"\"\n",
        "\n",
        "        return np.load(file_path)\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _build_graph(self):\n",
        "        \"\"\"Subclass will implement this.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _get_input_label_from_iter(self, batch_data):\n",
        "        \"\"\"Subclass will implement this\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _get_loss(self):\n",
        "        \"\"\"Make loss function, consists of data loss and regularization loss\n",
        "        Returns:\n",
        "            obj: Loss function or loss function name\n",
        "        \"\"\"\n",
        "        if self.hparams.loss == \"cross_entropy_loss\":\n",
        "            data_loss = \"categorical_crossentropy\"\n",
        "        elif self.hparams.loss == \"log_loss\":\n",
        "            data_loss = \"binary_crossentropy\"\n",
        "        else:\n",
        "            raise ValueError(\"this loss not defined {0}\".format(self.hparams.loss))\n",
        "        return data_loss\n",
        "\n",
        "    def _get_opt(self):\n",
        "        \"\"\"Get the optimizer according to configuration. Usually we will use Adam.\n",
        "        Returns:\n",
        "            obj: An optimizer.\n",
        "        \"\"\"\n",
        "        lr = self.hparams.learning_rate\n",
        "        optimizer = self.hparams.optimizer\n",
        "\n",
        "        if optimizer == \"adam\":\n",
        "            train_opt = keras.optimizers.Adam(lr=lr)\n",
        "\n",
        "        return train_opt\n",
        "\n",
        "    def _get_pred(self, logit, task):\n",
        "        \"\"\"Make final output as prediction score, according to different tasks.\n",
        "        Args:\n",
        "            logit (obj): Base prediction value.\n",
        "            task (str): A task (values: regression/classification)\n",
        "        Returns:\n",
        "            obj: Transformed score\n",
        "        \"\"\"\n",
        "        if task == \"regression\":\n",
        "            pred = tf.identity(logit)\n",
        "        elif task == \"classification\":\n",
        "            pred = tf.sigmoid(logit)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"method must be regression or classification, but now is {0}\".format(\n",
        "                    task\n",
        "                )\n",
        "            )\n",
        "        return pred\n",
        "\n",
        "    def train(self, train_batch_data):\n",
        "        \"\"\"Go through the optimization step once with training data in feed_dict.\n",
        "        Args:\n",
        "            sess (obj): The model session object.\n",
        "            feed_dict (dict): Feed values to train the model. This is a dictionary that maps graph elements to values.\n",
        "        Returns:\n",
        "            list: A list of values, including update operation, total loss, data loss, and merged summary.\n",
        "        \"\"\"\n",
        "        train_input, train_label = self._get_input_label_from_iter(train_batch_data)\n",
        "        rslt = self.model.train_on_batch(train_input, train_label)\n",
        "        return rslt\n",
        "\n",
        "    def eval(self, eval_batch_data):\n",
        "        \"\"\"Evaluate the data in feed_dict with current model.\n",
        "        Args:\n",
        "            sess (obj): The model session object.\n",
        "            feed_dict (dict): Feed values for evaluation. This is a dictionary that maps graph elements to values.\n",
        "        Returns:\n",
        "            list: A list of evaluated results, including total loss value, data loss value,\n",
        "                predicted scores, and ground-truth labels.\n",
        "        \"\"\"\n",
        "        eval_input, eval_label = self._get_input_label_from_iter(eval_batch_data)\n",
        "        imp_index = eval_batch_data[\"impression_index_batch\"]\n",
        "\n",
        "        pred_rslt = self.scorer.predict_on_batch(eval_input)\n",
        "\n",
        "        return pred_rslt, eval_label, imp_index\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        train_news_file,\n",
        "        train_behaviors_file,\n",
        "        valid_news_file,\n",
        "        valid_behaviors_file,\n",
        "        test_news_file=None,\n",
        "        test_behaviors_file=None,\n",
        "    ):\n",
        "        \"\"\"Fit the model with train_file. Evaluate the model on valid_file per epoch to observe the training status.\n",
        "        If test_news_file is not None, evaluate it too.\n",
        "        Args:\n",
        "            train_file (str): training data set.\n",
        "            valid_file (str): validation set.\n",
        "            test_news_file (str): test set.\n",
        "        Returns:\n",
        "            obj: An instance of self.\n",
        "        \"\"\"\n",
        "        losses = {'train': list(), 'eval': list(), 'test': list()}\n",
        "        for epoch in range(1, self.hparams.epochs + 1):\n",
        "            step = 0\n",
        "            self.hparams.current_epoch = epoch\n",
        "            epoch_loss = 0\n",
        "            train_start = time.time()\n",
        "\n",
        "            tqdm_util = tqdm(\n",
        "                self.train_iterator.load_data_from_file(\n",
        "                    train_news_file, train_behaviors_file\n",
        "                )\n",
        "            )\n",
        "\n",
        "            for batch_data_input in tqdm_util:\n",
        "\n",
        "                step_result = self.train(batch_data_input)\n",
        "                step_data_loss = step_result\n",
        "\n",
        "                epoch_loss += step_data_loss\n",
        "                step += 1\n",
        "                if step % self.hparams.show_step == 0:\n",
        "                    tqdm_util.set_description(\n",
        "                        \"step {0:d} , total_loss: {1:.4f}, data_loss: {2:.4f}\".format(\n",
        "                            step, epoch_loss / step, step_data_loss\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            train_end = time.time()\n",
        "            train_time = train_end - train_start\n",
        "\n",
        "            eval_start = time.time()\n",
        "\n",
        "            train_info = \",\".join(\n",
        "                [\n",
        "                    str(item[0]) + \":\" + str(item[1])\n",
        "                    for item in [(\"logloss loss\", epoch_loss / step)]\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            eval_res = self.run_eval(valid_news_file, valid_behaviors_file)\n",
        "            eval_info = \", \".join(\n",
        "                [\n",
        "                    str(item[0]) + \":\" + str(item[1])\n",
        "                    for item in sorted(eval_res.items(), key=lambda x: x[0])\n",
        "                ]\n",
        "            )\n",
        "            if test_news_file is not None:\n",
        "                test_res = self.run_eval(test_news_file, test_behaviors_file)\n",
        "                test_info = \", \".join(\n",
        "                    [\n",
        "                        str(item[0]) + \":\" + str(item[1])\n",
        "                        for item in sorted(test_res.items(), key=lambda x: x[0])\n",
        "                    ]\n",
        "                )\n",
        "            eval_end = time.time()\n",
        "            eval_time = eval_end - eval_start\n",
        "\n",
        "            if test_news_file is not None:\n",
        "                print(\n",
        "                    \"at epoch {0:d}\".format(epoch)\n",
        "                    + \"\\ntrain info: \"\n",
        "                    + train_info\n",
        "                    + \"\\neval info: \"\n",
        "                    + eval_info\n",
        "                    + \"\\ntest info: \"\n",
        "                    + test_info\n",
        "                )\n",
        "            else:\n",
        "                print(\n",
        "                    \"at epoch {0:d}\".format(epoch)\n",
        "                    + \"\\ntrain info: \"\n",
        "                    + train_info\n",
        "                    + \"\\neval info: \"\n",
        "                    + eval_info\n",
        "                )\n",
        "            print(\n",
        "                \"at epoch {0:d} , train time: {1:.1f} eval time: {2:.1f}\".format(\n",
        "                    epoch, train_time, eval_time\n",
        "                )\n",
        "            )\n",
        "            losses['train'].append(train_info)\n",
        "            losses['eval'].append(eval_info)\n",
        "        self.history_loss = losses\n",
        "        return self\n",
        "\n",
        "    def group_labels(self, labels, preds, group_keys):\n",
        "        \"\"\"Devide labels and preds into several group according to values in group keys.\n",
        "        Args:\n",
        "            labels (list): ground truth label list.\n",
        "            preds (list): prediction score list.\n",
        "            group_keys (list): group key list.\n",
        "        Returns:\n",
        "            all_labels: labels after group.\n",
        "            all_preds: preds after group.\n",
        "        \"\"\"\n",
        "\n",
        "        all_keys = list(set(group_keys))\n",
        "        all_keys.sort()\n",
        "        group_labels = {k: [] for k in all_keys}\n",
        "        group_preds = {k: [] for k in all_keys}\n",
        "\n",
        "        for l, p, k in zip(labels, preds, group_keys):\n",
        "            group_labels[k].append(l)\n",
        "            group_preds[k].append(p)\n",
        "\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for k in all_keys:\n",
        "            all_labels.append(group_labels[k])\n",
        "            all_preds.append(group_preds[k])\n",
        "\n",
        "        return all_keys, all_labels, all_preds\n",
        "\n",
        "    def run_eval(self, news_filename, behaviors_file):\n",
        "        \"\"\"Evaluate the given file and returns some evaluation metrics.\n",
        "        Args:\n",
        "            filename (str): A file name that will be evaluated.\n",
        "        Returns:\n",
        "            dict: A dictionary contains evaluation metrics.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.support_quick_scoring:\n",
        "            _, group_labels, group_preds = self.run_fast_eval(\n",
        "                news_filename, behaviors_file\n",
        "            )\n",
        "        else:\n",
        "            _, group_labels, group_preds = self.run_slow_eval(\n",
        "                news_filename, behaviors_file\n",
        "            )\n",
        "        res = cal_metric(group_labels, group_preds, self.hparams.metrics)\n",
        "        return res\n",
        "\n",
        "    def user(self, batch_user_input):\n",
        "        user_input = self._get_user_feature_from_iter(batch_user_input)\n",
        "        user_vec = self.userencoder.predict_on_batch(user_input)\n",
        "        user_index = batch_user_input[\"impr_index_batch\"]\n",
        "\n",
        "        return user_index, user_vec\n",
        "\n",
        "    def news(self, batch_news_input):\n",
        "        news_input = self._get_news_feature_from_iter(batch_news_input)\n",
        "        news_vec = self.newsencoder.predict_on_batch(news_input)\n",
        "        news_index = batch_news_input[\"news_index_batch\"]\n",
        "\n",
        "        return news_index, news_vec\n",
        "\n",
        "    def run_user(self, news_filename, behaviors_file):\n",
        "        if not hasattr(self, \"userencoder\"):\n",
        "            raise ValueError(\"model must have attribute userencoder\")\n",
        "\n",
        "        user_indexes = []\n",
        "        user_vecs = []\n",
        "        for batch_data_input in tqdm(\n",
        "            self.test_iterator.load_user_from_file(news_filename, behaviors_file)\n",
        "        ):\n",
        "            user_index, user_vec = self.user(batch_data_input)\n",
        "            user_indexes.extend(np.reshape(user_index, -1))\n",
        "            user_vecs.extend(user_vec)\n",
        "\n",
        "        return dict(zip(user_indexes, user_vecs))\n",
        "\n",
        "    def run_news(self, news_filename):\n",
        "        if not hasattr(self, \"newsencoder\"):\n",
        "            raise ValueError(\"model must have attribute newsencoder\")\n",
        "\n",
        "        news_indexes = []\n",
        "        news_vecs = []\n",
        "        for batch_data_input in tqdm(\n",
        "            self.test_iterator.load_news_from_file(news_filename)\n",
        "        ):\n",
        "            news_index, news_vec = self.news(batch_data_input)\n",
        "            news_indexes.extend(np.reshape(news_index, -1))\n",
        "            news_vecs.extend(news_vec)\n",
        "\n",
        "        return dict(zip(news_indexes, news_vecs))\n",
        "\n",
        "    def run_slow_eval(self, news_filename, behaviors_file):\n",
        "        preds = []\n",
        "        labels = []\n",
        "        imp_indexes = []\n",
        "\n",
        "        for batch_data_input in tqdm(\n",
        "            self.test_iterator.load_data_from_file(news_filename, behaviors_file)\n",
        "        ):\n",
        "            step_pred, step_labels, step_imp_index = self.eval(batch_data_input)\n",
        "            preds.extend(np.reshape(step_pred, -1))\n",
        "            labels.extend(np.reshape(step_labels, -1))\n",
        "            imp_indexes.extend(np.reshape(step_imp_index, -1))\n",
        "\n",
        "        group_impr_indexes, group_labels, group_preds = self.group_labels(\n",
        "            labels, preds, imp_indexes\n",
        "        )\n",
        "        return group_impr_indexes, group_labels, group_preds\n",
        "\n",
        "    def run_fast_eval(self, news_filename, behaviors_file):\n",
        "        news_vecs = self.run_news(news_filename)\n",
        "        user_vecs = self.run_user(news_filename, behaviors_file)\n",
        "\n",
        "        self.news_vecs = news_vecs\n",
        "        self.user_vecs = user_vecs\n",
        "\n",
        "        group_impr_indexes = []\n",
        "        group_labels = []\n",
        "        group_preds = []\n",
        "\n",
        "        for (\n",
        "            impr_index,\n",
        "            news_index,\n",
        "            user_index,\n",
        "            label,\n",
        "        ) in tqdm(self.test_iterator.load_impression_from_file(behaviors_file)):\n",
        "            pred = np.dot(\n",
        "                np.stack([news_vecs[i] for i in news_index], axis=0),\n",
        "                user_vecs[impr_index],\n",
        "            )\n",
        "            group_impr_indexes.append(impr_index)\n",
        "            group_labels.append(label)\n",
        "            group_preds.append(pred)\n",
        "\n",
        "        return group_impr_indexes, group_labels, group_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsaCYuHkkn0K"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "class AttLayer2(layers.Layer):\n",
        "    \"\"\"Soft alignment attention implement.\n",
        "    Attributes:\n",
        "        dim (int): attention hidden dim\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim=200, seed=0, **kwargs):\n",
        "        \"\"\"Initialization steps for AttLayer2.\n",
        "        \n",
        "        Args:\n",
        "            dim (int): attention hidden dim\n",
        "        \"\"\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.seed = seed\n",
        "        super(AttLayer2, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Initialization for variables in AttLayer2\n",
        "        There are there variables in AttLayer2, i.e. W, b and q.\n",
        "        Args:\n",
        "            input_shape (obj): shape of input tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(input_shape) == 3\n",
        "        dim = self.dim\n",
        "        self.W = self.add_weight(\n",
        "            name=\"W\",\n",
        "            shape=(int(input_shape[-1]), dim),\n",
        "            initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name=\"b\",\n",
        "            shape=(dim,),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.q = self.add_weight(\n",
        "            name=\"q\",\n",
        "            shape=(dim, 1),\n",
        "            initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            trainable=True,\n",
        "        )\n",
        "        super(AttLayer2, self).build(input_shape)  # be sure you call this somewhere!\n",
        "\n",
        "    def call(self, inputs, mask=None, **kwargs):\n",
        "        \"\"\"Core implemention of soft attention\n",
        "        Args:\n",
        "            inputs (obj): input tensor.\n",
        "        Returns:\n",
        "            obj: weighted sum of input tensors.\n",
        "        \"\"\"\n",
        "\n",
        "        attention = K.tanh(K.dot(inputs, self.W) + self.b)\n",
        "        attention = K.dot(attention, self.q)\n",
        "\n",
        "        attention = K.squeeze(attention, axis=2)\n",
        "\n",
        "        if mask == None:\n",
        "            attention = K.exp(attention)\n",
        "        else:\n",
        "            attention = K.exp(attention) * K.cast(mask, dtype=\"float32\")\n",
        "            \n",
        "        attention_weight = attention / (\n",
        "            K.sum(attention, axis=-1, keepdims=True) + K.epsilon()\n",
        "        )\n",
        "\n",
        "        attention_weight = K.expand_dims(attention_weight)\n",
        "        weighted_input = inputs * attention_weight\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        \"\"\"Compte output mask value\n",
        "        Args: \n",
        "            input (obj): input tensor.\n",
        "            input_mask: input mask\n",
        "        \n",
        "        Returns:\n",
        "            obj: output mask.\n",
        "        \"\"\"\n",
        "        return None\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Compute shape of output tensor\n",
        "        Args:\n",
        "            input_shape (tuple): shape of input tensor.\n",
        "        \n",
        "        Returns:\n",
        "            tuple: shape of output tensor.\n",
        "        \"\"\"\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "\n",
        "class SelfAttention(layers.Layer):\n",
        "    \"\"\"Multi-head self attention implement.\n",
        "    Args:\n",
        "        multiheads (int): The number of heads.\n",
        "        head_dim(obj): Dimention of each head.\n",
        "        mask_right(boolean): whether to mask right words.\n",
        "    Returns:\n",
        "        obj: Weighted sum after attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, multiheads, head_dim, seed=0, mask_right=False, **kwargs):\n",
        "        \"\"\"Initialization steps for AttLayer2.\n",
        "        \n",
        "        Args:\n",
        "            multiheads (int): The number of heads.\n",
        "            head_dim(obj): Dimention of each head.\n",
        "            mask_right(boolean): whether to mask right words.\n",
        "        \"\"\"\n",
        "\n",
        "        self.multiheads = multiheads\n",
        "        self.head_dim = head_dim\n",
        "        self.output_dim = multiheads * head_dim\n",
        "        self.mask_right = mask_right\n",
        "        self.seed = seed\n",
        "        super(SelfAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Compute shape of output tensor.\n",
        "        Returns:\n",
        "            tuple: output shape tuple.\n",
        "        \"\"\"\n",
        "\n",
        "        return (input_shape[0][0], input_shape[0][1], self.output_dim)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Initialization for variables in SelfAttention.\n",
        "        There are three variables in SelfAttention, i.e. WQ, WK ans WV.\n",
        "        WQ is used for linear transformation of query.\n",
        "        WK is used for linear transformation of key.\n",
        "        WV is used for linear transformation of value.\n",
        "        Args:\n",
        "            input_shape (obj): shape of input tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        self.WQ = self.add_weight(\n",
        "            name=\"WQ\",\n",
        "            shape=(int(input_shape[0][-1]), self.output_dim),\n",
        "            initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.WK = self.add_weight(\n",
        "            name=\"WK\",\n",
        "            shape=(int(input_shape[1][-1]), self.output_dim),\n",
        "            initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.WV = self.add_weight(\n",
        "            name=\"WV\",\n",
        "            shape=(int(input_shape[2][-1]), self.output_dim),\n",
        "            initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            trainable=True,\n",
        "        )\n",
        "        super(SelfAttention, self).build(input_shape)\n",
        "\n",
        "    def Mask(self, inputs, seq_len, mode=\"add\"):\n",
        "        \"\"\"Mask operation used in multi-head self attention\n",
        "        Args:\n",
        "            seq_len (obj): sequence length of inputs.\n",
        "            mode (str): mode of mask.\n",
        "        \n",
        "        Returns:\n",
        "            obj: tensors after masking.\n",
        "        \"\"\"\n",
        "\n",
        "        if seq_len == None:\n",
        "            return inputs\n",
        "        else:\n",
        "            mask = K.one_hot(indices=seq_len[:, 0], num_classes=K.shape(inputs)[1])\n",
        "            mask = 1 - K.cumsum(mask, axis=1)\n",
        "\n",
        "            for _ in range(len(inputs.shape) - 2):\n",
        "                mask = K.expand_dims(mask, 2)\n",
        "\n",
        "            if mode == \"mul\":\n",
        "                return inputs * mask\n",
        "            elif mode == \"add\":\n",
        "                return inputs - (1 - mask) * 1e12\n",
        "\n",
        "    def call(self, QKVs):\n",
        "        \"\"\"Core logic of multi-head self attention.\n",
        "        Args:\n",
        "            QKVs (list): inputs of multi-head self attention i.e. qeury, key and value.\n",
        "        Returns:\n",
        "            obj: ouput tensors.\n",
        "        \"\"\"\n",
        "        if len(QKVs) == 3:\n",
        "            Q_seq, K_seq, V_seq = QKVs\n",
        "            Q_len, V_len = None, None\n",
        "        elif len(QKVs) == 5:\n",
        "            Q_seq, K_seq, V_seq, Q_len, V_len = QKVs\n",
        "        Q_seq = K.dot(Q_seq, self.WQ)\n",
        "        Q_seq = K.reshape(\n",
        "            Q_seq, shape=(-1, K.shape(Q_seq)[1], self.multiheads, self.head_dim)\n",
        "        )\n",
        "        Q_seq = K.permute_dimensions(Q_seq, pattern=(0, 2, 1, 3))\n",
        "\n",
        "        K_seq = K.dot(K_seq, self.WK)\n",
        "        K_seq = K.reshape(\n",
        "            K_seq, shape=(-1, K.shape(K_seq)[1], self.multiheads, self.head_dim)\n",
        "        )\n",
        "        K_seq = K.permute_dimensions(K_seq, pattern=(0, 2, 1, 3))\n",
        "\n",
        "        V_seq = K.dot(V_seq, self.WV)\n",
        "        V_seq = K.reshape(\n",
        "            V_seq, shape=(-1, K.shape(V_seq)[1], self.multiheads, self.head_dim)\n",
        "        )\n",
        "        V_seq = K.permute_dimensions(V_seq, pattern=(0, 2, 1, 3))\n",
        "\n",
        "        A = K.batch_dot(Q_seq, K_seq, axes=[3, 3]) / K.sqrt(\n",
        "            K.cast(self.head_dim, dtype=\"float32\")\n",
        "        )\n",
        "        A = K.permute_dimensions(\n",
        "            A, pattern=(0, 3, 2, 1)\n",
        "        )  # A.shape=[batch_size,K_sequence_length,Q_sequence_length,self.multiheads]\n",
        "\n",
        "        A = self.Mask(A, V_len, \"add\")\n",
        "        A = K.permute_dimensions(A, pattern=(0, 3, 2, 1))\n",
        "\n",
        "        if self.mask_right:\n",
        "            ones = K.ones_like(A[:1, :1])\n",
        "            lower_triangular = K.tf.matrix_band_part(ones, num_lower=-1, num_upper=0)\n",
        "            mask = (ones - lower_triangular) * 1e12\n",
        "            A = A - mask\n",
        "        A = K.softmax(A)\n",
        "\n",
        "        O_seq = K.batch_dot(A, V_seq, axes=[3, 2])\n",
        "        O_seq = K.permute_dimensions(O_seq, pattern=(0, 2, 1, 3))\n",
        "\n",
        "        O_seq = K.reshape(O_seq, shape=(-1, K.shape(O_seq)[1], self.output_dim))\n",
        "        O_seq = self.Mask(O_seq, Q_len, \"mul\")\n",
        "        return O_seq\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\" add multiheads, multiheads and mask_right into layer config.\n",
        "        Returns:\n",
        "            dict: config of SelfAttention layer.  \n",
        "        \"\"\"\n",
        "        config = super(SelfAttention, self).get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"multiheads\": self.multiheads,\n",
        "                \"head_dim\": self.head_dim,\n",
        "                \"mask_right\": self.mask_right,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "def PersonalizedAttentivePooling(dim1, dim2, dim3, seed=0):\n",
        "    \"\"\"Soft alignment attention implement.\n",
        "    Attributes:\n",
        "        dim1 (int): first dimention of value shape.\n",
        "        dim2 (int): second dimention of value shape.\n",
        "        dim3 (int): shape of query\n",
        "    \n",
        "    Returns:\n",
        "        weighted summary of inputs value.\n",
        "    \"\"\"\n",
        "    vecs_input = keras.Input(shape=(dim1, dim2), dtype=\"float32\")\n",
        "    query_input = keras.Input(shape=(dim3,), dtype=\"float32\")\n",
        "\n",
        "    user_vecs = layers.Dropout(0.2)(vecs_input)\n",
        "    user_att = layers.Dense(\n",
        "        dim3,\n",
        "        activation=\"tanh\",\n",
        "        kernel_initializer=keras.initializers.glorot_uniform(seed=seed),\n",
        "        bias_initializer=keras.initializers.Zeros(),\n",
        "    )(user_vecs)\n",
        "    user_att2 = layers.Dot(axes=-1)([query_input, user_att])\n",
        "    user_att2 = layers.Activation(\"softmax\")(user_att2)\n",
        "    user_vec = layers.Dot((1, 1))([user_vecs, user_att2])\n",
        "\n",
        "    model = keras.Model([vecs_input, query_input], user_vec)\n",
        "    return model\n",
        "\n",
        "\n",
        "class ComputeMasking(layers.Layer):\n",
        "    \"\"\"Compute if inputs contains zero value.\n",
        "    Returns:\n",
        "        bool tensor: True for values not equal to zero.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ComputeMasking, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        mask = K.not_equal(inputs, 0)\n",
        "        return K.cast(mask, K.floatx())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "class OverwriteMasking(layers.Layer):\n",
        "    \"\"\"Set values at spasific positions to zero.\n",
        "    Args:\n",
        "        inputs (list): value tensor and mask tensor.\n",
        "    \n",
        "    Returns:\n",
        "        obj: tensor after setting values to zero.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(OverwriteMasking, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(OverwriteMasking, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return inputs[0] * K.expand_dims(inputs[1])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC_RsnCNnQRF"
      },
      "source": [
        "# LSTUR - Original Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT0fo9hrgN_s"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "__all__ = [\"LSTURModel\"]\n",
        "\n",
        "\n",
        "class LSTURModel(BaseModel):\n",
        "    \"\"\"LSTUR model(Neural News Recommendation with Multi-Head Self-Attention)\n",
        "    Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie: \n",
        "    Neural News Recommendation with Long- and Short-term User Representations, ACL 2019\n",
        "    Attributes:\n",
        "        word2vec_embedding (numpy.array): Pretrained word embedding matrix.\n",
        "        hparam (obj): Global hyper-parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hparams, iterator_creator, seed=None):\n",
        "        \"\"\"Initialization steps for LSTUR.\n",
        "        Compared with the BaseModel, LSTUR need word embedding.\n",
        "        After creating word embedding matrix, BaseModel's __init__ method will be called.\n",
        "        \n",
        "        Args:\n",
        "            hparams (obj): Global hyper-parameters. Some key setttings such as type and gru_unit are there.\n",
        "            iterator_creator_train(obj): LSTUR data loader class for train data.\n",
        "            iterator_creator_test(obj): LSTUR data loader class for test and validation data\n",
        "        \"\"\"\n",
        "\n",
        "        self.word2vec_embedding = self._init_embedding(hparams.wordEmb_file)\n",
        "        self.hparam = hparams\n",
        "\n",
        "        super().__init__(hparams, iterator_creator, seed=seed)\n",
        "\n",
        "    def _get_input_label_from_iter(self, batch_data):\n",
        "        input_feat = [\n",
        "            batch_data[\"user_index_batch\"],\n",
        "            batch_data[\"clicked_title_batch\"],\n",
        "            batch_data[\"candidate_title_batch\"],\n",
        "        ]\n",
        "        input_label = batch_data[\"labels\"]\n",
        "        return input_feat, input_label\n",
        "\n",
        "    def _get_user_feature_from_iter(self, batch_data):\n",
        "        return [batch_data[\"clicked_title_batch\"], batch_data[\"user_index_batch\"]]\n",
        "\n",
        "    def _get_news_feature_from_iter(self, batch_data):\n",
        "        return batch_data[\"candidate_title_batch\"]\n",
        "\n",
        "    def _build_graph(self):\n",
        "        \"\"\"Build LSTUR model and scorer.\n",
        "        Returns:\n",
        "            obj: a model used to train.\n",
        "            obj: a model used to evaluate and inference.\n",
        "        \"\"\"\n",
        "\n",
        "        model, scorer = self._build_lstur()\n",
        "        return model, scorer\n",
        "\n",
        "    def _build_userencoder(self, titleencoder, type=\"ini\"):\n",
        "        \"\"\"The main function to create user encoder of LSTUR.\n",
        "        Args:\n",
        "            titleencoder(obj): the news encoder of LSTUR. \n",
        "        Return:\n",
        "            obj: the user encoder of LSTUR.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        his_input_title = keras.Input(\n",
        "            shape=(hparams.his_size, hparams.title_size), dtype=\"int32\"\n",
        "        )\n",
        "        user_indexes = keras.Input(shape=(1,), dtype=\"int32\")\n",
        "\n",
        "        user_embedding_layer = layers.Embedding(\n",
        "            len(self.train_iterator.uid2index),\n",
        "            hparams.gru_unit,\n",
        "            trainable=True,\n",
        "            embeddings_initializer=\"zeros\",\n",
        "        )\n",
        "\n",
        "        long_u_emb = layers.Reshape((hparams.gru_unit,))(\n",
        "            user_embedding_layer(user_indexes)\n",
        "        )\n",
        "        click_title_presents = layers.TimeDistributed(titleencoder)(his_input_title)\n",
        "\n",
        "        if type == \"ini\":\n",
        "            user_present = layers.GRU(\n",
        "                hparams.gru_unit,\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                recurrent_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "            )(\n",
        "                layers.Masking(mask_value=0.0)(click_title_presents),\n",
        "                initial_state=[long_u_emb],\n",
        "            )\n",
        "        elif type == \"con\":\n",
        "            short_uemb = layers.GRU(\n",
        "                hparams.gru_unit,\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                recurrent_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "            )(layers.Masking(mask_value=0.0)(click_title_presents))\n",
        "\n",
        "            user_present = layers.Concatenate()([short_uemb, long_u_emb])\n",
        "            user_present = layers.Dense(\n",
        "                hparams.gru_unit,\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            )(user_present)\n",
        "\n",
        "        model = keras.Model(\n",
        "            [his_input_title, user_indexes], user_present, name=\"user_encoder\"\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def _build_newsencoder(self, embedding_layer):\n",
        "        \"\"\"The main function to create news encoder of LSTUR.\n",
        "        Args:\n",
        "            embedding_layer(obj): a word embedding layer.\n",
        "        \n",
        "        Return:\n",
        "            obj: the news encoder of LSTUR.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        sequences_input_title = keras.Input(shape=(hparams.title_size,), dtype=\"int32\")\n",
        "        embedded_sequences_title = embedding_layer(sequences_input_title)\n",
        "\n",
        "        y = layers.Dropout(hparams.dropout)(embedded_sequences_title)\n",
        "        y = layers.Conv1D(\n",
        "            hparams.filter_num,\n",
        "            hparams.window_size,\n",
        "            activation=hparams.cnn_activation,\n",
        "            padding=\"same\",\n",
        "            bias_initializer=keras.initializers.Zeros(),\n",
        "            kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "        )(y)\n",
        "        print(y)\n",
        "        y = layers.Dropout(hparams.dropout)(y)\n",
        "        y = layers.Masking()(\n",
        "            OverwriteMasking()([y, ComputeMasking()(sequences_input_title)])\n",
        "        )\n",
        "        pred_title = AttLayer2(hparams.attention_hidden_dim, seed=self.seed)(y)\n",
        "        print(pred_title)\n",
        "        model = keras.Model(sequences_input_title, pred_title, name=\"news_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_lstur(self):\n",
        "        \"\"\"The main function to create LSTUR's logic. The core of LSTUR\n",
        "        is a user encoder and a news encoder.\n",
        "        \n",
        "        Returns:\n",
        "            obj: a model used to train.\n",
        "            obj: a model used to evaluate and inference.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "\n",
        "        his_input_title = keras.Input(\n",
        "            shape=(hparams.his_size, hparams.title_size), dtype=\"int32\"\n",
        "        )\n",
        "        pred_input_title = keras.Input(\n",
        "            shape=(hparams.npratio + 1, hparams.title_size), dtype=\"int32\"\n",
        "        )\n",
        "        pred_input_title_one = keras.Input(\n",
        "            shape=(1, hparams.title_size,), dtype=\"int32\"\n",
        "        )\n",
        "        pred_title_reshape = layers.Reshape((hparams.title_size,))(pred_input_title_one)\n",
        "        user_indexes = keras.Input(shape=(1,), dtype=\"int32\")\n",
        "\n",
        "        embedding_layer = layers.Embedding(\n",
        "            self.word2vec_embedding.shape[0],\n",
        "            hparams.word_emb_dim,\n",
        "            weights=[self.word2vec_embedding],\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "        titleencoder = self._build_newsencoder(embedding_layer)\n",
        "        self.userencoder = self._build_userencoder(titleencoder, type=hparams.type)\n",
        "        self.newsencoder = titleencoder\n",
        "\n",
        "        user_present = self.userencoder([his_input_title, user_indexes])\n",
        "        news_present = layers.TimeDistributed(self.newsencoder)(pred_input_title)\n",
        "        news_present_one = self.newsencoder(pred_title_reshape)\n",
        "\n",
        "        preds = layers.Dot(axes=-1)([news_present, user_present])\n",
        "        preds = layers.Activation(activation=\"softmax\")(preds)\n",
        "\n",
        "        pred_one = layers.Dot(axes=-1)([news_present_one, user_present])\n",
        "        pred_one = layers.Activation(activation=\"sigmoid\")(pred_one)\n",
        "\n",
        "        model = keras.Model([user_indexes, his_input_title, pred_input_title], preds)\n",
        "        scorer = keras.Model(\n",
        "            [user_indexes, his_input_title, pred_input_title_one], pred_one\n",
        "        )\n",
        "\n",
        "        return model, scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCyNaGdimI4g"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import abc\n",
        "\n",
        "\n",
        "class BaseIterator(object):\n",
        "    @abc.abstractmethod\n",
        "    def parser_one_line(self, line):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def load_data_from_file(self, infile):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _convert_data(self, labels, features):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def gen_feed_dict(self, data_dict):\n",
        "        pass\n",
        "\n",
        "\n",
        "class FFMTextIterator(BaseIterator):\n",
        "    \"\"\"Data loader for FFM format based models, such as xDeepFM.\n",
        "    Iterator will not load the whole data into memory. Instead, it loads data into memory\n",
        "    per mini-batch, so that large files can be used as input data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hparams, graph, col_spliter=\" \", ID_spliter=\"%\"):\n",
        "        \"\"\"Initialize an iterator. Create necessary placeholders for the model.\n",
        "        \n",
        "        Args:\n",
        "            hparams (obj): Global hyper-parameters. Some key settings such as #_feature and #_field are there.\n",
        "            graph (obj): the running graph. All created placeholder will be added to this graph.\n",
        "            col_spliter (str): column splitter in one line.\n",
        "            ID_spliter (str): ID splitter in one line.\n",
        "        \"\"\"\n",
        "        self.feature_cnt = hparams.FEATURE_COUNT\n",
        "        self.field_cnt = hparams.FIELD_COUNT\n",
        "        self.col_spliter = col_spliter\n",
        "        self.ID_spliter = ID_spliter\n",
        "        self.batch_size = hparams.batch_size\n",
        "\n",
        "        self.graph = graph\n",
        "        with self.graph.as_default():\n",
        "            self.labels = tf.placeholder(tf.float32, [None, 1], name=\"label\")\n",
        "            self.fm_feat_indices = tf.placeholder(\n",
        "                tf.int64, [None, 2], name=\"fm_feat_indices\"\n",
        "            )\n",
        "            self.fm_feat_values = tf.placeholder(\n",
        "                tf.float32, [None], name=\"fm_feat_values\"\n",
        "            )\n",
        "            self.fm_feat_shape = tf.placeholder(tf.int64, [None], name=\"fm_feat_shape\")\n",
        "            self.dnn_feat_indices = tf.placeholder(\n",
        "                tf.int64, [None, 2], name=\"dnn_feat_indices\"\n",
        "            )\n",
        "            self.dnn_feat_values = tf.placeholder(\n",
        "                tf.int64, [None], name=\"dnn_feat_values\"\n",
        "            )\n",
        "            self.dnn_feat_weights = tf.placeholder(\n",
        "                tf.float32, [None], name=\"dnn_feat_weights\"\n",
        "            )\n",
        "            self.dnn_feat_shape = tf.placeholder(\n",
        "                tf.int64, [None], name=\"dnn_feat_shape\"\n",
        "            )\n",
        "\n",
        "    def parser_one_line(self, line):\n",
        "        \"\"\"Parse one string line into feature values.\n",
        "        \n",
        "        Args:\n",
        "            line (str): a string indicating one instance\n",
        "        Returns:\n",
        "            list: Parsed results,including label, features and impression_id\n",
        "        \"\"\"\n",
        "        impression_id = 0\n",
        "        words = line.strip().split(self.ID_spliter)\n",
        "        if len(words) == 2:\n",
        "            impression_id = words[1].strip()\n",
        "\n",
        "        cols = words[0].strip().split(self.col_spliter)\n",
        "\n",
        "        label = float(cols[0])\n",
        "\n",
        "        features = []\n",
        "        for word in cols[1:]:\n",
        "            if not word.strip():\n",
        "                continue\n",
        "            tokens = word.split(\":\")\n",
        "            features.append([int(tokens[0]) - 1, int(tokens[1]) - 1, float(tokens[2])])\n",
        "\n",
        "        return label, features, impression_id\n",
        "\n",
        "    def load_data_from_file(self, infile):\n",
        "        \"\"\"Read and parse data from a file.\n",
        "        \n",
        "        Args:\n",
        "            infile (str): text input file. Each line in this file is an instance.\n",
        "        Returns:\n",
        "            obj: An iterator that will yields parsed results, in the format of graph feed_dict.\n",
        "        \"\"\"\n",
        "        label_list = []\n",
        "        features_list = []\n",
        "        impression_id_list = []\n",
        "        cnt = 0\n",
        "\n",
        "        with tf.gfile.GFile(infile, \"r\") as rd:\n",
        "            for line in rd:\n",
        "                label, features, impression_id = self.parser_one_line(line)\n",
        "\n",
        "                features_list.append(features)\n",
        "                label_list.append(label)\n",
        "                impression_id_list.append(impression_id)\n",
        "\n",
        "                cnt += 1\n",
        "                if cnt == self.batch_size:\n",
        "                    res = self._convert_data(label_list, features_list)\n",
        "                    yield self.gen_feed_dict(res), impression_id_list, self.batch_size\n",
        "                    label_list = []\n",
        "                    features_list = []\n",
        "                    impression_id_list = []\n",
        "                    cnt = 0\n",
        "            if cnt > 0:\n",
        "                res = self._convert_data(label_list, features_list)\n",
        "                yield self.gen_feed_dict(res), impression_id_list, cnt\n",
        "\n",
        "    def _convert_data(self, labels, features):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further operation.\n",
        "        \n",
        "        Args:\n",
        "            labels (list): a list of ground-truth labels.\n",
        "            features (list): a 3-dimensional list, carrying a list (batch_size) of feature array,\n",
        "                    where each feature array is a list of [field_idx, feature_idx, feature_value] tuple.\n",
        "        Returns:\n",
        "            dict: A dictionary, contains multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "        dim = self.feature_cnt\n",
        "        FIELD_COUNT = self.field_cnt\n",
        "        instance_cnt = len(labels)\n",
        "\n",
        "        fm_feat_indices = []\n",
        "        fm_feat_values = []\n",
        "        fm_feat_shape = [instance_cnt, dim]\n",
        "\n",
        "        dnn_feat_indices = []\n",
        "        dnn_feat_values = []\n",
        "        dnn_feat_weights = []\n",
        "        dnn_feat_shape = [instance_cnt * FIELD_COUNT, -1]\n",
        "\n",
        "        for i in range(instance_cnt):\n",
        "            m = len(features[i])\n",
        "            dnn_feat_dic = {}\n",
        "            for j in range(m):\n",
        "                fm_feat_indices.append([i, features[i][j][1]])\n",
        "                fm_feat_values.append(features[i][j][2])\n",
        "                if features[i][j][0] not in dnn_feat_dic:\n",
        "                    dnn_feat_dic[features[i][j][0]] = 0\n",
        "                else:\n",
        "                    dnn_feat_dic[features[i][j][0]] += 1\n",
        "                dnn_feat_indices.append(\n",
        "                    [\n",
        "                        i * FIELD_COUNT + features[i][j][0],\n",
        "                        dnn_feat_dic[features[i][j][0]],\n",
        "                    ]\n",
        "                )\n",
        "                dnn_feat_values.append(features[i][j][1])\n",
        "                dnn_feat_weights.append(features[i][j][2])\n",
        "                if dnn_feat_shape[1] < dnn_feat_dic[features[i][j][0]]:\n",
        "                    dnn_feat_shape[1] = dnn_feat_dic[features[i][j][0]]\n",
        "        dnn_feat_shape[1] += 1\n",
        "\n",
        "        sorted_index = sorted(\n",
        "            range(len(dnn_feat_indices)),\n",
        "            key=lambda k: (dnn_feat_indices[k][0], dnn_feat_indices[k][1]),\n",
        "        )\n",
        "\n",
        "        res = {}\n",
        "        res[\"fm_feat_indices\"] = np.asarray(fm_feat_indices, dtype=np.int64)\n",
        "        res[\"fm_feat_values\"] = np.asarray(fm_feat_values, dtype=np.float32)\n",
        "        res[\"fm_feat_shape\"] = np.asarray(fm_feat_shape, dtype=np.int64)\n",
        "        res[\"labels\"] = np.asarray([[label] for label in labels], dtype=np.float32)\n",
        "\n",
        "        res[\"dnn_feat_indices\"] = np.asarray(dnn_feat_indices, dtype=np.int64)[\n",
        "            sorted_index\n",
        "        ]\n",
        "        res[\"dnn_feat_values\"] = np.asarray(dnn_feat_values, dtype=np.int64)[\n",
        "            sorted_index\n",
        "        ]\n",
        "        res[\"dnn_feat_weights\"] = np.asarray(dnn_feat_weights, dtype=np.float32)[\n",
        "            sorted_index\n",
        "        ]\n",
        "        res[\"dnn_feat_shape\"] = np.asarray(dnn_feat_shape, dtype=np.int64)\n",
        "        return res\n",
        "\n",
        "    def gen_feed_dict(self, data_dict):\n",
        "        \"\"\"Construct a dictionary that maps graph elements to values.\n",
        "        Args:\n",
        "            data_dict (dict): a dictionary that maps string name to numpy arrays.\n",
        "        Returns:\n",
        "            dict: a dictionary that maps graph elements to numpy arrays.\n",
        "        \"\"\"\n",
        "        feed_dict = {\n",
        "            self.labels: data_dict[\"labels\"],\n",
        "            self.fm_feat_indices: data_dict[\"fm_feat_indices\"],\n",
        "            self.fm_feat_values: data_dict[\"fm_feat_values\"],\n",
        "            self.fm_feat_shape: data_dict[\"fm_feat_shape\"],\n",
        "            self.dnn_feat_indices: data_dict[\"dnn_feat_indices\"],\n",
        "            self.dnn_feat_values: data_dict[\"dnn_feat_values\"],\n",
        "            self.dnn_feat_weights: data_dict[\"dnn_feat_weights\"],\n",
        "            self.dnn_feat_shape: data_dict[\"dnn_feat_shape\"],\n",
        "        }\n",
        "        return feed_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEbQF_UmRCj"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    log_loss,\n",
        "    mean_squared_error,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "import numpy as np\n",
        "import yaml\n",
        "import zipfile\n",
        "import json\n",
        "import pickle as pkl\n",
        "import random\n",
        "import re\n",
        "\n",
        "\n",
        "def check_type(config):\n",
        "    \"\"\"Check that the config parameters are the correct type\n",
        "    \n",
        "    Args:\n",
        "        config (dict): Configuration dictionary.\n",
        "    Raises:\n",
        "        TypeError: If the parameters are not the correct type.\n",
        "    \"\"\"\n",
        "\n",
        "    int_parameters = [\n",
        "        \"word_size\",\n",
        "        \"his_size\",\n",
        "        \"title_size\",\n",
        "        \"body_size\",\n",
        "        \"npratio\",\n",
        "        \"word_emb_dim\",\n",
        "        \"attention_hidden_dim\",\n",
        "        \"epochs\",\n",
        "        \"batch_size\",\n",
        "        \"show_step\",\n",
        "        \"save_epoch\",\n",
        "        \"head_num\",\n",
        "        \"head_dim\",\n",
        "        \"user_num\",\n",
        "        \"filter_num\",\n",
        "        \"window_size\",\n",
        "        \"gru_unit\",\n",
        "        \"user_emb_dim\",\n",
        "        \"vert_emb_dim\",\n",
        "        \"subvert_emb_dim\",\n",
        "    ]\n",
        "    for param in int_parameters:\n",
        "        if param in config and not isinstance(config[param], int):\n",
        "            raise TypeError(\"Parameters {0} must be int\".format(param))\n",
        "\n",
        "    float_parameters = [\"learning_rate\", \"dropout\"]\n",
        "    for param in float_parameters:\n",
        "        if param in config and not isinstance(config[param], float):\n",
        "            raise TypeError(\"Parameters {0} must be float\".format(param))\n",
        "\n",
        "    str_parameters = [\n",
        "        \"wordEmb_file\",\n",
        "        \"wordDict_file\",\n",
        "        \"userDict_file\",\n",
        "        \"vertDict_file\",\n",
        "        \"subvertDict_file\",\n",
        "        \"method\",\n",
        "        \"loss\",\n",
        "        \"optimizer\",\n",
        "        \"cnn_activation\",\n",
        "        \"dense_activation\" \"type\",\n",
        "    ]\n",
        "    for param in str_parameters:\n",
        "        if param in config and not isinstance(config[param], str):\n",
        "            raise TypeError(\"Parameters {0} must be str\".format(param))\n",
        "\n",
        "    list_parameters = [\"layer_sizes\", \"activation\"]\n",
        "    for param in list_parameters:\n",
        "        if param in config and not isinstance(config[param], list):\n",
        "            raise TypeError(\"Parameters {0} must be list\".format(param))\n",
        "\n",
        "    bool_parameters = [\"support_quick_scoring\"]\n",
        "    for param in bool_parameters:\n",
        "        if param in config and not isinstance(config[param], bool):\n",
        "            raise TypeError(\"Parameters {0} must be bool\".format(param))\n",
        "\n",
        "\n",
        "def check_nn_config(f_config):\n",
        "    \"\"\"Check neural networks configuration.\n",
        "    \n",
        "    Args:\n",
        "        f_config (dict): Neural network configuration.\n",
        "    \n",
        "    Raises:\n",
        "        ValueError: If the parameters are not correct.\n",
        "    \"\"\"\n",
        "\n",
        "    if f_config[\"model_type\"] in [\"nrms\", \"NRMS\"]:\n",
        "        required_parameters = [\n",
        "            \"title_size\",\n",
        "            \"his_size\",\n",
        "            \"wordEmb_file\",\n",
        "            \"wordDict_file\",\n",
        "            \"userDict_file\",\n",
        "            \"npratio\",\n",
        "            \"data_format\",\n",
        "            \"word_emb_dim\",\n",
        "            # nrms\n",
        "            \"head_num\",\n",
        "            \"head_dim\",\n",
        "            # attention\n",
        "            \"attention_hidden_dim\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "\n",
        "    elif f_config[\"model_type\"] in [\"naml\", \"NAML\"]:\n",
        "        required_parameters = [\n",
        "            \"title_size\",\n",
        "            \"body_size\",\n",
        "            \"his_size\",\n",
        "            \"wordEmb_file\",\n",
        "            \"subvertDict_file\",\n",
        "            \"vertDict_file\",\n",
        "            \"wordDict_file\",\n",
        "            \"userDict_file\",\n",
        "            \"npratio\",\n",
        "            \"data_format\",\n",
        "            \"word_emb_dim\",\n",
        "            \"vert_emb_dim\",\n",
        "            \"subvert_emb_dim\",\n",
        "            # naml\n",
        "            \"filter_num\",\n",
        "            \"cnn_activation\",\n",
        "            \"window_size\",\n",
        "            \"dense_activation\",\n",
        "            # attention\n",
        "            \"attention_hidden_dim\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"lstur\", \"LSTUR\"]:\n",
        "        required_parameters = [\n",
        "            \"title_size\",\n",
        "            \"his_size\",\n",
        "            \"wordEmb_file\",\n",
        "            \"wordDict_file\",\n",
        "            \"userDict_file\",\n",
        "            \"npratio\",\n",
        "            \"data_format\",\n",
        "            \"word_emb_dim\",\n",
        "            # lstur\n",
        "            \"gru_unit\",\n",
        "            \"type\",\n",
        "            \"filter_num\",\n",
        "            \"cnn_activation\",\n",
        "            \"window_size\",\n",
        "            # attention\n",
        "            \"attention_hidden_dim\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "    elif f_config[\"model_type\"] in [\"npa\", \"NPA\"]:\n",
        "        required_parameters = [\n",
        "            \"title_size\",\n",
        "            \"his_size\",\n",
        "            \"wordEmb_file\",\n",
        "            \"wordDict_file\",\n",
        "            \"userDict_file\",\n",
        "            \"npratio\",\n",
        "            \"data_format\",\n",
        "            \"word_emb_dim\",\n",
        "            # npa\n",
        "            \"user_emb_dim\",\n",
        "            \"filter_num\",\n",
        "            \"cnn_activation\",\n",
        "            \"window_size\",\n",
        "            # attention\n",
        "            \"attention_hidden_dim\",\n",
        "            \"loss\",\n",
        "            \"data_format\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "    else:\n",
        "        required_parameters = []\n",
        "\n",
        "    # check required parameters\n",
        "    for param in required_parameters:\n",
        "        if param not in f_config:\n",
        "            raise ValueError(\"Parameters {0} must be set\".format(param))\n",
        "\n",
        "    if f_config[\"model_type\"] in [\"nrms\", \"NRMS\", \"lstur\", \"LSTUR\"]:\n",
        "        if f_config[\"data_format\"] != \"news\":\n",
        "            raise ValueError(\n",
        "                \"For nrms and naml model, data format must be 'news', but your set is {0}\".format(\n",
        "                    f_config[\"data_format\"]\n",
        "                )\n",
        "            )\n",
        "    elif f_config[\"model_type\"] in [\"naml\", \"NAML\"]:\n",
        "        if f_config[\"data_format\"] != \"naml\":\n",
        "            raise ValueError(\n",
        "                \"For nrms and naml model, data format must be 'naml', but your set is {0}\".format(\n",
        "                    f_config[\"data_format\"]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    check_type(f_config)\n",
        "\n",
        "\n",
        "def create_hparams(flags):\n",
        "    \"\"\"Create the model hyperparameters.\n",
        "    Args:\n",
        "        flags (dict): Dictionary with the model requirements.\n",
        "    Returns:\n",
        "        obj: Hyperparameter object in TF (tf.contrib.training.HParams).\n",
        "    \"\"\"\n",
        "    return tf.contrib.training.HParams(\n",
        "        # data\n",
        "        data_format=flags.get(\"data_format\", None),\n",
        "        iterator_type=flags.get(\"iterator_type\", None),\n",
        "        support_quick_scoring=flags.get(\"support_quick_scoring\", False),\n",
        "        wordEmb_file=flags.get(\"wordEmb_file\", None),\n",
        "        wordDict_file=flags.get(\"wordDict_file\", None),\n",
        "        userDict_file=flags.get(\"userDict_file\", None),\n",
        "        vertDict_file=flags.get(\"vertDict_file\", None),\n",
        "        subvertDict_file=flags.get(\"subvertDict_file\", None),\n",
        "        # models\n",
        "        title_size=flags.get(\"title_size\", None),\n",
        "        body_size=flags.get(\"body_size\", None),\n",
        "        word_emb_dim=flags.get(\"word_emb_dim\", None),\n",
        "        word_size=flags.get(\"word_size\", None),\n",
        "        user_num=flags.get(\"user_num\", None),\n",
        "        vert_num=flags.get(\"vert_num\", None),\n",
        "        subvert_num=flags.get(\"subvert_num\", None),\n",
        "        his_size=flags.get(\"his_size\", None),\n",
        "        npratio=flags.get(\"npratio\"),\n",
        "        dropout=flags.get(\"dropout\", 0.0),\n",
        "        attention_hidden_dim=flags.get(\"attention_hidden_dim\", 200),\n",
        "        # nrms\n",
        "        head_num=flags.get(\"head_num\", 4),\n",
        "        head_dim=flags.get(\"head_dim\", 100),\n",
        "        # naml\n",
        "        cnn_activation=flags.get(\"cnn_activation\", None),\n",
        "        dense_activation=flags.get(\"dense_activation\", None),\n",
        "        filter_num=flags.get(\"filter_num\", 200),\n",
        "        window_size=flags.get(\"window_size\", 3),\n",
        "        vert_emb_dim=flags.get(\"vert_emb_dim\", 100),\n",
        "        subvert_emb_dim=flags.get(\"subvert_emb_dim\", 100),\n",
        "        # lstur\n",
        "        gru_unit=flags.get(\"gru_unit\", 400),\n",
        "        type=flags.get(\"type\", \"ini\"),\n",
        "        # npa\n",
        "        user_emb_dim=flags.get(\"user_emb_dim\", 50),\n",
        "        # train\n",
        "        learning_rate=flags.get(\"learning_rate\", 0.001),\n",
        "        loss=flags.get(\"loss\", None),\n",
        "        optimizer=flags.get(\"optimizer\", \"adam\"),\n",
        "        epochs=flags.get(\"epochs\", 10),\n",
        "        batch_size=flags.get(\"batch_size\", 1),\n",
        "        # show info\n",
        "        show_step=flags.get(\"show_step\", 1),\n",
        "        metrics=flags.get(\"metrics\", None),\n",
        "    )\n",
        "\n",
        "\n",
        "def prepare_hparams(yaml_file=None, **kwargs):\n",
        "    \"\"\"Prepare the model hyperparameters and check that all have the correct value.\n",
        "    Args:\n",
        "        yaml_file (str): YAML file as configuration.\n",
        "    Returns:\n",
        "        obj: Hyperparameter object in TF (tf.contrib.training.HParams).\n",
        "    \"\"\"\n",
        "    if yaml_file is not None:\n",
        "        config = load_yaml(yaml_file)\n",
        "        config = flat_config(config)\n",
        "    else:\n",
        "        config = {}\n",
        "\n",
        "    config.update(kwargs)\n",
        "\n",
        "    check_nn_config(config)\n",
        "    return create_hparams(config)\n",
        "\n",
        "\n",
        "def word_tokenize(sent):\n",
        "    \"\"\" Split sentence into word list using regex.\n",
        "    Args:\n",
        "        sent (str): Input sentence\n",
        "    Return:\n",
        "        list: word list\n",
        "    \"\"\"\n",
        "    pat = re.compile(r\"[\\w]+|[.,!?;|]\")\n",
        "    if isinstance(sent, str):\n",
        "        return pat.findall(sent.lower())\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "\n",
        "def newsample(news, ratio):\n",
        "    \"\"\" Sample ratio samples from news list. \n",
        "    If length of news is less than ratio, pad zeros.\n",
        "    Args:\n",
        "        news (list): input news list\n",
        "        ratio (int): sample number\n",
        "    \n",
        "    Returns:\n",
        "        list: output of sample list.\n",
        "    \"\"\"\n",
        "    if ratio > len(news):\n",
        "        return news + [0] * (ratio - len(news))\n",
        "    else:\n",
        "        return random.sample(news, ratio)\n",
        "\n",
        "\n",
        "def get_mind_data_set(type):\n",
        "    \"\"\" Get MIND dataset address \n",
        "    Args:\n",
        "        type (str): type of mind dataset, must be in ['large', 'small', 'demo']\n",
        "        \n",
        "    Returns:\n",
        "        list: data url and train valid dataset name\n",
        "    \"\"\"\n",
        "    assert type in [\"large\", \"small\", \"demo\"]\n",
        "\n",
        "    if type == \"large\":\n",
        "        return (\n",
        "            \"https://mind201910small.blob.core.windows.net/release/\",\n",
        "            \"MINDlarge_train.zip\",\n",
        "            \"MINDlarge_dev.zip\",\n",
        "            \"MINDlarge_utils.zip\",\n",
        "        )\n",
        "\n",
        "    elif type == \"small\":\n",
        "        return (\n",
        "            \"https://mind201910small.blob.core.windows.net/release/\",\n",
        "            \"MINDsmall_train.zip\",\n",
        "            \"MINDsmall_dev.zip\",\n",
        "            \"MINDsmall_utils.zip\",\n",
        "        )\n",
        "\n",
        "    elif type == \"demo\":\n",
        "        return (\n",
        "            \"https://recodatasets.z20.web.core.windows.net/newsrec/\",\n",
        "            \"MINDdemo_train.zip\",\n",
        "            \"MINDdemo_dev.zip\",\n",
        "            \"MINDdemo_utils.zip\",\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F31ZBYzTmCp_"
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "__all__ = [\"MINDIterator\"]\n",
        "\n",
        "\n",
        "class MINDIterator(BaseIterator):\n",
        "    \"\"\"Train data loader for NAML model.\n",
        "    The model require a special type of data format, where each instance contains a label, impresion id, user id,\n",
        "    the candidate news articles and user's clicked news article. Articles are represented by title words,\n",
        "    body words, verts and subverts. \n",
        "    Iterator will not load the whole data into memory. Instead, it loads data into memory\n",
        "    per mini-batch, so that large files can be used as input data.\n",
        "    Attributes:\n",
        "        col_spliter (str): column spliter in one line.\n",
        "        ID_spliter (str): ID spliter in one line.\n",
        "        batch_size (int): the samples num in one batch.\n",
        "        title_size (int): max word num in news title.\n",
        "        his_size (int): max clicked news num in user click history.\n",
        "        npratio (int): negaive and positive ratio used in negative sampling. -1 means no need of negtive sampling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, hparams, npratio=-1, col_spliter=\"\\t\", ID_spliter=\"%\",\n",
        "    ):\n",
        "        \"\"\"Initialize an iterator. Create necessary placeholders for the model.\n",
        "        \n",
        "        Args:\n",
        "            hparams (obj): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\n",
        "            npratio (int): negaive and positive ratio used in negative sampling. -1 means no need of negtive sampling.\n",
        "            col_spliter (str): column spliter in one line.\n",
        "            ID_spliter (str): ID spliter in one line.\n",
        "        \"\"\"\n",
        "        self.col_spliter = col_spliter\n",
        "        self.ID_spliter = ID_spliter\n",
        "        self.batch_size = hparams.batch_size\n",
        "        self.title_size = hparams.title_size\n",
        "        self.his_size = hparams.his_size\n",
        "        self.npratio = npratio\n",
        "\n",
        "        self.word_dict = self.load_dict(hparams.wordDict_file)\n",
        "        self.uid2index = self.load_dict(hparams.userDict_file)\n",
        "\n",
        "    def load_dict(self, file_path):\n",
        "        \"\"\" load pickle file\n",
        "        Args:\n",
        "            file path (str): file path\n",
        "        \n",
        "        Returns:\n",
        "            (obj): pickle load obj\n",
        "        \"\"\"\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def init_news(self, news_file):\n",
        "        \"\"\" init news information given news file, such as news_title_index and nid2index.\n",
        "        Args:\n",
        "            news_file: path of news file\n",
        "        \"\"\"\n",
        "\n",
        "        self.nid2index = {}\n",
        "        news_title = [\"\"]\n",
        "\n",
        "        with tf.io.gfile.GFile(news_file, \"r\") as rd:\n",
        "            for line in rd:\n",
        "                nid, vert, subvert, title, ab, url, _, _ = line.strip(\"\\n\").split(\n",
        "                    self.col_spliter\n",
        "                )\n",
        "\n",
        "                if nid in self.nid2index:\n",
        "                    continue\n",
        "\n",
        "                self.nid2index[nid] = len(self.nid2index) + 1\n",
        "                title = word_tokenize(title)\n",
        "                news_title.append(title)\n",
        "\n",
        "        self.news_title_index = np.zeros(\n",
        "            (len(news_title), self.title_size), dtype=\"int32\"\n",
        "        )\n",
        "\n",
        "        for news_index in range(len(news_title)):\n",
        "            title = news_title[news_index]\n",
        "            for word_index in range(min(self.title_size, len(title))):\n",
        "                if title[word_index] in self.word_dict:\n",
        "                    self.news_title_index[news_index, word_index] = self.word_dict[\n",
        "                        title[word_index].lower()\n",
        "                    ]\n",
        "\n",
        "    def init_behaviors(self, behaviors_file):\n",
        "        \"\"\" init behavior logs given behaviors file.\n",
        "        Args:\n",
        "        behaviors_file: path of behaviors file\n",
        "        \"\"\"\n",
        "        self.histories = []\n",
        "        self.imprs = []\n",
        "        self.labels = []\n",
        "        self.impr_indexes = []\n",
        "        self.uindexes = []\n",
        "\n",
        "        with tf.io.gfile.GFile(behaviors_file, \"r\") as rd:\n",
        "            impr_index = 0\n",
        "            for line in rd:\n",
        "                uid, time, history, impr = line.strip(\"\\n\").split(self.col_spliter)[-4:]\n",
        "\n",
        "                history = [self.nid2index[i] for i in history.split()]\n",
        "                history = [0] * (self.his_size - len(history)) + history[\n",
        "                    : self.his_size\n",
        "                ]\n",
        "\n",
        "                impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
        "                label = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
        "                uindex = self.uid2index[uid] if uid in self.uid2index else 0\n",
        "\n",
        "                self.histories.append(history)\n",
        "                self.imprs.append(impr_news)\n",
        "                self.labels.append(label)\n",
        "                self.impr_indexes.append(impr_index)\n",
        "                self.uindexes.append(uindex)\n",
        "                impr_index += 1\n",
        "\n",
        "    def parser_one_line(self, line):\n",
        "        \"\"\"Parse one behavior sample into feature values.\n",
        "        if npratio is larger than 0, return negtive sampled result.\n",
        "        \n",
        "        Args:\n",
        "            line (int): sample index.\n",
        "        Returns:\n",
        "            list: Parsed results including label, impression id , user id, \n",
        "            candidate_title_index, clicked_title_index.\n",
        "        \"\"\"\n",
        "        if self.npratio > 0:\n",
        "            impr_label = self.labels[line]\n",
        "            impr = self.imprs[line]\n",
        "\n",
        "            poss = []\n",
        "            negs = []\n",
        "\n",
        "            for news, click in zip(impr, impr_label):\n",
        "                if click == 1:\n",
        "                    poss.append(news)\n",
        "                else:\n",
        "                    negs.append(news)\n",
        "\n",
        "            for p in poss:\n",
        "                candidate_title_index = []\n",
        "                impr_index = []\n",
        "                user_index = []\n",
        "                label = [1] + [0] * self.npratio\n",
        "\n",
        "                n = newsample(negs, self.npratio)\n",
        "                candidate_title_index = self.news_title_index[[p] + n]\n",
        "                click_title_index = self.news_title_index[self.histories[line]]\n",
        "                impr_index.append(self.impr_indexes[line])\n",
        "                user_index.append(self.uindexes[line])\n",
        "\n",
        "                yield (\n",
        "                    label,\n",
        "                    impr_index,\n",
        "                    user_index,\n",
        "                    candidate_title_index,\n",
        "                    click_title_index,\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            impr_label = self.labels[line]\n",
        "            impr = self.imprs[line]\n",
        "\n",
        "            for news, label in zip(impr, impr_label):\n",
        "                candidate_title_index = []\n",
        "                impr_index = []\n",
        "                user_index = []\n",
        "                label = [label]\n",
        "\n",
        "                candidate_title_index.append(self.news_title_index[news])\n",
        "                click_title_index = self.news_title_index[self.histories[line]]\n",
        "                impr_index.append(self.impr_indexes[line])\n",
        "                user_index.append(self.uindexes[line])\n",
        "\n",
        "                yield (\n",
        "                    label,\n",
        "                    impr_index,\n",
        "                    user_index,\n",
        "                    candidate_title_index,\n",
        "                    click_title_index,\n",
        "                )\n",
        "\n",
        "    def load_data_from_file(self, news_file, behavior_file):\n",
        "        \"\"\"Read and parse data from news file and behavior file.\n",
        "        \n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "            beahaviros_file (str): A file contains information of user impressions.\n",
        "        Returns:\n",
        "            obj: An iterator that will yields parsed results, in the format of dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        if not hasattr(self, \"impr_indexes\"):\n",
        "            self.init_behaviors(behavior_file)\n",
        "\n",
        "        label_list = []\n",
        "        imp_indexes = []\n",
        "        user_indexes = []\n",
        "        candidate_title_indexes = []\n",
        "        click_title_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        indexes = np.arange(len(self.labels))\n",
        "\n",
        "        if self.npratio > 0:\n",
        "            np.random.shuffle(indexes)\n",
        "\n",
        "        for index in indexes:\n",
        "            for (\n",
        "                label,\n",
        "                imp_index,\n",
        "                user_index,\n",
        "                candidate_title_index,\n",
        "                click_title_index,\n",
        "            ) in self.parser_one_line(index):\n",
        "                candidate_title_indexes.append(candidate_title_index)\n",
        "                click_title_indexes.append(click_title_index)\n",
        "                imp_indexes.append(imp_index)\n",
        "                user_indexes.append(user_index)\n",
        "                label_list.append(label)\n",
        "\n",
        "                cnt += 1\n",
        "                if cnt >= self.batch_size:\n",
        "                    yield self._convert_data(\n",
        "                        label_list,\n",
        "                        imp_indexes,\n",
        "                        user_indexes,\n",
        "                        candidate_title_indexes,\n",
        "                        click_title_indexes,\n",
        "                    )\n",
        "                    label_list = []\n",
        "                    imp_indexes = []\n",
        "                    user_indexes = []\n",
        "                    candidate_title_indexes = []\n",
        "                    click_title_indexes = []\n",
        "                    cnt = 0\n",
        "\n",
        "        if cnt > 0:\n",
        "            yield self._convert_data(\n",
        "                label_list,\n",
        "                imp_indexes,\n",
        "                user_indexes,\n",
        "                candidate_title_indexes,\n",
        "                click_title_indexes,\n",
        "            )\n",
        "\n",
        "    def _convert_data(\n",
        "        self,\n",
        "        label_list,\n",
        "        imp_indexes,\n",
        "        user_indexes,\n",
        "        candidate_title_indexes,\n",
        "        click_title_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        \n",
        "        Args:\n",
        "            label_list (list): a list of ground-truth labels.\n",
        "            imp_indexes (list): a list of impression indexes.\n",
        "            user_indexes (list): a list of user indexes.\n",
        "            candidate_title_indexes (list): the candidate news titles' words indices.\n",
        "            click_title_indexes (list): words indices for user's clicked news titles.\n",
        "            \n",
        "        Returns:\n",
        "            dict: A dictionary, contains multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        labels = np.asarray(label_list, dtype=np.float32)\n",
        "        imp_indexes = np.asarray(imp_indexes, dtype=np.int32)\n",
        "        user_indexes = np.asarray(user_indexes, dtype=np.int32)\n",
        "        candidate_title_index_batch = np.asarray(\n",
        "            candidate_title_indexes, dtype=np.int64\n",
        "        )\n",
        "        click_title_index_batch = np.asarray(click_title_indexes, dtype=np.int64)\n",
        "        return {\n",
        "            \"impression_index_batch\": imp_indexes,\n",
        "            \"user_index_batch\": user_indexes,\n",
        "            \"clicked_title_batch\": click_title_index_batch,\n",
        "            \"candidate_title_batch\": candidate_title_index_batch,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def load_user_from_file(self, news_file, behavior_file):\n",
        "        \"\"\"Read and parse user data from news file and behavior file.\n",
        "        \n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "            beahaviros_file (str): A file contains information of user impressions.\n",
        "        Returns:\n",
        "            obj: An iterator that will yields parsed user feature, in the format of dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        if not hasattr(self, \"impr_indexes\"):\n",
        "            self.init_behaviors(behavior_file)\n",
        "\n",
        "        user_indexes = []\n",
        "        impr_indexes = []\n",
        "        click_title_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        for index in range(len(self.impr_indexes)):\n",
        "            click_title_indexes.append(self.news_title_index[self.histories[index]])\n",
        "            user_indexes.append(self.uindexes[index])\n",
        "            impr_indexes.append(self.impr_indexes[index])\n",
        "\n",
        "            cnt += 1\n",
        "            if cnt >= self.batch_size:\n",
        "                yield self._convert_user_data(\n",
        "                    user_indexes, impr_indexes, click_title_indexes,\n",
        "                )\n",
        "                user_indexes = []\n",
        "                impr_indexes = []\n",
        "                click_title_indexes = []\n",
        "                cnt = 0\n",
        "\n",
        "        if cnt > 0:\n",
        "            yield self._convert_user_data(\n",
        "                user_indexes, impr_indexes, click_title_indexes,\n",
        "            )\n",
        "\n",
        "    def _convert_user_data(\n",
        "        self, user_indexes, impr_indexes, click_title_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        \n",
        "        Args:\n",
        "            user_indexes (list): a list of user indexes.\n",
        "            click_title_indexes (list): words indices for user's clicked news titles.\n",
        "            \n",
        "        Returns:\n",
        "            dict: A dictionary, contains multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        user_indexes = np.asarray(user_indexes, dtype=np.int32)\n",
        "        impr_indexes = np.asarray(impr_indexes, dtype=np.int32)\n",
        "        click_title_index_batch = np.asarray(click_title_indexes, dtype=np.int64)\n",
        "\n",
        "        return {\n",
        "            \"user_index_batch\": user_indexes,\n",
        "            \"impr_index_batch\": impr_indexes,\n",
        "            \"clicked_title_batch\": click_title_index_batch,\n",
        "        }\n",
        "\n",
        "    def load_news_from_file(self, news_file):\n",
        "        \"\"\"Read and parse user data from news file.\n",
        "        \n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "            \n",
        "        Returns:\n",
        "            obj: An iterator that will yields parsed news feature, in the format of dict.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        news_indexes = []\n",
        "        candidate_title_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        for index in range(len(self.news_title_index)):\n",
        "            news_indexes.append(index)\n",
        "            candidate_title_indexes.append(self.news_title_index[index])\n",
        "\n",
        "            cnt += 1\n",
        "            if cnt >= self.batch_size:\n",
        "                yield self._convert_news_data(\n",
        "                    news_indexes, candidate_title_indexes,\n",
        "                )\n",
        "                news_indexes = []\n",
        "                candidate_title_indexes = []\n",
        "                cnt = 0\n",
        "\n",
        "        if cnt > 0:\n",
        "            yield self._convert_news_data(\n",
        "                news_indexes, candidate_title_indexes,\n",
        "            )\n",
        "\n",
        "    def _convert_news_data(\n",
        "        self, news_indexes, candidate_title_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        \n",
        "        Args:\n",
        "            news_indexes (list): a list of news indexes.\n",
        "            candidate_title_indexes (list): the candidate news titles' words indices.\n",
        "            \n",
        "        Returns:\n",
        "            dict: A dictionary, contains multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        news_indexes_batch = np.asarray(news_indexes, dtype=np.int32)\n",
        "        candidate_title_index_batch = np.asarray(\n",
        "            candidate_title_indexes, dtype=np.int32\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"news_index_batch\": news_indexes_batch,\n",
        "            \"candidate_title_batch\": candidate_title_index_batch,\n",
        "        }\n",
        "\n",
        "    def load_impression_from_file(self, behaivors_file):\n",
        "        \"\"\"Read and parse impression data from behaivors file.\n",
        "        \n",
        "        Args:\n",
        "            behaivors_file (str): A file contains several informations of behaviros.\n",
        "            \n",
        "        Returns:\n",
        "            obj: An iterator that will yields parsed impression data, in the format of dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"histories\"):\n",
        "            self.init_behaviors(behaivors_file)\n",
        "\n",
        "        indexes = np.arange(len(self.labels))\n",
        "\n",
        "        for index in indexes:\n",
        "            impr_label = np.array(self.labels[index], dtype=\"int32\")\n",
        "            impr_news = np.array(self.imprs[index], dtype=\"int32\")\n",
        "\n",
        "            yield (\n",
        "                self.impr_indexes[index],\n",
        "                impr_news,\n",
        "                self.uindexes[index],\n",
        "                impr_label,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzm19x_Bkaaj",
        "outputId": "cd6f4d5a-f57a-47f8-9c95-a0bc7e63c6e6"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import scrapbook as sb\n",
        "from tempfile import TemporaryDirectory\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "# from reco_utils.recommender.deeprec.deeprec_utils import download_deeprec_resources \n",
        "# from reco_utils.recommender.newsrec.newsrec_utils import prepare_hparams\n",
        "# from reco_utils.recommender.newsrec.models.lstur import LSTURModel\n",
        "# from reco_utils.recommender.newsrec.io.mind_iterator import MINDIterator\n",
        "# from reco_utils.recommender.newsrec.newsrec_utils import get_mind_data_set\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) \n",
            "[GCC 9.3.0]\n",
            "Tensorflow version: 1.15.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxx9ZanCkaal"
      },
      "source": [
        "## Prepare Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRpU2UO1kaan"
      },
      "source": [
        "epochs = 5\n",
        "seed = 40\n",
        "batch_size = 32\n",
        "\n",
        "# Options: demo, small, large\n",
        "MIND_type = 'small'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWIEZ9rdkaao"
      },
      "source": [
        "## Download and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKmOYeJkkaap",
        "outputId": "2737e857-542b-4f1f-d16b-4b229af28648"
      },
      "source": [
        "tmpdir = TemporaryDirectory()\n",
        "data_path = tmpdir.name\n",
        "\n",
        "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
        "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
        "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
        "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
        "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
        "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
        "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
        "yaml_file = os.path.join(data_path, \"utils\", r'lstur.yaml')\n",
        "\n",
        "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
        "\n",
        "if not os.path.exists(train_news_file):\n",
        "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
        "    \n",
        "if not os.path.exists(valid_news_file):\n",
        "    download_deeprec_resources(mind_url, \\\n",
        "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
        "if not os.path.exists(yaml_file):\n",
        "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
        "                               os.path.join(data_path, 'utils'), mind_utils)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51.7k/51.7k [00:04<00:00, 12.8kKB/s]\n",
            "100%|██████████| 30.2k/30.2k [00:02<00:00, 12.5kKB/s]\n",
            "100%|██████████| 152k/152k [00:02<00:00, 60.8kKB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3qpwPsJkaaq"
      },
      "source": [
        "## Create hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsFn8sTPkaat",
        "outputId": "4b1a8f4b-2011-4ff4-dbe8-f573fcbbac43"
      },
      "source": [
        "hparams = prepare_hparams(yaml_file, \n",
        "                          wordEmb_file=wordEmb_file,\n",
        "                          wordDict_file=wordDict_file, \n",
        "                          userDict_file=userDict_file,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs)\n",
        "print(hparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_format=news,iterator_type=None,support_quick_scoring=True,wordEmb_file=/tmp/tmp5jvcvykg/utils/embedding.npy,wordDict_file=/tmp/tmp5jvcvykg/utils/word_dict.pkl,userDict_file=/tmp/tmp5jvcvykg/utils/uid2index.pkl,vertDict_file=None,subvertDict_file=None,title_size=30,body_size=None,word_emb_dim=300,word_size=None,user_num=None,vert_num=None,subvert_num=None,his_size=50,npratio=4,dropout=0.2,attention_hidden_dim=200,head_num=4,head_dim=100,cnn_activation=relu,dense_activation=None,filter_num=400,window_size=3,vert_emb_dim=100,subvert_emb_dim=100,gru_unit=400,type=ini,user_emb_dim=50,learning_rate=0.0001,loss=cross_entropy_loss,optimizer=adam,epochs=5,batch_size=32,show_step=100000,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBd78oovkaat"
      },
      "source": [
        "iterator = MINDIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMER0_r2kaat"
      },
      "source": [
        "## Train the LSTUR model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOxoJnQokaau",
        "outputId": "cfa47380-891d-488d-85ab-4acb701ab7bf"
      },
      "source": [
        "lstur_model = LSTURModel(hparams, iterator, seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"conv1d/Relu:0\", shape=(?, 30, 400), dtype=float32)\n",
            "Tensor(\"att_layer2/Sum_1:0\", shape=(?, 400), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UoyvzS8kaau",
        "outputId": "74049342-2f08-4f15-9e79-350e48b27e5a"
      },
      "source": [
        "print(lstur_model.run_eval(valid_news_file, valid_behaviors_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1326it [00:34, 38.01it/s] \n",
            "2286it [01:05, 35.10it/s]\n",
            "73152it [00:19, 3812.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.5268, 'mean_mrr': 0.234, 'ndcg@5': 0.2415, 'ndcg@10': 0.305}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO0t5i9Ukaau",
        "outputId": "277eea2b-1562-4a8f-8dc5-f8acdfb5b479"
      },
      "source": [
        "%%time\n",
        "lstur_model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2021-08-17 19:54:55.965 ip-172-16-37-239:23940 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
            "[2021-08-17 19:54:56.036 ip-172-16-37-239:23940 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [14:05,  8.74it/s]\n",
            "1326it [00:01, 741.14it/s]\n",
            "2286it [01:01, 37.15it/s]\n",
            "73152it [00:18, 3916.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 1\n",
            "train info: logloss loss:1.3798686091069636\n",
            "eval info: group_auc:0.6425, mean_mrr:0.2953, ndcg@10:0.3906, ndcg@5:0.3267\n",
            "at epoch 1 , train time: 845.3 eval time: 172.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:43,  8.97it/s]\n",
            "1326it [00:01, 731.34it/s]\n",
            "2286it [01:06, 34.52it/s]\n",
            "73152it [00:20, 3523.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 2\n",
            "train info: logloss loss:1.3078901182417297\n",
            "eval info: group_auc:0.6495, mean_mrr:0.2997, ndcg@10:0.3946, ndcg@5:0.3305\n",
            "at epoch 2 , train time: 823.8 eval time: 177.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:38,  9.02it/s]\n",
            "1326it [00:01, 748.48it/s]\n",
            "2286it [01:00, 37.78it/s]\n",
            "73152it [00:18, 3853.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 3\n",
            "train info: logloss loss:1.2781965106185007\n",
            "eval info: group_auc:0.6592, mean_mrr:0.3078, ndcg@10:0.4042, ndcg@5:0.34\n",
            "at epoch 3 , train time: 818.8 eval time: 170.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:40,  9.00it/s]\n",
            "1326it [00:01, 746.51it/s]\n",
            "2286it [01:00, 37.50it/s]\n",
            "73152it [00:19, 3788.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 4\n",
            "train info: logloss loss:1.2557451590157251\n",
            "eval info: group_auc:0.6621, mean_mrr:0.3132, ndcg@10:0.4091, ndcg@5:0.3462\n",
            "at epoch 4 , train time: 820.3 eval time: 170.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:39,  9.01it/s]\n",
            "1326it [00:01, 749.77it/s]\n",
            "2286it [01:00, 37.73it/s]\n",
            "73152it [00:19, 3732.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 5\n",
            "train info: logloss loss:1.2298024632389746\n",
            "eval info: group_auc:0.6659, mean_mrr:0.3169, ndcg@10:0.4121, ndcg@5:0.3493\n",
            "at epoch 5 , train time: 819.7 eval time: 170.2\n",
            "CPU times: user 2h 35min 4s, sys: 24min 51s, total: 2h 59min 56s\n",
            "Wall time: 1h 23min 8s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.LSTURModel at 0x7f3498a92748>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9fuGzTukaav",
        "outputId": "ef9ec15a-a3d3-48fa-d5a0-1f2e5eaedcd6"
      },
      "source": [
        "%%time\n",
        "res_syn = lstur_model.run_eval(valid_news_file, valid_behaviors_file)\n",
        "print(res_syn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1326it [00:01, 747.32it/s]\n",
            "2286it [01:00, 37.61it/s]\n",
            "73152it [00:19, 3690.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.6659, 'mean_mrr': 0.3169, 'ndcg@5': 0.3493, 'ndcg@10': 0.4121}\n",
            "CPU times: user 4min 47s, sys: 1min 37s, total: 6min 24s\n",
            "Wall time: 2min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sOv6w9XNkaav",
        "outputId": "111965a3-39e3-435f-9dcf-ef57641b4c5b"
      },
      "source": [
        "sb.glue(\"res_syn\", res_syn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/scrapbook.scrap.json+json": {
              "data": {
                "group_auc": 0.6659,
                "mean_mrr": 0.3169,
                "ndcg@10": 0.4121,
                "ndcg@5": 0.3493
              },
              "encoder": "json",
              "name": "res_syn",
              "version": 1
            }
          },
          "metadata": {
            "scrapbook": {
              "data": true,
              "display": false,
              "name": "res_syn"
            }
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_1nnbuTkaax"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojU-tucWkaaz"
      },
      "source": [
        "model_path = os.path.join(data_path, \"lstur_model\")\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "lstur_model.model.save_weights(os.path.join(model_path, \"lstur_ckpt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku5paePwoGjb"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "jgeOartnoLPF",
        "outputId": "b619ca7e-a0ca-467f-f447-b8d7afdc51c1"
      },
      "source": [
        "plt.plot([float(l.split(':')[-1]) for l in lstur_model.history_loss['train']], label='logloss')\n",
        "plt.title('training loss over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JOOYmTFipzgR",
        "outputId": "b377d7ce-d1a9-481e-8533-c64eaba731a1"
      },
      "source": [
        "plt.plot([float(l.split(',')[0].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='group_auc')\n",
        "plt.plot([float(l.split(',')[1].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='mean_mrr')\n",
        "plt.plot([float(l.split(',')[2].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='ndcg@10')\n",
        "plt.plot([float(l.split(',')[3].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='ndcg@5')\n",
        "plt.title('eval measures over epochs')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riPbCJ9a692m"
      },
      "source": [
        "### Overfitting measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CjUDHjt7BDt"
      },
      "source": [
        "This plot will show the amount of overfitting in the model, the gap between the train loss and the evaluation measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df21z2Iu7JJs",
        "outputId": "ddce7503-c285-4192-bfbd-ee2fef79a905"
      },
      "source": [
        "plt.plot([float(l.split(':')[-1]) for l in lstur_model.history_loss['train']], label='train logloss')\n",
        "plt.plot([float(l.split(',')[0].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='group_auc')\n",
        "plt.plot([float(l.split(',')[1].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='mean_mrr')\n",
        "plt.plot([float(l.split(',')[2].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='ndcg@10')\n",
        "plt.plot([float(l.split(',')[3].split(':')[-1]) for l in lstur_model.history_loss['eval']], label='ndcg@5')\n",
        "plt.title(\"Overfit measure\")\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('score / loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5evxkFgDEzpP"
      },
      "source": [
        "# LSTUR - The Enhanced News Encoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEKVyE6XGMb8"
      },
      "source": [
        "__all__ = [\"MINDAllIterator\"]\n",
        "\n",
        "\n",
        "class MINDAllIterator(BaseIterator):\n",
        "    \"\"\"Train data loader for NAML model.\n",
        "    The model require a special type of data format, where each instance contains a label, impresion id, user id,\n",
        "    the candidate news articles and user's clicked news article. Articles are represented by title words,\n",
        "    body words, verts and subverts.\n",
        "    Iterator will not load the whole data into memory. Instead, it loads data into memory\n",
        "    per mini-batch, so that large files can be used as input data.\n",
        "    Attributes:\n",
        "        col_spliter (str): column spliter in one line.\n",
        "        ID_spliter (str): ID spliter in one line.\n",
        "        batch_size (int): the samples num in one batch.\n",
        "        title_size (int): max word num in news title.\n",
        "        body_size (int): max word num in news body (abstract used in MIND).\n",
        "        his_size (int): max clicked news num in user click history.\n",
        "        npratio (int): negaive and positive ratio used in negative sampling. -1 means no need of negtive sampling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hparams,\n",
        "        npratio=-1,\n",
        "        col_spliter=\"\\t\",\n",
        "        ID_spliter=\"%\",\n",
        "    ):\n",
        "        \"\"\"Initialize an iterator. Create necessary placeholders for the model.\n",
        "        Args:\n",
        "            hparams (object): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\n",
        "            graph (object): the running graph. All created placeholder will be added to this graph.\n",
        "            col_spliter (str): column spliter in one line.\n",
        "            ID_spliter (str): ID spliter in one line.\n",
        "        \"\"\"\n",
        "        self.col_spliter = col_spliter\n",
        "        self.ID_spliter = ID_spliter\n",
        "        self.batch_size = hparams.batch_size\n",
        "        self.title_size = hparams.title_size\n",
        "        self.body_size = hparams.body_size\n",
        "        self.his_size = hparams.his_size\n",
        "        self.npratio = npratio\n",
        "\n",
        "        self.word_dict = self.load_dict(hparams.wordDict_file)\n",
        "        self.vert_dict = self.load_dict(hparams.vertDict_file)\n",
        "        self.subvert_dict = self.load_dict(hparams.subvertDict_file)\n",
        "        self.uid2index = self.load_dict(hparams.userDict_file)\n",
        "\n",
        "    def load_dict(self, file_path):\n",
        "        \"\"\"Load pickled file\n",
        "        Args:\n",
        "            file path (str): File path\n",
        "        Returns:\n",
        "            object: pickle load obj\n",
        "        \"\"\"\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def init_news(self, news_file):\n",
        "        \"\"\"Init news information given news file, such as `news_title_index`, `news_abstract_index`.\n",
        "        Args:\n",
        "            news_file: path of news file\n",
        "        \"\"\"\n",
        "        self.nid2index = {}\n",
        "        news_title = [\"\"]\n",
        "        news_ab = [\"\"]\n",
        "        news_vert = [\"\"]\n",
        "        news_subvert = [\"\"]\n",
        "\n",
        "        with tf.io.gfile.GFile(news_file, \"r\") as rd:\n",
        "            for line in rd:\n",
        "                nid, vert, subvert, title, ab, url, _, _ = line.strip(\"\\n\").split(\n",
        "                    self.col_spliter\n",
        "                )\n",
        "\n",
        "                if nid in self.nid2index:\n",
        "                    continue\n",
        "\n",
        "                self.nid2index[nid] = len(self.nid2index) + 1\n",
        "                title = word_tokenize(title)\n",
        "                ab = word_tokenize(ab)\n",
        "                news_title.append(title)\n",
        "                news_ab.append(ab)\n",
        "                news_vert.append(vert)\n",
        "                news_subvert.append(subvert)\n",
        "\n",
        "        self.news_title_index = np.zeros(\n",
        "            (len(news_title), self.title_size), dtype=\"int32\"\n",
        "        )\n",
        "\n",
        "        self.news_ab_index = np.zeros((len(news_ab), self.body_size), dtype=\"int32\")\n",
        "        self.news_vert_index = np.zeros((len(news_vert), 1), dtype=\"int32\")\n",
        "        self.news_subvert_index = np.zeros((len(news_subvert), 1), dtype=\"int32\")\n",
        "\n",
        "        for news_index in range(len(news_title)):\n",
        "            title = news_title[news_index]\n",
        "            ab = news_ab[news_index]\n",
        "            vert = news_vert[news_index]\n",
        "            subvert = news_subvert[news_index]\n",
        "            for word_index in range(min(self.title_size, len(title))):\n",
        "                if title[word_index] in self.word_dict:\n",
        "                    self.news_title_index[news_index, word_index] = self.word_dict[\n",
        "                        title[word_index].lower()\n",
        "                    ]\n",
        "            for word_index_ab in range(min(self.body_size, len(ab))):\n",
        "                if ab[word_index_ab] in self.word_dict:\n",
        "                    self.news_ab_index[news_index, word_index_ab] = self.word_dict[\n",
        "                        ab[word_index_ab].lower()\n",
        "                    ]\n",
        "            if vert in self.vert_dict:\n",
        "                self.news_vert_index[news_index, 0] = self.vert_dict[vert]\n",
        "            if subvert in self.subvert_dict:\n",
        "                self.news_subvert_index[news_index, 0] = self.subvert_dict[subvert]\n",
        "\n",
        "    def init_behaviors(self, behaviors_file):\n",
        "        \"\"\"Init behavior logs given behaviors file.\n",
        "        Args:\n",
        "            behaviors_file (str): path of behaviors file\n",
        "        \"\"\"\n",
        "        self.histories = []\n",
        "        self.imprs = []\n",
        "        self.labels = []\n",
        "        self.impr_indexes = []\n",
        "        self.uindexes = []\n",
        "\n",
        "        with tf.io.gfile.GFile(behaviors_file, \"r\") as rd:\n",
        "            impr_index = 0\n",
        "            for line in rd:\n",
        "                uid, time, history, impr = line.strip(\"\\n\").split(self.col_spliter)[-4:]\n",
        "\n",
        "                history = [self.nid2index[i] for i in history.split()]\n",
        "                history = [0] * (self.his_size - len(history)) + history[\n",
        "                    : self.his_size\n",
        "                ]\n",
        "\n",
        "                impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
        "                label = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
        "                uindex = self.uid2index[uid] if uid in self.uid2index else 0\n",
        "\n",
        "                self.histories.append(history)\n",
        "                self.imprs.append(impr_news)\n",
        "                self.labels.append(label)\n",
        "                self.impr_indexes.append(impr_index)\n",
        "                self.uindexes.append(uindex)\n",
        "                impr_index += 1\n",
        "\n",
        "    def parser_one_line(self, line):\n",
        "        \"\"\"Parse one string line into feature values.\n",
        "        Args:\n",
        "            line (str): a string indicating one instance.\n",
        "        Yields:\n",
        "            list: Parsed results including label, impression id , user id,\n",
        "            candidate_title_index, clicked_title_index,\n",
        "            candidate_ab_index, clicked_ab_index,\n",
        "            candidate_vert_index, clicked_vert_index,\n",
        "            candidate_subvert_index, clicked_subvert_index,\n",
        "        \"\"\"\n",
        "        if self.npratio > 0:\n",
        "            impr_label = self.labels[line]\n",
        "            impr = self.imprs[line]\n",
        "\n",
        "            poss = []\n",
        "            negs = []\n",
        "\n",
        "            for news, click in zip(impr, impr_label):\n",
        "                if click == 1:\n",
        "                    poss.append(news)\n",
        "                else:\n",
        "                    negs.append(news)\n",
        "\n",
        "            for p in poss:\n",
        "                candidate_title_index = []\n",
        "                impr_index = []\n",
        "                user_index = []\n",
        "                label = [1] + [0] * self.npratio\n",
        "\n",
        "                n = newsample(negs, self.npratio)\n",
        "                candidate_title_index = self.news_title_index[[p] + n]\n",
        "                candidate_ab_index = self.news_ab_index[[p] + n]\n",
        "                candidate_vert_index = self.news_vert_index[[p] + n]\n",
        "                candidate_subvert_index = self.news_subvert_index[[p] + n]\n",
        "                click_title_index = self.news_title_index[self.histories[line]]\n",
        "                click_ab_index = self.news_ab_index[self.histories[line]]\n",
        "                click_vert_index = self.news_vert_index[self.histories[line]]\n",
        "                click_subvert_index = self.news_subvert_index[self.histories[line]]\n",
        "                impr_index.append(self.impr_indexes[line])\n",
        "                user_index.append(self.uindexes[line])\n",
        "\n",
        "                yield (\n",
        "                    label,\n",
        "                    impr_index,\n",
        "                    user_index,\n",
        "                    candidate_title_index,\n",
        "                    candidate_ab_index,\n",
        "                    candidate_vert_index,\n",
        "                    candidate_subvert_index,\n",
        "                    click_title_index,\n",
        "                    click_ab_index,\n",
        "                    click_vert_index,\n",
        "                    click_subvert_index,\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            impr_label = self.labels[line]\n",
        "            impr = self.imprs[line]\n",
        "\n",
        "            for news, label in zip(impr, impr_label):\n",
        "                candidate_title_index = []\n",
        "                impr_index = []\n",
        "                user_index = []\n",
        "                label = [label]\n",
        "\n",
        "                candidate_title_index.append(self.news_title_index[news])\n",
        "                click_title_index = self.news_title_index[self.histories[line]]\n",
        "\n",
        "                candidate_title_index = self.news_title_index[news]\n",
        "                candidate_ab_index = self.news_ab_index[news]\n",
        "                candidate_vert_index = self.news_vert_index[news]\n",
        "                candidate_subvert_index = self.news_subvert_index[news]\n",
        "                click_title_index = self.news_title_index[self.histories[line]]\n",
        "                click_ab_index = self.news_ab_index[self.histories[line]]\n",
        "                click_vert_index = self.news_vert_index[self.histories[line]]\n",
        "                click_subvert_index = self.news_subvert_index[self.histories[line]]\n",
        "                impr_index.append(self.impr_indexes[line])\n",
        "                user_index.append(self.uindexes[line])\n",
        "\n",
        "                yield (\n",
        "                    label,\n",
        "                    impr_index,\n",
        "                    user_index,\n",
        "                    candidate_title_index,\n",
        "                    candidate_ab_index,\n",
        "                    candidate_vert_index,\n",
        "                    candidate_subvert_index,\n",
        "                    click_title_index,\n",
        "                    click_ab_index,\n",
        "                    click_vert_index,\n",
        "                    click_subvert_index,\n",
        "                )\n",
        "\n",
        "    def load_data_from_file(self, news_file, behavior_file):\n",
        "        \"\"\"Read and parse data from a file.\n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "            beahaviros_file (str): A file contains information of user impressions.\n",
        "        Yields:\n",
        "            object: An iterator that yields parsed results, in the format of graph feed_dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        if not hasattr(self, \"impr_indexes\"):\n",
        "            self.init_behaviors(behavior_file)\n",
        "\n",
        "        label_list = []\n",
        "        imp_indexes = []\n",
        "        user_indexes = []\n",
        "        candidate_title_indexes = []\n",
        "        candidate_ab_indexes = []\n",
        "        candidate_vert_indexes = []\n",
        "        candidate_subvert_indexes = []\n",
        "        click_title_indexes = []\n",
        "        click_ab_indexes = []\n",
        "        click_vert_indexes = []\n",
        "        click_subvert_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        indexes = np.arange(len(self.labels))\n",
        "\n",
        "        if self.npratio > 0:\n",
        "            np.random.shuffle(indexes)\n",
        "\n",
        "        for index in indexes:\n",
        "            for (\n",
        "                label,\n",
        "                impr_index,\n",
        "                user_index,\n",
        "                candidate_title_index,\n",
        "                candidate_ab_index,\n",
        "                candidate_vert_index,\n",
        "                candidate_subvert_index,\n",
        "                click_title_index,\n",
        "                click_ab_index,\n",
        "                click_vert_index,\n",
        "                click_subvert_index,\n",
        "            ) in self.parser_one_line(index):\n",
        "                candidate_title_indexes.append(candidate_title_index)\n",
        "                candidate_ab_indexes.append(candidate_ab_index)\n",
        "                candidate_vert_indexes.append(candidate_vert_index)\n",
        "                candidate_subvert_indexes.append(candidate_subvert_index)\n",
        "                click_title_indexes.append(click_title_index)\n",
        "                click_ab_indexes.append(click_ab_index)\n",
        "                click_vert_indexes.append(click_vert_index)\n",
        "                click_subvert_indexes.append(click_subvert_index)\n",
        "                imp_indexes.append(impr_index)\n",
        "                user_indexes.append(user_index)\n",
        "                label_list.append(label)\n",
        "\n",
        "                cnt += 1\n",
        "                if cnt >= self.batch_size:\n",
        "                    yield self._convert_data(\n",
        "                        label_list,\n",
        "                        imp_indexes,\n",
        "                        user_indexes,\n",
        "                        candidate_title_indexes,\n",
        "                        candidate_ab_indexes,\n",
        "                        candidate_vert_indexes,\n",
        "                        candidate_subvert_indexes,\n",
        "                        click_title_indexes,\n",
        "                        click_ab_indexes,\n",
        "                        click_vert_indexes,\n",
        "                        click_subvert_indexes,\n",
        "                    )\n",
        "                    label_list = []\n",
        "                    imp_indexes = []\n",
        "                    user_indexes = []\n",
        "                    candidate_title_indexes = []\n",
        "                    candidate_ab_indexes = []\n",
        "                    candidate_vert_indexes = []\n",
        "                    candidate_subvert_indexes = []\n",
        "                    click_title_indexes = []\n",
        "                    click_ab_indexes = []\n",
        "                    click_vert_indexes = []\n",
        "                    click_subvert_indexes = []\n",
        "                    cnt = 0\n",
        "\n",
        "    def _convert_data(\n",
        "        self,\n",
        "        label_list,\n",
        "        imp_indexes,\n",
        "        user_indexes,\n",
        "        candidate_title_indexes,\n",
        "        candidate_ab_indexes,\n",
        "        candidate_vert_indexes,\n",
        "        candidate_subvert_indexes,\n",
        "        click_title_indexes,\n",
        "        click_ab_indexes,\n",
        "        click_vert_indexes,\n",
        "        click_subvert_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        Args:\n",
        "            label_list (list): a list of ground-truth labels.\n",
        "            imp_indexes (list): a list of impression indexes.\n",
        "            user_indexes (list): a list of user indexes.\n",
        "            candidate_title_indexes (list): the candidate news titles' words indices.\n",
        "            candidate_ab_indexes (list): the candidate news abstarcts' words indices.\n",
        "            candidate_vert_indexes (list): the candidate news verts' words indices.\n",
        "            candidate_subvert_indexes (list): the candidate news subverts' indices.\n",
        "            click_title_indexes (list): words indices for user's clicked news titles.\n",
        "            click_ab_indexes (list): words indices for user's clicked news abstarcts.\n",
        "            click_vert_indexes (list): indices for user's clicked news verts.\n",
        "            click_subvert_indexes (list):indices for user's clicked news subverts.\n",
        "        Returns:\n",
        "            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        labels = np.asarray(label_list, dtype=np.float32)\n",
        "        imp_indexes = np.asarray(imp_indexes, dtype=np.int32)\n",
        "        user_indexes = np.asarray(user_indexes, dtype=np.int32)\n",
        "        candidate_title_index_batch = np.asarray(\n",
        "            candidate_title_indexes, dtype=np.int64\n",
        "        )\n",
        "        candidate_ab_index_batch = np.asarray(candidate_ab_indexes, dtype=np.int64)\n",
        "        candidate_vert_index_batch = np.asarray(candidate_vert_indexes, dtype=np.int64)\n",
        "        candidate_subvert_index_batch = np.asarray(\n",
        "            candidate_subvert_indexes, dtype=np.int64\n",
        "        )\n",
        "        click_title_index_batch = np.asarray(click_title_indexes, dtype=np.int64)\n",
        "        click_ab_index_batch = np.asarray(click_ab_indexes, dtype=np.int64)\n",
        "        click_vert_index_batch = np.asarray(click_vert_indexes, dtype=np.int64)\n",
        "        click_subvert_index_batch = np.asarray(click_subvert_indexes, dtype=np.int64)\n",
        "        return {\n",
        "            \"impression_index_batch\": imp_indexes,\n",
        "            \"user_index_batch\": user_indexes,\n",
        "            \"clicked_title_batch\": click_title_index_batch,\n",
        "            \"clicked_ab_batch\": click_ab_index_batch,\n",
        "            \"clicked_vert_batch\": click_vert_index_batch,\n",
        "            \"clicked_subvert_batch\": click_subvert_index_batch,\n",
        "            \"candidate_title_batch\": candidate_title_index_batch,\n",
        "            \"candidate_ab_batch\": candidate_ab_index_batch,\n",
        "            \"candidate_vert_batch\": candidate_vert_index_batch,\n",
        "            \"candidate_subvert_batch\": candidate_subvert_index_batch,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def load_user_from_file(self, news_file, behavior_file):\n",
        "        \"\"\"Read and parse user data from news file and behavior file.\n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "            beahaviros_file (str): A file contains information of user impressions.\n",
        "        Yields:\n",
        "            object: An iterator that yields parsed user feature, in the format of dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        if not hasattr(self, \"impr_indexes\"):\n",
        "            self.init_behaviors(behavior_file)\n",
        "\n",
        "        user_indexes = []\n",
        "        impr_indexes = []\n",
        "        click_title_indexes = []\n",
        "        click_ab_indexes = []\n",
        "        click_vert_indexes = []\n",
        "        click_subvert_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        for index in range(len(self.impr_indexes)):\n",
        "            click_title_indexes.append(self.news_title_index[self.histories[index]])\n",
        "            click_ab_indexes.append(self.news_ab_index[self.histories[index]])\n",
        "            click_vert_indexes.append(self.news_vert_index[self.histories[index]])\n",
        "            click_subvert_indexes.append(self.news_subvert_index[self.histories[index]])\n",
        "            user_indexes.append(self.uindexes[index])\n",
        "            impr_indexes.append(self.impr_indexes[index])\n",
        "\n",
        "            cnt += 1\n",
        "            if cnt >= self.batch_size:\n",
        "                yield self._convert_user_data(\n",
        "                    user_indexes,\n",
        "                    impr_indexes,\n",
        "                    click_title_indexes,\n",
        "                    click_ab_indexes,\n",
        "                    click_vert_indexes,\n",
        "                    click_subvert_indexes,\n",
        "                )\n",
        "                user_indexes = []\n",
        "                impr_indexes = []\n",
        "                click_title_indexes = []\n",
        "                click_ab_indexes = []\n",
        "                click_vert_indexes = []\n",
        "                click_subvert_indexes = []\n",
        "\n",
        "    def _convert_user_data(\n",
        "        self,\n",
        "        user_indexes,\n",
        "        impr_indexes,\n",
        "        click_title_indexes,\n",
        "        click_ab_indexes,\n",
        "        click_vert_indexes,\n",
        "        click_subvert_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        Args:\n",
        "            user_indexes (list): a list of user indexes.\n",
        "            click_title_indexes (list): words indices for user's clicked news titles.\n",
        "            click_ab_indexes (list): words indices for user's clicked news abs.\n",
        "            click_vert_indexes (list): words indices for user's clicked news verts.\n",
        "            click_subvert_indexes (list): words indices for user's clicked news subverts.\n",
        "        Returns:\n",
        "            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        user_indexes = np.asarray(user_indexes, dtype=np.int32)\n",
        "        impr_indexes = np.asarray(impr_indexes, dtype=np.int32)\n",
        "        click_title_index_batch = np.asarray(click_title_indexes, dtype=np.int64)\n",
        "        click_ab_index_batch = np.asarray(click_ab_indexes, dtype=np.int64)\n",
        "        click_vert_index_batch = np.asarray(click_vert_indexes, dtype=np.int64)\n",
        "        click_subvert_index_batch = np.asarray(click_subvert_indexes, dtype=np.int64)\n",
        "\n",
        "        return {\n",
        "            \"user_index_batch\": user_indexes,\n",
        "            \"impr_index_batch\": impr_indexes,\n",
        "            \"clicked_title_batch\": click_title_index_batch,\n",
        "            \"clicked_ab_batch\": click_ab_index_batch,\n",
        "            \"clicked_vert_batch\": click_vert_index_batch,\n",
        "            \"clicked_subvert_batch\": click_subvert_index_batch,\n",
        "        }\n",
        "\n",
        "    def load_news_from_file(self, news_file):\n",
        "        \"\"\"Read and parse user data from news file.\n",
        "        Args:\n",
        "            news_file (str): A file contains several informations of news.\n",
        "        Yields:\n",
        "            object: An iterator that yields parsed news feature, in the format of dict.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"news_title_index\"):\n",
        "            self.init_news(news_file)\n",
        "\n",
        "        news_indexes = []\n",
        "        candidate_title_indexes = []\n",
        "        candidate_ab_indexes = []\n",
        "        candidate_vert_indexes = []\n",
        "        candidate_subvert_indexes = []\n",
        "        cnt = 0\n",
        "\n",
        "        for index in range(len(self.news_title_index)):\n",
        "            news_indexes.append(index)\n",
        "            candidate_title_indexes.append(self.news_title_index[index])\n",
        "            candidate_ab_indexes.append(self.news_ab_index[index])\n",
        "            candidate_vert_indexes.append(self.news_vert_index[index])\n",
        "            candidate_subvert_indexes.append(self.news_subvert_index[index])\n",
        "\n",
        "            cnt += 1\n",
        "            if cnt >= self.batch_size:\n",
        "                yield self._convert_news_data(\n",
        "                    news_indexes,\n",
        "                    candidate_title_indexes,\n",
        "                    candidate_ab_indexes,\n",
        "                    candidate_vert_indexes,\n",
        "                    candidate_subvert_indexes,\n",
        "                )\n",
        "                news_indexes = []\n",
        "                candidate_title_indexes = []\n",
        "                candidate_ab_indexes = []\n",
        "                candidate_vert_indexes = []\n",
        "                candidate_subvert_indexes = []\n",
        "\n",
        "    def _convert_news_data(\n",
        "        self,\n",
        "        news_indexes,\n",
        "        candidate_title_indexes,\n",
        "        candidate_ab_indexes,\n",
        "        candidate_vert_indexes,\n",
        "        candidate_subvert_indexes,\n",
        "    ):\n",
        "        \"\"\"Convert data into numpy arrays that are good for further model operation.\n",
        "        Args:\n",
        "            news_indexes (list): a list of news indexes.\n",
        "            candidate_title_indexes (list): the candidate news titles' words indices.\n",
        "            candidate_ab_indexes (list): the candidate news abstarcts' words indices.\n",
        "            candidate_vert_indexes (list): the candidate news verts' words indices.\n",
        "            candidate_subvert_indexes (list): the candidate news subverts' words indices.\n",
        "        Returns:\n",
        "            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n",
        "        \"\"\"\n",
        "\n",
        "        news_indexes_batch = np.asarray(news_indexes, dtype=np.int32)\n",
        "        candidate_title_index_batch = np.asarray(\n",
        "            candidate_title_indexes, dtype=np.int32\n",
        "        )\n",
        "        candidate_ab_index_batch = np.asarray(candidate_ab_indexes, dtype=np.int32)\n",
        "        candidate_vert_index_batch = np.asarray(candidate_vert_indexes, dtype=np.int32)\n",
        "        candidate_subvert_index_batch = np.asarray(\n",
        "            candidate_subvert_indexes, dtype=np.int32\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"news_index_batch\": news_indexes_batch,\n",
        "            \"candidate_title_batch\": candidate_title_index_batch,\n",
        "            \"candidate_ab_batch\": candidate_ab_index_batch,\n",
        "            \"candidate_vert_batch\": candidate_vert_index_batch,\n",
        "            \"candidate_subvert_batch\": candidate_subvert_index_batch,\n",
        "        }\n",
        "\n",
        "    def load_impression_from_file(self, behaivors_file):\n",
        "        \"\"\"Read and parse impression data from behaivors file.\n",
        "        Args:\n",
        "            behaivors_file (str): A file contains several informations of behaviros.\n",
        "        Yields:\n",
        "            object: An iterator that yields parsed impression data, in the format of dict.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hasattr(self, \"histories\"):\n",
        "            self.init_behaviors(behaivors_file)\n",
        "\n",
        "        indexes = np.arange(len(self.labels))\n",
        "\n",
        "        for index in indexes:\n",
        "            impr_label = np.array(self.labels[index], dtype=\"int32\")\n",
        "            impr_news = np.array(self.imprs[index], dtype=\"int32\")\n",
        "\n",
        "            yield (\n",
        "                self.impr_indexes[index],\n",
        "                impr_news,\n",
        "                self.uindexes[index],\n",
        "                impr_label,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNKwnwk6uKfo"
      },
      "source": [
        "## LSTUR - the enhanced model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQZN1LtnhYfY"
      },
      "source": [
        "__all__ = [\"LSTUR_enhanced\"]\n",
        "\n",
        "\n",
        "class LSTUR_enhanced(BaseModel):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "        word2vec_embedding (numpy.ndarray): Pretrained word embedding matrix.\n",
        "        hparam (object): Global hyper-parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hparams, iterator_creator, seed=None):\n",
        "\n",
        "        self.word2vec_embedding = self._init_embedding(hparams.wordEmb_file)\n",
        "        self.hparam = hparams\n",
        "\n",
        "        super().__init__(hparams, iterator_creator, seed=seed)\n",
        "\n",
        "    def _get_input_label_from_iter(self, batch_data):\n",
        "        input_feat = [\n",
        "            batch_data[\"user_index_batch\"],\n",
        "            batch_data[\"clicked_title_batch\"],\n",
        "            batch_data[\"clicked_ab_batch\"],\n",
        "            batch_data[\"clicked_vert_batch\"],\n",
        "            batch_data[\"clicked_subvert_batch\"],\n",
        "            batch_data[\"candidate_title_batch\"],\n",
        "            batch_data[\"candidate_ab_batch\"],\n",
        "            batch_data[\"candidate_vert_batch\"],\n",
        "            batch_data[\"candidate_subvert_batch\"],\n",
        "        ]\n",
        "        input_label = batch_data[\"labels\"]\n",
        "        return input_feat, input_label\n",
        "\n",
        "    def _get_user_feature_from_iter(self, batch_data):\n",
        "        \"\"\" get input of user encoder \n",
        "        Args:\n",
        "            batch_data: input batch data from user iterator\n",
        "        \n",
        "        Returns:\n",
        "            numpy.ndarray: input user feature (clicked title batch)\n",
        "        \"\"\"\n",
        "\n",
        "        input_feature = [\n",
        "            batch_data[\"clicked_title_batch\"],\n",
        "            batch_data[\"clicked_ab_batch\"],\n",
        "            batch_data[\"clicked_vert_batch\"],\n",
        "            batch_data[\"clicked_subvert_batch\"],\n",
        "        ]\n",
        "        input_feature = np.concatenate(input_feature, axis=-1)\n",
        "        return [input_feature, batch_data[\"user_index_batch\"]]\n",
        "\n",
        "    def _get_news_feature_from_iter(self, batch_data):\n",
        "        \"\"\" get input of news encoder\n",
        "        Args:\n",
        "            batch_data: input batch data from news iterator\n",
        "        \n",
        "        Returns:\n",
        "            numpy.ndarray: input news feature (candidate title batch)\n",
        "        \"\"\"\n",
        "        input_feature = [\n",
        "            batch_data[\"candidate_title_batch\"],\n",
        "            batch_data[\"candidate_ab_batch\"],\n",
        "            batch_data[\"candidate_vert_batch\"],\n",
        "            batch_data[\"candidate_subvert_batch\"],\n",
        "        ]\n",
        "        input_feature = np.concatenate(input_feature, axis=-1)\n",
        "        return input_feature\n",
        "\n",
        "    def _build_graph(self):\n",
        "        \"\"\"Build NAML model and scorer.\n",
        "        Returns:\n",
        "            object: a model used to train.\n",
        "            object: a model used to evaluate and inference.\n",
        "        \"\"\"\n",
        "\n",
        "        model, scorer = self._build_naml()\n",
        "        return model, scorer\n",
        "\n",
        "    def _build_userencoder(self, titleencoder, type=\"ini\"):\n",
        "        \"\"\"The main function to create user encoder of LSTUR.\n",
        "        Args:\n",
        "            titleencoder(obj): the news encoder of LSTUR. \n",
        "        Return:\n",
        "            obj: the user encoder of LSTUR.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        his_input_title = keras.Input(\n",
        "            shape=(hparams.his_size, hparams.title_size + hparams.body_size + 2), dtype=\"int32\"\n",
        "        )\n",
        "        user_indexes = keras.Input(shape=(1,), dtype=\"int32\")\n",
        "\n",
        "        user_embedding_layer = layers.Embedding(\n",
        "            len(self.train_iterator.uid2index),\n",
        "            hparams.gru_unit,\n",
        "            trainable=True,\n",
        "            embeddings_initializer=\"zeros\",\n",
        "        )\n",
        "\n",
        "        long_u_emb = layers.Reshape((hparams.gru_unit,))(\n",
        "            user_embedding_layer(user_indexes)\n",
        "        )\n",
        "        click_title_presents = layers.TimeDistributed(titleencoder)(his_input_title)\n",
        "\n",
        "        if type == \"ini\":\n",
        "            user_present = layers.GRU(\n",
        "                hparams.gru_unit,\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                recurrent_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "            )(\n",
        "                layers.Masking(mask_value=0.0)(click_title_presents),\n",
        "                initial_state=[long_u_emb],\n",
        "            )\n",
        "        elif type == \"con\":\n",
        "            short_uemb = layers.GRU(\n",
        "                hparams.gru_unit,\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                recurrent_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "            )(layers.Masking(mask_value=0.0)(click_title_presents))\n",
        "\n",
        "            user_present = layers.Concatenate()([short_uemb, long_u_emb])\n",
        "            user_present = layers.Dense(\n",
        "                hparams.gru_unit,\n",
        "                bias_initializer=keras.initializers.Zeros(),\n",
        "                kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "            )(user_present)\n",
        "\n",
        "        model = keras.Model(\n",
        "            [his_input_title, user_indexes], user_present, name=\"user_encoder\"\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def _build_newsencoder(self, embedding_layer):\n",
        "        \"\"\"The main function to create news encoder of NAML.\n",
        "        news encoder in composed of title encoder, body encoder, vert encoder and subvert encoder\n",
        "        Args:\n",
        "            embedding_layer (object): a word embedding layer.\n",
        "        \n",
        "        Return:\n",
        "            object: the news encoder of NAML.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        input_title_body_verts = keras.Input(\n",
        "            shape=(hparams.title_size + hparams.body_size + 2,), dtype=\"int32\"\n",
        "        )\n",
        "\n",
        "        sequences_input_title = layers.Lambda(lambda x: x[:, : hparams.title_size])(\n",
        "            input_title_body_verts\n",
        "        )\n",
        "        sequences_input_body = layers.Lambda(\n",
        "            lambda x: x[:, hparams.title_size : hparams.title_size + hparams.body_size]\n",
        "        )(input_title_body_verts)\n",
        "        input_vert = layers.Lambda(\n",
        "            lambda x: x[\n",
        "                :,\n",
        "                hparams.title_size\n",
        "                + hparams.body_size : hparams.title_size\n",
        "                + hparams.body_size\n",
        "                + 1,\n",
        "            ]\n",
        "        )(input_title_body_verts)\n",
        "        input_subvert = layers.Lambda(\n",
        "            lambda x: x[:, hparams.title_size + hparams.body_size + 1 :]\n",
        "        )(input_title_body_verts)\n",
        "\n",
        "        title_repr = self._build_titleencoder(embedding_layer)(sequences_input_title)\n",
        "        body_repr = self._build_bodyencoder(embedding_layer)(sequences_input_body)\n",
        "        vert_repr = self._build_vertencoder()(input_vert)\n",
        "        subvert_repr = self._build_subvertencoder()(input_subvert)\n",
        "\n",
        "        concate_repr = layers.Concatenate(axis=-2)(\n",
        "            [title_repr, body_repr, vert_repr, subvert_repr]\n",
        "        )\n",
        "        news_repr = AttLayer2(hparams.attention_hidden_dim, seed=self.seed)(\n",
        "            concate_repr\n",
        "        )\n",
        "\n",
        "        model = keras.Model(input_title_body_verts, news_repr, name=\"news_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_titleencoder(self, embedding_layer):\n",
        "        \"\"\"build title encoder of NAML news encoder.\n",
        "        Args:\n",
        "            embedding_layer (object): a word embedding layer.\n",
        "        \n",
        "        Return:\n",
        "            object: the title encoder of NAML.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        sequences_input_title = keras.Input(shape=(hparams.title_size,), dtype=\"int32\")\n",
        "        embedded_sequences_title = embedding_layer(sequences_input_title)\n",
        "        \n",
        "        y = layers.Dropout(hparams.dropout)(embedded_sequences_title)\n",
        "        y = layers.Conv1D(\n",
        "            hparams.filter_num,\n",
        "            hparams.window_size,\n",
        "            activation=hparams.cnn_activation,\n",
        "            padding=\"same\",\n",
        "            bias_initializer=keras.initializers.Zeros(),\n",
        "            kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "        )(y)\n",
        "        y = layers.Dropout(hparams.dropout)(y)\n",
        "        pred_title = AttLayer2(hparams.attention_hidden_dim, seed=self.seed)(y)\n",
        "        pred_title = layers.Reshape((1, hparams.filter_num))(pred_title)\n",
        "\n",
        "        model = keras.Model(sequences_input_title, pred_title, name=\"title_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_bodyencoder(self, embedding_layer):\n",
        "        \"\"\"build body encoder of NAML news encoder.\n",
        "        Args:\n",
        "            embedding_layer (object): a word embedding layer.\n",
        "        \n",
        "        Return:\n",
        "            object: the body encoder of NAML.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        sequences_input_body = keras.Input(shape=(hparams.body_size,), dtype=\"int32\")\n",
        "        embedded_sequences_body = embedding_layer(sequences_input_body)\n",
        "\n",
        "        y = layers.Dropout(hparams.dropout)(embedded_sequences_body)\n",
        "        y = layers.Conv1D(\n",
        "            hparams.filter_num,\n",
        "            hparams.window_size,\n",
        "            activation=hparams.cnn_activation,\n",
        "            padding=\"same\",\n",
        "            bias_initializer=keras.initializers.Zeros(),\n",
        "            kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "        )(y)\n",
        "        y = layers.Dropout(hparams.dropout)(y)\n",
        "        pred_body = AttLayer2(hparams.attention_hidden_dim, seed=self.seed)(y)\n",
        "        pred_body = layers.Reshape((1, hparams.filter_num))(pred_body)\n",
        "\n",
        "        model = keras.Model(sequences_input_body, pred_body, name=\"body_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_vertencoder(self):\n",
        "        \"\"\"build vert encoder of NAML news encoder.\n",
        "        Return:\n",
        "            object: the vert encoder of NAML.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        input_vert = keras.Input(shape=(1,), dtype=\"int32\")\n",
        "\n",
        "        vert_embedding = layers.Embedding(\n",
        "            hparams.vert_num, hparams.vert_emb_dim, trainable=True\n",
        "        )\n",
        "\n",
        "        vert_emb = vert_embedding(input_vert)\n",
        "        pred_vert = layers.Dense(\n",
        "            hparams.filter_num,\n",
        "            activation=hparams.dense_activation,\n",
        "            bias_initializer=keras.initializers.Zeros(),\n",
        "            kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "        )(vert_emb)\n",
        "        pred_vert = layers.Reshape((1, hparams.filter_num))(pred_vert)\n",
        "\n",
        "        model = keras.Model(input_vert, pred_vert, name=\"vert_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_subvertencoder(self):\n",
        "        \"\"\"build subvert encoder of NAML news encoder.\n",
        "        Return:\n",
        "            object: the subvert encoder of NAML.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "        input_subvert = keras.Input(shape=(1,), dtype=\"int32\")\n",
        "\n",
        "        subvert_embedding = layers.Embedding(\n",
        "            hparams.subvert_num, hparams.subvert_emb_dim, trainable=True\n",
        "        )\n",
        "\n",
        "        subvert_emb = subvert_embedding(input_subvert)\n",
        "        pred_subvert = layers.Dense(\n",
        "            hparams.filter_num,\n",
        "            activation=hparams.dense_activation,\n",
        "            bias_initializer=keras.initializers.Zeros(),\n",
        "            kernel_initializer=keras.initializers.glorot_uniform(seed=self.seed),\n",
        "        )(subvert_emb)\n",
        "        pred_subvert = layers.Reshape((1, hparams.filter_num))(pred_subvert)\n",
        "\n",
        "        model = keras.Model(input_subvert, pred_subvert, name=\"subvert_encoder\")\n",
        "        return model\n",
        "\n",
        "    def _build_naml(self):\n",
        "        \"\"\"The main function to create NAML's logic. The core of NAML\n",
        "        is a user encoder and a news encoder.\n",
        "        \n",
        "        Returns:\n",
        "            object: a model used to train.\n",
        "            object: a model used to evaluate and predict.\n",
        "        \"\"\"\n",
        "        hparams = self.hparams\n",
        "\n",
        "        his_input_title = keras.Input(\n",
        "            shape=(hparams.his_size, hparams.title_size), dtype=\"int32\",\n",
        "            name=\"his_input_title\"\n",
        "        )\n",
        "        his_input_body = keras.Input(\n",
        "            shape=(hparams.his_size, hparams.body_size), dtype=\"int32\",\n",
        "            name=\"his_input_body\"\n",
        "        )\n",
        "        his_input_vert = keras.Input(shape=(hparams.his_size, 1), dtype=\"int32\", name=\"his_input_vert\")\n",
        "        his_input_subvert = keras.Input(shape=(hparams.his_size, 1), dtype=\"int32\", name=\"his_input_subvert\")\n",
        "\n",
        "        pred_input_title = keras.Input(\n",
        "            shape=(hparams.npratio + 1, hparams.title_size), dtype=\"int32\",\n",
        "            name=\"pred_input_title\"\n",
        "        )\n",
        "        pred_input_body = keras.Input(\n",
        "            shape=(hparams.npratio + 1, hparams.body_size), dtype=\"int32\",\n",
        "            name=\"pred_input_body\"\n",
        "        )\n",
        "        pred_input_vert = keras.Input(shape=(hparams.npratio + 1, 1), dtype=\"int32\", name=\"pred_input_vert\")\n",
        "        pred_input_subvert = keras.Input(shape=(hparams.npratio + 1, 1), dtype=\"int32\", name=\"pred_input_subvert\")\n",
        "\n",
        "        pred_input_title_one = keras.Input(\n",
        "            shape=(1, hparams.title_size,), dtype=\"int32\", name=\"pred_input_title_one\"\n",
        "        )\n",
        "        pred_input_body_one = keras.Input(shape=(1, hparams.body_size,), dtype=\"int32\", name=\"pred_input_body_one\")\n",
        "        pred_input_vert_one = keras.Input(shape=(1, 1), dtype=\"int32\", name=\"pred_input_vert_one\")\n",
        "        pred_input_subvert_one = keras.Input(shape=(1, 1), dtype=\"int32\", name=\"pred_input_subvert_one\")\n",
        "        user_indexes = keras.Input(shape=(1,), dtype=\"int32\", name=\"user_indexes\")\n",
        "\n",
        "        his_title_body_verts = layers.Concatenate(axis=-1)(\n",
        "            [his_input_title, his_input_body, his_input_vert, his_input_subvert]\n",
        "        )\n",
        "\n",
        "        pred_title_body_verts = layers.Concatenate(axis=-1)(\n",
        "            [pred_input_title, pred_input_body, pred_input_vert, pred_input_subvert]\n",
        "        )\n",
        "\n",
        "        pred_title_body_verts_one = layers.Concatenate(axis=-1)(\n",
        "            [\n",
        "                pred_input_title_one,\n",
        "                pred_input_body_one,\n",
        "                pred_input_vert_one,\n",
        "                pred_input_subvert_one,\n",
        "            ]\n",
        "        )\n",
        "        pred_title_body_verts_one = layers.Reshape((-1,))(pred_title_body_verts_one)\n",
        "\n",
        "        embedding_layer = layers.Embedding(\n",
        "            self.word2vec_embedding.shape[0],\n",
        "            hparams.word_emb_dim,\n",
        "            weights=[self.word2vec_embedding],\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "        self.newsencoder = self._build_newsencoder(embedding_layer)\n",
        "        self.userencoder = self._build_userencoder(self.newsencoder)\n",
        "\n",
        "        user_present = self.userencoder([his_title_body_verts, user_indexes])\n",
        "        news_present = layers.TimeDistributed(self.newsencoder)(pred_title_body_verts)\n",
        "        news_present_one = self.newsencoder(pred_title_body_verts_one)\n",
        "\n",
        "        preds = layers.Dot(axes=-1)([news_present, user_present])\n",
        "        preds = layers.Activation(activation=\"softmax\")(preds)\n",
        "\n",
        "        pred_one = layers.Dot(axes=-1)([news_present_one, user_present])\n",
        "        pred_one = layers.Activation(activation=\"sigmoid\")(pred_one)\n",
        "\n",
        "        model = keras.Model(\n",
        "            [\n",
        "                user_indexes,\n",
        "                his_input_title,\n",
        "                his_input_body,\n",
        "                his_input_vert,\n",
        "                his_input_subvert,\n",
        "                pred_input_title,\n",
        "                pred_input_body,\n",
        "                pred_input_vert,\n",
        "                pred_input_subvert,\n",
        "            ],\n",
        "            preds,\n",
        "        )\n",
        "\n",
        "        scorer = keras.Model(\n",
        "            [\n",
        "                user_indexes,\n",
        "                his_input_title,\n",
        "                his_input_body,\n",
        "                his_input_vert,\n",
        "                his_input_subvert,\n",
        "                pred_input_title_one,\n",
        "                pred_input_body_one,\n",
        "                pred_input_vert_one,\n",
        "                pred_input_subvert_one,\n",
        "            ],\n",
        "            pred_one,\n",
        "        )\n",
        "\n",
        "        return model, scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuS-PVprhUj5"
      },
      "source": [
        "## Train the enahnced model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsveyk5ZhTq0"
      },
      "source": [
        "epochs = 5\n",
        "seed = 40\n",
        "batch_size = 32\n",
        "\n",
        "# Options: demo, small, large\n",
        "# MIND_type = 'demo'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMJUAPPEic3r",
        "outputId": "edaab05a-dac9-4c41-c115-ee2392982641"
      },
      "source": [
        "tmpdir = TemporaryDirectory()\n",
        "data_path = tmpdir.name\n",
        "\n",
        "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
        "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
        "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
        "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
        "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding_all.npy\")\n",
        "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
        "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict_all.pkl\")\n",
        "vertDict_file = os.path.join(data_path, \"utils\", \"vert_dict.pkl\")\n",
        "subvertDict_file = os.path.join(data_path, \"utils\", \"subvert_dict.pkl\")\n",
        "yaml_file = os.path.join(data_path, \"utils\", r'naml.yaml')\n",
        "\n",
        "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
        "\n",
        "if not os.path.exists(train_news_file):\n",
        "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
        "    \n",
        "if not os.path.exists(valid_news_file):\n",
        "    download_deeprec_resources(mind_url, \\\n",
        "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
        "if not os.path.exists(yaml_file):\n",
        "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
        "                               os.path.join(data_path, 'utils'), mind_utils)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51.7k/51.7k [00:03<00:00, 13.7kKB/s]\n",
            "100%|██████████| 30.2k/30.2k [00:02<00:00, 11.3kKB/s]\n",
            "100%|██████████| 152k/152k [00:02<00:00, 61.9kKB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ph4-6fiizZ9",
        "outputId": "70055d58-0b15-4086-e3a3-e68959954676"
      },
      "source": [
        "hparams = prepare_hparams(yaml_file, \n",
        "                          wordEmb_file=wordEmb_file,\n",
        "                          wordDict_file=wordDict_file, \n",
        "                          userDict_file=userDict_file,\n",
        "                          vertDict_file=vertDict_file, \n",
        "                          subvertDict_file=subvertDict_file,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs)\n",
        "print(hparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_format=naml,iterator_type=None,support_quick_scoring=True,wordEmb_file=/tmp/tmp1iw5v56c/utils/embedding_all.npy,wordDict_file=/tmp/tmp1iw5v56c/utils/word_dict_all.pkl,userDict_file=/tmp/tmp1iw5v56c/utils/uid2index.pkl,vertDict_file=/tmp/tmp1iw5v56c/utils/vert_dict.pkl,subvertDict_file=/tmp/tmp1iw5v56c/utils/subvert_dict.pkl,title_size=30,body_size=50,word_emb_dim=300,word_size=None,user_num=None,vert_num=17,subvert_num=249,his_size=50,npratio=4,dropout=0.2,attention_hidden_dim=200,head_num=4,head_dim=100,cnn_activation=relu,dense_activation=relu,filter_num=400,window_size=3,vert_emb_dim=100,subvert_emb_dim=100,gru_unit=400,type=ini,user_emb_dim=50,learning_rate=0.0001,loss=cross_entropy_loss,optimizer=adam,epochs=5,batch_size=32,show_step=100000,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mev2Cj01ih65"
      },
      "source": [
        "iterator = MINDAllIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV9m8cYTiqGF"
      },
      "source": [
        "enhanced_model = LSTUR_enhanced(hparams, iterator, seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtERu-e3iqe-",
        "outputId": "2d46d695-7101-410e-f5ca-55e405482ed8"
      },
      "source": [
        "print(enhanced_model.run_eval(valid_news_file, valid_behaviors_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42386it [02:03, 344.54it/s]\n",
            "73121it [29:47, 40.90it/s]\n",
            "73152it [00:19, 3751.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.5351, 'mean_mrr': 0.2327, 'ndcg@5': 0.2377, 'ndcg@10': 0.3003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_C3hHkuCMj",
        "outputId": "75996c09-c5f0-40e6-85a7-a78d65aa4b26"
      },
      "source": [
        "%%time\n",
        "enhanced_model.fit(train_news_file, train_behaviors_file,valid_news_file, valid_behaviors_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7385it [20:46,  5.93it/s]\n",
            "42386it [01:59, 354.10it/s]\n",
            "73121it [29:20, 41.53it/s]\n",
            "73152it [00:18, 3853.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 1\n",
            "train info: logloss loss:1.3695503628326575\n",
            "eval info: group_auc:0.659, mean_mrr:0.3111, ndcg@10:0.4076, ndcg@5:0.345\n",
            "at epoch 1 , train time: 1246.1 eval time: 1988.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7385it [19:57,  6.17it/s]\n",
            "42386it [01:58, 357.70it/s]\n",
            "73121it [29:03, 41.94it/s]\n",
            "73152it [00:19, 3742.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 2\n",
            "train info: logloss loss:1.2914329702820257\n",
            "eval info: group_auc:0.6658, mean_mrr:0.3122, ndcg@10:0.4111, ndcg@5:0.3494\n",
            "at epoch 2 , train time: 1197.1 eval time: 1969.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7385it [20:10,  6.10it/s]\n",
            "42386it [01:59, 356.05it/s]\n",
            "73121it [28:43, 42.43it/s]\n",
            "73152it [00:19, 3843.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 3\n",
            "train info: logloss loss:1.2649976140595645\n",
            "eval info: group_auc:0.6685, mean_mrr:0.3176, ndcg@10:0.4146, ndcg@5:0.3524\n",
            "at epoch 3 , train time: 1210.2 eval time: 1949.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7385it [20:04,  6.13it/s]\n",
            "42386it [01:58, 357.59it/s]\n",
            "73121it [29:20, 41.53it/s]\n",
            "73152it [00:19, 3715.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 4\n",
            "train info: logloss loss:1.2462980859087542\n",
            "eval info: group_auc:0.6712, mean_mrr:0.3171, ndcg@10:0.4152, ndcg@5:0.3527\n",
            "at epoch 4 , train time: 1204.8 eval time: 1986.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7385it [20:07,  6.12it/s]\n",
            "42386it [01:58, 357.00it/s]\n",
            "73121it [29:19, 41.55it/s]\n",
            "73152it [00:19, 3820.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 5\n",
            "train info: logloss loss:1.2310148035261224\n",
            "eval info: group_auc:0.6753, mean_mrr:0.3211, ndcg@10:0.4198, ndcg@5:0.3577\n",
            "at epoch 5 , train time: 1207.5 eval time: 1986.0\n",
            "CPU times: user 8h 5min 35s, sys: 57min 19s, total: 9h 2min 55s\n",
            "Wall time: 4h 25min 44s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.LSTUR_enhanced at 0x7f347c15aa90>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HogIGifSv5aY"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV1YdoMTwAz8",
        "outputId": "351e84e4-c834-4955-da90-3ccc58ef0bf6"
      },
      "source": [
        "plt.plot([float(l.split(':')[-1]) for l in enhanced_model.history_loss['train']], label='logloss')\n",
        "plt.title('training loss over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3yV9d3/8dcng7BCGAkjYcmWlahRHAhBreICt7bWUa3W1but2tqhta3WOqq3eltvar39WWu1dRZErQgytM6oCXsLAgESwt4Zn98f50JP6QkEyMl1kryfj8d5PM4532t8csE57/P9XsvcHRERkb0lhV2AiIgkJgWEiIjEpIAQEZGYFBAiIhKTAkJERGJSQIiISEwKCAmVmY0zszvqetoDrKGnmbmZpdT1sps6M/uVmT0bdh1ycPSBkINmZsuA77r75INdhrtfF49pReTQqQchcaNf5OHRtpe6oICQg2JmfwG6A6+Z2VYz+0nUUM3VZvYl8E4w7YtmtsbMNpnZDDMbFLWcp83s7uB5gZmtNLNbzKzUzFab2XcOctoOZvaamW02s0/M7G4ze6+Wf1u2mU0ws/VmttjMrolqO8bMCoPlrjWzh4L3m5vZs2ZWbmYbg3V2qmH5h5vZtGC6OWY2Jnh/WLCdkqOmPdfMZgbPk8zsp2a2JFjPC2bWPmiLue1jrPssMysK1v2+mQ2NaltmZj8zs7lmtsHM/p+ZNY9qvybYHuuD7ZMd1TbIzN4O2taa2c+jVtvMzJ4xsy3B35sfNd9tZrYqaFtgZifX5t9I6ocCQg6Ku18GfAmc7e6t3f3+qOaRwOHAacHrN4G+QEfgM+Cv+1h0ZyADyAGuBv5gZu0OYto/ANuCaa4IHrX1N2AlkA1cANxjZicFbY8Aj7h7G6A38ELw/hVBLd2ADsB1wI69F2xmqcBrwCQi2+P7wF/NrL+7fxTUfFLULN8Cnguefx84h8j2zQY2BH9ntL23ffS6jwCeAr4X1PhHYIKZpUVNdmkwb2+gH3B7MO9JwO+Ai4AuwPJgO2Fm6cBk4J9BXX2AKVHLHBNM2xaYADwWzNcfuAk42t3Tg/Uu27tuCZG766HHQT2IfJhPiXrdE3Cg1z7maRtMkxG8fhq4O3heQORLNSVq+lLg2AOZFkgGKoD+UW13A+/VUNOeulOIfMFXAelR7b8Dng6ezwB+DWTutYyrgPeBofvZZicCa4CkqPeeB34VVedTwfN0IoHRI3g9Dzg5ar4uwd+ZUstt/7/AXXu9twAYGfXveV1U2xnAkuD5/wH3R7W1DtbdE/gm8HkN6/wVMDnq9UBgR/C8T/BvdgqQGvb/Zz3+86EehMTDij1PzCzZzO4NhkU28/UvxMwa5i1398qo19uJfBkdyLRZRL40V0S1RT/fl2xgvbtviXpvOZFeCkR6Kv2A+cEw0lnB+38B3gL+ZmYlZnZ/0FuItfwV7l5dw/KfA84LftWfB3zm7suDth7Aq8Hw0EYigVEFRA9l7evv7AHcsmf+YBndgppizb88qi07eA2Au28FyoO6uwFL9rHeNVHPtwPNzSzF3RcDPyQSIqVm9rfoYSsJnwJCDkVNlwKOfv9bwFgivxIziPziBLD4lUUZUAl0jXqvWy3nLQHaB8Mme3QHVgG4+yJ3/yaR4aH7gJfMrJW7V7j7r919IHA8cBZweQ3L72Zm0Z+96OXPJfJFfDr/PrwEkS/v0929bdSjubuvippmX5dnXgH8dq/5W7r781HTRG+n7kG9e+rusafBzFoRGaZaFSy31z7WWyN3f87dhwfLdiLbVBKEAkIOxVr2/8WQDuwi8muzJXBPvIty9yrgFeBXZtbSzAYQ+8s61rwriAwV/S7Y8TyUSK/hWQAz+7aZZQU9gI3BbNVmNsrMhgQ7mDcTGX6pjrGKj4j8iv6JmaWaWQFwNsF4fuA54AfACODFqPfHAb81sx5BLVlmNrY2f1fgT8B1wc5wM7NWZnbmXmF4o5l1DXZ+/wL4e/D+88B3zCwv6N3cA3zk7suAiUAXM/uhmaWZWbqZDdtfMWbW38xOCpa3k8iQYaxtJiFRQMih+B1wezBccWsN0zxD5BfxKmAu8GE91XYTkR7LGiLDP88TCara+CaRnk4J8Cpwp399rsdoYI6ZbSWyw/oSd99BZGf4S0TCYR4wPVjvv3H33UQC4XRgHfA4cLm7z4+a7HkiO5vfcfd1Ue8/QmQn7yQz20JkW+73izhq3YXANUR2Em8AFgNX7jXZc0R2oC8lMmx0dzDvZOAO4GVgNZGd2JcEbVuAbwR/1xpgETCqFiWlAfcS2Q5riPTKflbbv0fiz9x1wyBp/MzsPqCzux/I0UxNitXBiY/SuKgHIY2SmQ0ws6HBUMoxRIaJXg27LpGGRGdbSmOVTmSoJpvIvpIHgfGhViTSwGiISUREYtIQk4iIxNSohpgyMzO9Z8+eYZchItJgfPrpp+vcPStWW6MKiJ49e1JYWBh2GSIiDYaZLa+pTUNMIiISkwJCRERiUkCIiEhMCggREYlJASEiIjEpIEREJCYFhIiIxNTkA6Kq2vnfaUsoWrFx/xOLiDQhTT4gtu2u5JkPlnHLC0XsrKgKuxwRkYTR5AOiTfNUHrgglyVl23jgrQVhlyMikjCafEAADO+byeXH9eCpf33Bh0vLwy5HRCQhKCACPz19AD3at+TWF4vZuqsy7HJEREKngAi0bJbCgxflUrJxB3dPnBt2OSIioVNARDmqR3uuHdGbv32ygqnzS8MuR0QkVAqIvfzoG30Z0Dmd216eycbtu8MuR0QkNAqIvaSlJPPgRbms37abO8bPCbscEZHQKCBiGJSdwQ9O7strxSVMnFkSdjkiIqFQQNTg+oLe5HZry+3/mE3plp1hlyMiUu8UEDVISU7iwQtz2bG7ip+9PAt3D7skEZF6FbeAMLOnzKzUzGbX0D7WzGaaWZGZFZrZ8Ki27mY2yczmmdlcM+sZrzr3pU/H1tw2egBT5pfyYuHKMEoQEQlNPHsQTwOj99E+Bch19zzgKuDJqLZngAfc/XDgGCC0Y06vPL4nx/Zqz28mzmXF+u1hlSEiUu/iFhDuPgNYv4/2rf71uE0rwAHMbCCQ4u5vR00X2jdzUpLxwAW5APz4pWKqqzXUJCJNQ6j7IMzsXDObD7xOpBcB0A/YaGavmNnnZvaAmSXvYxnXBkNUhWVlZXGps1v7ltxx1uF8uHQ9f/5gWVzWISKSaEINCHd/1d0HAOcAdwVvpwAnArcCRwO9gCv3sYwn3D3f3fOzsrLiVutF+d04aUBH7n1zPkvKtsZtPSIiiSIhjmIKhqN6mVkmsBIocvel7l4J/AM4MtQCATPj3vOG0KJZMje/UExlVXXYJYmIxFVoAWFmfczMgudHAmlAOfAJ0NbM9nQHTgIS4up5Hds0566xgylesZFx05eEXY6ISFylxGvBZvY8UABkmtlK4E4gFcDdxwHnA5ebWQWwA7g42GldZWa3AlOCAPkU+FO86jxQZ+dm89acNTwyZRGjBnRkUHZG2CWJiMSFNaYTwPLz872wsDDu69mwbTenPjyDDq2aMf6mE0hLqXEfuohIQjOzT909P1ZbQuyDaGjatWrGfecPYf6aLTw8eVHY5YiIxIUC4iCdNKATF+d344/Tl/Dp8hpP9xARabAUEIfg9rMOp0tGC255oZjtu3WbUhFpXBQQhyC9eSq/vzCXZeXbue/N+WGXIyJSpxQQh+i43h246oTD+PMHy/nX4nVhlyMiUmcUEHXgJ6P70yurFT9+sZjNOyvCLkdEpE4oIOpA89RkHrooj7VbdvHrCQlxTp+IyCFTQNSRvG5tuaGgNy9/tpJJc9aEXY6IyCFTQNSh75/Ul4Fd2vDzV2dRvnVX2OWIiBwSBUQdapaSxEMX57J5RyW3/2O2blMqIg2aAqKODejchh99ox9vzl7D+KKSsMsRETloCog4uHZEL47q0Y5fjp/Nmk07wy5HROSgKCDiIDnJePDCXCqqnNtenqmhJhFpkBQQcdIzsxU/P2MA0xeW8dzHX4ZdjojIAVNAxNGlw3owvE8mv319HsvLt4VdjojIAVFAxFFSknH/BUNJTjJufbGYqmoNNYlIw6GAiLPsti341dmD+GTZBp5674uwyxERqTUFRD0478gcTh3YiQcmLWDh2i1hlyMiUisKiHpgZtxz3hBap6Vw8wtFVFRVh12SiMh+xTUgzOwpMys1s9k1tI81s5lmVmRmhWY2fK/2Nma20swei2ed9SGzdRr3nDuY2as289g7i8MuR0Rkv+Ldg3gaGL2P9ilArrvnAVcBT+7VfhcwIz6l1b/Rg7tw7hE5PDZ1MbNWbgq7HBGRfYprQLj7DKDGGza7+1b/+iyyVsBXh/mY2VFAJ2BSPGusb786exBZrdO4+YUidlZUhV2OiEiNQt8HYWbnmtl84HUivQjMLAl4ELi1FvNfGwxPFZaVlcW32DqQ0TKV+y4YyqLSrTw4aUHY5YiI1Cj0gHD3V919AHAOkSElgBuAN9x9ZS3mf8Ld8909PysrK56l1pmR/bK4dFh3nnzvCz5aWh52OSIiMYUeEHsEw1G9zCwTOA64ycyWAb8HLjeze8Osr679/IzD6dauJbe+VMy2XZVhlyMi8h9CDQgz62NmFjw/EkgDyt39Unfv7u49iQwzPePuPw2x1DrXKi2FBy/KZeWGHfz2jXlhlyMi8h9S4rlwM3seKAAyzWwlcCeQCuDu44DzifQOKoAdwMXehC59enTP9lxzYi+emLGUUwd2oqB/x7BLEhH5ijWm7+P8/HwvLCwMu4wDsrOiijGPvcemHRVM+uFIMlqmhl2SiDQhZvapu+fHakuYfRBNVfPUZB66KI/yrbv55YSY5xOKiIRCAZEABudk8P2T+jK+qIQ3Zq0OuxwREUABkTBuGNWboV0z+MWrsyjbsivsckREFBCJIjU5iQcvzGXb7ip+9sos3aZUREKngEggfTul85PT+jN53lpe+nS/5wiKiMSVAiLBXHXCYRxzWHt+89pcVm3cEXY5ItKEKSASTFKS8eCFuVS585OXiqnWbUpFJCQKiATUrX1Lbj9zIP9aXM5fPlwedjki0kQpIBLUN4/pRkH/LH735jyWlm0NuxwRaYIUEAnKzLjv/KGkpSRzy4vFVGmoSUTqmQIigXVq05zfjB3E519u5I8zloRdjog0MQqIBDcmN5szhnTmv99eyLzVm8MuR0SaEAVEgjMz7j5nCBktmnHzC8XsrqwOuyQRaSIUEA1A+1bNuPe8IcxbvZlHpiwMuxwRaSIUEA3EKQM7ceFRXfnfaUv4/MsNYZcjIk2AAqIBuePsgXTJaMEtLxSzY3dV2OWISCOngGhA2jRP5YELhrJ03Tbu++f8sMsRkUZOAdHAHN8nkyuP78nT7y/j/cXrwi5HRBoxBUQDdNvoAfTKbMWPX5rJlp0VYZcjIo2UAqIBatEsmd9flMvqTTu4a+LcsMsRkUYqbgFhZk+ZWamZxbzRspmNNbOZZlZkZoVmNjx4P8/MPjCzOUH7xfGqsSE7sns7rhvZmxcKVzJ57tqwyxGRRiiePYingdH7aJ8C5Lp7HnAV8GTw/nbgcncfFMz/sJm1jWOdDdYPTunLgM7p/PSVWazftjvsckSkkYlbQLj7DGD9Ptq3+tf31WwFePD+QndfFDwvAUqBrHjV2ZClpSTz3xfnsWnHbu74x2zdplRE6lSo+yDM7Fwzmw+8TqQXsXf7MUAzoMYr1ZnZtcEQVWFZWVn8ik1Qh3dpww9P6cfrs1bz2szVYZcjIo1IqAHh7q+6+wDgHOCu6DYz6wL8BfiOu9d4ASJ3f8Ld8909PyuraXY0vjeiF0d0b8sd/5jN2s07wy5HRBqJhDiKKRiO6mVmmQBm1oZIr+IX7v5hqMU1ACnJSTx4YS67Kqu47eWZGmoSkToRWkCYWR8zs+D5kUAaUG5mzYBXgWfc/aWw6mtoemW15qejBzBtQRl/+2RF2OWISCOQEq8Fm9nzQAGQaWYrgTuBVAB3HwecD1xuZhXADuBid3czuwgYAXQwsyuDxV3p7kXxqrWxuPy4nkyau5a7J85leJ9MurVvGXZJItKAWWMajsjPz/fCwsKwywjVyg3bGf3wuwzKbsPz1xxLUpKFXZKIJDAz+9Td82O1JcQ+CKk7Xdu15JdnD+SjL9bz1L++CLscEWnAFBCN0IVHdeWUwzty/1sLWFy6JexyRKSBUkA0QmbGPecNoVWzZG5+oZjKKt2mVEQOnAKikeqY3py7zxnCzJWbeHxajecZiojUSAHRiJ05tAtjcrN5dMoiZq/aFHY5ItLAKCAaud+MHUT7Vs24+YUidlboNqUiUnsKiEaubctm3HfBUBau3cp/v70w7HJEpAFRQDQBo/p35JvHdOeJd5dSuKzGC+yKiPwbBUQT8YszD6druxbc8mIx23ZVhl2OiDQACogmonVaCr+/IJcv12/nd2/OC7scEWkAFBBNyLBeHbj6hMN49sMvmbGw6d07Q0QOjAKiibn1tP706dian7w0k007KsIuR0QSmAKiiWmemsxDF+VStnUXv54wJ+xyRCSBKSCaoKFd23LjqD688vkq/jl7TdjliEiCUkA0Ud8/qQ+Dc9rwi1dnsW7rrrDLEZEEpIBoolKTk3joojy27Kzk56/M0m1KReQ/1CogzOwHZtbGIv7PzD4zs1PjXZzEV79O6dxyaj8mzV3Lq5+vCrscEUkwte1BXOXum4FTgXbAZcC9catK6s13T+zF0T3bceeEOZRs3BF2OSKSQGobEHvuW3kG8Bd3nxP1njRgyUnG7y/Mparaue3lmRpqEpGv1DYgPjWzSUQC4i0zSwf2excaM3vKzErNbHYN7WPNbKaZFZlZoZkNj2q7wswWBY8ralmnHIQeHVrx8zMO591F63j2w+VhlyMiCaK2AXE18FPgaHffDqQC36nFfE8Do/fRPgXIdfc84CrgSQAzaw/cCQwDjgHuNLN2taxVDsKlw7pzYt9M7nljPsvWbQu7HBFJALUNiOOABe6+0cy+DdwO7PcONO4+A6jx8qHuvtW/HtNoBex5fhrwtruvd/cNwNvsO2jkEJkZ918wlJRk49YXi6mq1lCTSFNX24D4X2C7meUCtwBLgGfqogAzO9fM5gOvE+lFAOQAK6ImWxm8F2v+a4PhqcKyMl1f6FB0yWjBb8YOonD5Bv707tKwyxGRkNU2ICqDX/pjgcfc/Q9Ael0U4O6vuvsA4BzgroOY/wl3z3f3/KysrLooqUk7Jy+H0YM689CkhcxfsznsckQkRLUNiC1m9jMih7e+bmZJRPZD1JlgOKqXmWUCq4BuUc1dg/ckzsyM3547mPTmKdzyQjG7K/d7LIKINFK1DYiLgV1EzodYQ+QL+4FDXbmZ9TEzC54fCaQB5cBbwKlm1i7YOX1q8J7Ugw6t07jnvCHMKdnMY+8sCrscEQlJSm0mcvc1ZvZX4GgzOwv42N33uw/CzJ4HCoBMM1tJ5Mik1GCZ44DzgcvNrALYAVwcDGWtN7O7gE+CRf3G3XWvzHp02qDOnHdkDn+YtoSTD+9Ebre2YZckIvXManNilJldRKTHMI3ICXInAj9295fiWt0Bys/P98LCwrDLaDQ27ahg9MMzaNksmdf/60SapyaHXZKI1DEz+9Td82O11XaI6RdEzoG4wt0vJ3Juwh11VaAkpowWqTxwQS5LyrbxwFsLwi5HROpZbQMiyd1Lo16XH8C80oAN75vJZcf24Kl/fcGHS8vDLkdE6lFtv+T/aWZvmdmVZnYlkXMW3ohfWZJIfnbGAHq0b8mtLxazdVdl2OWISD2pVUC4+4+BJ4ChweMJd78tnoVJ4mjZLIUHL8qlZOMO7p44N+xyRKSe1OooJgB3fxl4OY61SAI7qkd7rh3Rm3HTl3DqoE6cNKBT2CWJSJztswdhZlvMbHOMxxYz02m2TcyPvtGX/p3Sue3lWWzYtjvsckQkzvYZEO6e7u5tYjzS3b1NfRUpiSEtJZkHL8plw7bdXPTHD3h95mqqdVE/kUZLRyLJARmck8G4bx9FlTs3PvcZpz08gwnFJbr6q0gjpICQA3bKwE68/aORPHJJHg781/Ofc9rDMxhftEpBIdKI1OpM6oZCZ1LXv+pq543Zq3l0yiIWrt1Kr6xWfP+kPpw9NJuUZP3+EEl0+zqTWgEhdaK62vnnnDU8OmUR89ds4bDMVtw0qg9j8xQUIolMASH1prramTR3DY9MWcy81Zvp2aElN47qw7lH5CgoRBKQAkLqXXW18/a8tTw6ZRFzSjbTvX1LbhrVh3OPzCFVQSGSMBQQEhp3Z/K8Uh6dsohZqzbRtV0LbhzVh/OP7EqzFAWFSNgUEBI6d2fqglIembyI4pWbyGnbghtG9ebCo7opKERCpICQhOHuTFtYxiOTF1G0YiPZGc25flQfLsrvSlqK7jchUt8UEJJw3J0Zi9bxyOSFfPblRrpkNOf6gt5clN9NNyYSqUcKCElY7s57i9fxyORFFC7fQKc2aVw/sjeXHNNdQSFSDxQQkvDcnQ+WlPPwlEV8/MV6Oqan8b2Rvbl0mIJCJJ4UENKgfLCknIcnL+SjL9aT2TqN60b24tJhPWjRTEEhUtfq4p7UB7PSp8ys1Mxm19B+qZnNNLNZZva+meVGtf3IzOaY2Wwze97MmserTkk8x/XuwN+/dxx/u/ZY+nVqzd2vz+PE+9/hiRlL2L5bd7QTqS/xPL7waWD0Ptq/AEa6+xDgLiJ3rMPMcoD/AvLdfTCQDFwSxzolQR3bqwPPXXMsL153HAM6t+GeN+Zz4n1TGTd9Cdt061ORuItbQLj7DGD9Ptrfd/cNwcsPga5RzSlACzNLAVoCJfGqUxLf0T3b8+x3h/Hy9ccxMLsN9745nxPvn8rj0xbrHtkicZQoZyhdDbwJ4O6rgN8DXwKrgU3uPqmmGc3sWjMrNLPCsrKyeilWwnFUj/b85ephvHLD8QzJyeD+fy5g+H3v8Ng7i9iysyLs8kQanbjupDaznsDEYKiopmlGAY8Dw9293MzaEbn39cXARuBF4CV3f3Z/69NO6qalaMVGHp2yiHfml5LRIpWrhx/GlSf0pE3z1LBLE2kwQtlJXRtmNhR4Ehjr7uXB26cAX7h7mbtXAK8Ax4dVoySuvG5teerKo5lw0wkc3bMdD729kOH3vsPDkxeyaYd6FCKHKrSAMLPuRL78L3P3hVFNXwLHmllLMzPgZGBeGDVKwzC0a1uevOJoJn5/OMN6deDhyYsYft87PPT2QjZtV1CIHKy4DTGZ2fNAAZAJrAXuBFIB3H2cmT0JnA8sD2ap3NPNMbNfExliqgQ+B77r7rv2t04NMQnAnJJNPDplEW/NWUt6WgpXntCTq4cfRtuWzcIuTSTh6EQ5aZLmrd7Mo1MW8ebsNbROS+GK43vw3eG9aNdKQSGyhwJCmrQFa7bw6DuLeGPWalqmJnP58T255sRetFdQiCggRAAWrt3C/7yzmIkzS2iRmsxlx/bgmhG9yGydFnZpIqFRQIhEWVwaCYrXiktIS0nm28d259oRvclKV1BI06OAEIlhSdlWHntnMeOLVtEsJYlLh/XgeyN70TFdl/6SpkMBIbIPS8u28tjUxYwvKiElyfjWsO5cN7I3ndooKKTxU0CI1MKyddv4w9TFvPL5KpKTjG8dEwmKzhkKCmm8FBAiB+DL8u38YepiXv5sJUlmXHJMN64b2Zvsti3CLk2kzikgRA7CivXbeXzaYl4sjATFhflduWFUH3IUFNKIKCBEDsHKDdt5fNoSXixcAcAFR3XjxlG96dquZciViRw6BYRIHVi1cQfjpi3h75+soNqdC47qyo2j+tCtvYJCGi4FhEgdWr0pEhTPf7KC6mrnvCNzuGlUX7p3UFBIw6OAEImDNZt2Mm76Ep77+Euqqp1zj8jhplF96JnZKuzSRGpNASESR6WbdzJu+lL++tFyKqqqOScvh5tO6kOvrNZhlyayXwoIkXpQumUnT0xfyrMfLWd3ZTVjcrO56aS+9OmooJDEpYAQqUdlW3bxp3eX8pcPlrOzsoqzh2Zz7YheDMpuQ+QeWCKJQwEhEoLyrbv407tf8MwHy9i+u4q+HVszJjebMXnZ9Oig/RSSGBQQIiHauH03E2euZkJRCR8vWw9E7qc9Ni+bM4d20cUBJVQKCJEEsWrjDiYWlzC+qIS5qzeTZHB870zG5GVz2qDOZLRIDbtEaWIUECIJaNHaLUwIwuLL9dtplpzEqAFZjM3L4aQBHWmemhx2idIEhBIQZvYUcBZQ6u6DY7RfCtwGGLAFuN7di4O2tsCTwGDAgavc/YP9rVMBIQ2Ru1O8chPji1bxWvFq1m3dReu0FE4d1ImxeTmc0LsDKclJYZcpjVRYATEC2Ao8U0NAHA/Mc/cNZnY68Ct3Hxa0/Rl4192fNLNmQEt337i/dSogpKGrqnY+WFLOhOJVvDl7DVt2VpLZuhlnDunCmLwcjuzeVkdCSZ0KbYjJzHoCE2MFxF7TtQNmu3uOmWUARUAvP8DiFBDSmOysqGLagjImFK9i8rxSdldW07VdC8bkZjM2L4f+ndPDLlEagX0FREp9F1ODq4E3g+eHAWXA/zOzXOBT4Afuvi2s4kTC0Dw1mdGDOzN6cGe27Kxg0py1jC8u4Y8zlvL4tCUM6JzO2bnZjMnN1gUDJS5C70GY2SjgcWC4u5ebWT7wIXCCu39kZo8Am939jhrmvxa4FqB79+5HLV++vI7/CpHEUrZlF2/MWs2E4hI+Xb4BgKN6tGNsXjZnDOlCZuu0kCuUhiRhh5jMbCjwKnC6uy8M3usMfOjuPYPXJwI/dfcz97c+DTFJU7Ni/XYmFJfwWnEJ89dsITnJOKFPJmNzszl1UCfSm+uwWdm3hBxiMrPuwCvAZXvCAcDd15jZCjPr7+4LgJOBuWHVKZLIurVvyY2j+nDjqD7MX7OZCUWRw2ZvebGYtFeTOOXwTpydm01B/ywdNisHLJ5HMT0PFACZwFrgTiAVwN3HmdmTwPnAnjGhyj0pZmZ5RA5zbQYsBb7j7hv2t071IEQih81+9uVGJhStYuLM1ZRv20168xROH9yZsXk5HNurAzOLAggAAA1XSURBVMlJOhJKInSinEgTVVlVzb+WlDO+aBWT5qxl665KstLTOGtoF8bm5ZDbNUOHzTZxCggRYWdFFe/ML2V80Sqmzi9jd1U1PTq0ZGxwAcE+HXXYbFOkgBCRf7NpRwVvzVnDhKIS3l+yjmqHgV3aMDYvm7Nzs8lu2yLsEqWeKCBEpEalm3cyceZqxheXULwicsGCYw5rz5jcyGGz7Vs1C7lCiScFhIjUyrJ123ituITxxSUsLt1KSpIxol8WY/OyOeXwTrRKS5Rza6WuKCBE5IC4O/NWb2F88SpeKyqhZNNOWqQmc8rATozNzWZEvyyapegCgo2BAkJEDlp1tVO4fAMTilfx+szVbNheQUaLVM4Y0pkxuTkMO6w9STpstsFSQIhInaioqua9Resih83OXcv23VV0btOcs3Mjh83qvtsNjwJCROrc9t2VTJlXyviiEqYvLKWiyumV2YoxeZELCPbKah12iVILCggRiauN23fz5uzIYbMfflGOOwztmsGY3GzOGppN5wzddztRKSBEpN6s2bSTiTMj14SatWoTZnDsYR0Ym5fN6YO7kNFSFxBMJAoIEQnF0rKtTCguYUJRCUvXbSM12RjZr+NXh822aKYLCIZNASEioXJ3Zq/aHLnv9swS1m7eRctmyZw2qDNjcrMZ3jeTVN13OxQKCBFJGFXVzsdfrGdC8SremLWGTTsqaNcylTODCwge1b2dDputRwoIEUlIuyurmbGwjPHFJbw9dw07K6rJzmjOGUO6MGpAR/J7tiMtRcNQ8aSAEJGEt21XJZPnrWV8UQnvLVrH7qpqWjZL5oQ+mRT0z6Kgf0dydBHBOpeQd5QTEYnWKi2FsXk5jM3LYfvuSt5fXM60haVMnV/G23PXAtCvU2sK+nekoF8W+T3b63IfcaYehIgkNHdnSdlWpi0oY+qCUj7+Yj0VVU6roHcxakBHCvpn0SVDvYuDoR6EiDRYZkafjun06ZjOd0/sxbZdlby/pJypC0qZvqCMSUHvon+ndAoGZFHQL7LvQkdFHTr1IESkwXJ3FpVuZdqCUqYtKOOTZZHeReu0FIZH7bvQmdw1005qEWkStu6q5F+L1zFtQRnTFpSyetNOAAZ0Tqegf0dG9c/iyB7qXUQLJSDM7CngLKDU3QfHaL8UuA0wYAtwvbsXR7UnA4XAKnc/qzbrVECIyB7uzsK1kd7F1AWlFC7bQGW1k56WwvC+mYzq35GR/bPo1KZp9y7C2gfxNPAY8EwN7V8AI919g5mdDjwBDItq/wEwD2gTxxpFpJEyM/p3Tqd/53S+N7I3W3ZWRPUuynhz9hoADu/ShlHBUNSR3duSot7FV+I6xGRmPYGJsXoQe03XDpjt7jnB667An4HfAjerByEidcndmb9my1dDUYXLN1BV7aQ3T2FE3yxG9s+ioF8WHZtA76IhHMV0NfBm1OuHgZ8A6fub0cyuBa4F6N69e1yKE5HGxcw4vEsbDu/ShusLerN5ZwX/WrTuq0NpX5+1GoBB2W0o6J/FqP4dyevW9HoXofcgzGwU8Dgw3N3Lzews4Ax3v8HMCoBb1YMQkfqy537c0xaWMm1+GZ9+GeldtGmewon9ImExsl8WWelpYZdaJxK2B2FmQ4EngdPdvTx4+wRgjJmdATQH2pjZs+7+7bDqFJGmw8wYmN2GgdltuKGgD5t2VPDeonWRQ2kXlvH6zEjvYkhORnAYbRZ53dqR3AgvMBhaD8LMugPvAJe7+/s1zF+AehAikiCqq525qzczfWFk38WnyzdQ7dC2ZSon9o3stxjZP4vM1g2ndxFKD8LMngcKgEwzWwncCaQCuPs44JdAB+Dx4CbnlTUVKSKSCJKSjME5GQzOyeDGUX3YtL2CdxeXfXVk1GvFJUDkdqsF/bIoGNCR3K5tG2zvQifKiYjUgT29i6nzI0NRn38Z6V20a5nKiH6RoagRfbPokGC9C51JLSJSzzZu382MYN/F9AVllG/bjRkM7do20rvon8XQBOhdKCBEREJUXe3MLtn01WG0RSs24g7tWzVjRN9MCvp3ZES/LNq3albvtSkgREQSyIZtu5mxKLLfYvrCMtYHvYvcrm0Z1T9y+fIhORn1cutVBYSISIKqrnZmrdrE1OCKtMUrI72LDq2aMTI4KmpE3yzaxal3oYAQEWkgyrfu4t09+y4WlrFhewVJBnnd2kbuptc/i8HZdde7UECIiDRAVdXOzJUbv7pm1MxVm3CHzNbNGBGc1T2ibxYZLVMPeh0KCBGRRqB86y5mLCpj6vwyZiwqY2PQu8jv0Z7nrhl2UNeKSthLbYiISO11aJ3GuUd05dwjulJV7RSt2Mj0BaWUbtkVlwsJKiBERBqg5CTjqB7tOKpHu7ito2ldu1ZERGpNASEiIjEpIEREJCYFhIiIxKSAEBGRmBQQIiISkwJCRERiUkCIiEhMjepSG2ZWBiw/yNkzgXV1WE5dUV0HRnUdGNV1YBpjXT3cPStWQ6MKiENhZoWJeE9s1XVgVNeBUV0HpqnVpSEmERGJSQEhIiIxKSC+9kTYBdRAdR0Y1XVgVNeBaVJ1aR+EiIjEpB6EiIjEpIAQEZGYmlxAmNloM1tgZovN7Kcx2tPM7O9B+0dm1jNB6rrSzMrMrCh4fLceanrKzErNbHYN7WZmjwY1zzSzI+NdUy3rKjCzTVHb6pf1VFc3M5tqZnPNbI6Z/SDGNPW+zWpZV71vMzNrbmYfm1lxUNevY0xT75/HWtZV75/HqHUnm9nnZjYxRlvdbi93bzIPIBlYAvQCmgHFwMC9prkBGBc8vwT4e4LUdSXwWD1vrxHAkcDsGtrPAN4EDDgW+ChB6ioAJobw/6sLcGTwPB1YGOPfsd63WS3rqvdtFmyD1sHzVOAj4Ni9pgnj81ibuur98xi17puB52L9e9X19mpqPYhjgMXuvtTddwN/A8buNc1Y4M/B85eAk83MEqCueufuM4D1+5hkLPCMR3wItDWzLglQVyjcfbW7fxY83wLMA3L2mqzet1kt66p3wTbYGrxMDR57HzVT75/HWtYVCjPrCpwJPFnDJHW6vZpaQOQAK6Jer+Q/PyhfTePulcAmoEMC1AVwfjAs8ZKZdYtzTbVR27rDcFwwRPCmmQ2q75UHXfsjiPz6jBbqNttHXRDCNguGS4qAUuBtd69xe9Xj57E2dUE4n8eHgZ8A1TW01+n2amoB0ZC9BvR096HA23z9K0H+02dEri+TC/wP8I/6XLmZtQZeBn7o7pvrc937sp+6Qtlm7l7l7nlAV+AYMxtcH+vdn1rUVe+fRzM7Cyh190/jva49mlpArAKik75r8F7MacwsBcgAysOuy93L3X1X8PJJ4Kg411Qbtdme9c7dN+8ZInD3N4BUM8usj3WbWSqRL+G/uvsrMSYJZZvtr64wt1mwzo3AVGD0Xk1hfB73W1dIn8cTgDFmtozIMPRJZvbsXtPU6fZqagHxCdDXzA4zs2ZEduJM2GuaCcAVwfMLgHc82OMTZl17jVOPITKOHLYJwOXBkTnHApvcfXXYRZlZ5z3jrmZ2DJH/53H/UgnW+X/APHd/qIbJ6n2b1aauMLaZmWWZWdvgeQvgG8D8vSar989jbeoK4/Po7j9z967u3pPId8Q77v7tvSar0+2VcrAzNkTuXmlmNwFvETly6Cl3n2NmvwEK3X0CkQ/SX8xsMZEdoZckSF3/ZWZjgMqgrivjXZeZPU/k6JZMM1sJ3Elkhx3uPg54g8hROYuB7cB34l1TLeu6ALjezCqBHcAl9RDyEPmFdxkwKxi/Bvg50D2qtjC2WW3qCmObdQH+bGbJRALpBXefGPbnsZZ11fvnsSbx3F661IaIiMTU1IaYRESklhQQIiISkwJCRERiUkCIiEhMCggREYlJASESIotcRfU/rsopkggUECIiEpMCQqQWzOzbwT0Ciszsj8HF3Laa2X8H9wyYYmZZwbR5ZvZhcCG3V82sXfB+HzObHFwQ7zMz6x0svnVwwbf5ZvbXqDOa77XIPRxmmtnvQ/rTpQlTQIjsh5kdDlwMnBBcwK0KuBRoReQM1kHAdCJndAM8A9wWXMhtVtT7fwX+EFwQ73hgzyU2jgB+CAwkck+QE8ysA3AuMChYzt3x/StF/pMCQmT/TiZyMbZPgktVnEzki7wa+HswzbPAcDPLANq6+/Tg/T8DI8wsHchx91cB3H2nu28PpvnY3Ve6ezVQBPQkcpnmncD/mdl5RC7LIVKvFBAi+2fAn909L3j0d/dfxZjuYK9bsyvqeRWQElzL/xgiN305C/jnQS5b5KApIET2bwpwgZl1BDCz9mbWg8jn54Jgmm8B77n7JmCDmZ0YvH8ZMD24k9tKMzsnWEaambWsaYXBvRsygktv/wjIjccfJrIvTepqriIHw93nmtntwCQzSwIqgBuBbURuJnM7kTuPXRzMcgUwLgiApXx9xdbLgD8GV9+sAC7cx2rTgfFm1pxID+bmOv6zRPZLV3MVOUhmttXdW4ddh0i8aIhJRERiUg9CRERiUg9CRERiUkCIiEhMCggREYlJASEiIjEpIEREJKb/D99tDc7kqPWdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdOjVegowUsv",
        "outputId": "2667d0ec-e67c-42e2-c1dd-6d0f1496b898"
      },
      "source": [
        "plt.plot([float(l.split(',')[0].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='group_auc')\n",
        "plt.plot([float(l.split(',')[1].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='mean_mrr')\n",
        "plt.plot([float(l.split(',')[2].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='ndcg@10')\n",
        "plt.plot([float(l.split(',')[3].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='ndcg@5')\n",
        "plt.title('eval measures over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5oVAOQz7RIi"
      },
      "source": [
        "### Overfitting measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SqZJb-J7Tiw",
        "outputId": "bec829e6-e8e6-4276-9b48-ce635ac95138"
      },
      "source": [
        "plt.plot([float(l.split(':')[-1]) for l in enhanced_model.history_loss['train']], label='train logloss')\n",
        "plt.plot([float(l.split(',')[0].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='group_auc')\n",
        "plt.plot([float(l.split(',')[1].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='mean_mrr')\n",
        "plt.plot([float(l.split(',')[2].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='ndcg@10')\n",
        "plt.plot([float(l.split(',')[3].split(':')[-1]) for l in enhanced_model.history_loss['eval']], label='ndcg@5')\n",
        "plt.title('overfit measure')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('score / loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O5-SOg7v7YH"
      },
      "source": [
        "# Evaluation of LSTUR vs Enhanced LSTUR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8S78EfvwAKK",
        "outputId": "6607424c-1feb-4ac2-f736-a0ae7c9c015c"
      },
      "source": [
        "plt.plot([float(l.split(':')[-1]) for l in lstur_model.history_loss['train']], label='LSTUR')\n",
        "plt.plot([float(l.split(':')[-1]) for l in enhanced_model.history_loss['train']], label='Enhanced LSTUR')\n",
        "plt.title('logloss LSTUR vs Enhanced LSTUR')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDwed00RiA6_",
        "outputId": "2f9dd306-3c59-4472-8319-02e531962e84"
      },
      "source": [
        "labels = ['group_auc', 'mean_mrr', 'ndcg@10', 'ndcg@5']\n",
        "\n",
        "lstur_measures = [float(lstur_model.history_loss['eval'][-1].split(',')[l].split(':')[-1]) for l in range(len(labels))]\n",
        "enhanced_lstur_measures = [float(enhanced_model.history_loss['eval'][-1].split(',')[l].split(':')[-1]) for l in range(len(labels))]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.2\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, lstur_measures, width, label='LSTUR')\n",
        "rects2 = ax.bar(x + width/2, enhanced_lstur_measures, width, label='Enhanced LSTUR')\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Scores on validation set')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "# ax.bar_label(rects1, padding=3)\n",
        "# ax.bar_label(rects2, padding=3)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpwBhBKkaa3"
      },
      "source": [
        "# Reference\n",
        "\\[1\\] Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie: Neural News Recommendation with Long- and Short-term User Representations, ACL 2019<br>\n",
        "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
        "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
      ]
    }
  ]
}
